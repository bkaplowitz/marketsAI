

@comment{jabref-meta: databaseType:biblatex;}

@techreport{asker2021,
	title={Artificial Intelligence and Pricing: The Impact of Algorithm Design},
	author={Asker, John and Fershtman, Chaim and Pakes, Ariel},
	year={2021},
	institution={National Bureau of Economic Research}
}

@article{baker2019,
	title={Emergent tool use from multi-agent autocurricula},
	author={Baker, Bowen and Kanitscheider, Ingmar and Markov, Todor and Wu, Yi and Powell, Glenn and McGrew, Bob and Mordatch, Igor},
	journal={arXiv preprint arXiv:1909.07528},
	year={2019}
}

@article{berner2019,
	title={Dota 2 with large scale deep reinforcement learning},
	author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and D{\k{e}}biak, Przemys{\l}aw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
	journal={arXiv preprint arXiv:1912.06680},
	year={2019}
}


@article{bertsekas2012,
	title={Q-learning and enhanced policy iteration in discounted dynamic programming},
	author={Bertsekas, Dimitri P and Yu, Huizhen},
	journal={Mathematics of Operations Research},
	volume={37},
	number={1},
	pages={66--94},
	year={2012},
	publisher={INFORMS}
}

@article{calvano2020,
	title={Artificial intelligence, algorithmic pricing, and collusion},
	author={Calvano, Emilio and Calzolari, Giacomo and Denicolo, Vincenzo and Pastorello, Sergio},
	journal={American Economic Review},
	volume={110},
	number={10},
	pages={3267--97},
	year={2020}
}

@article{co-reyes2021,
	title={Evolving Reinforcement Learning Algorithms},
	author={Co-Reyes, John D and Miao, Yingjie and Peng, Daiyi and Real, Esteban and Levine, Sergey and Le, Quoc V and Lee, Honglak and Faust, Aleksandra},
	journal={arXiv preprint arXiv:2101.03958},
	year={2021}
}

@inproceedings{espeholt2018,
	title={Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures},
	author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Vlad and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
	booktitle={International Conference on Machine Learning},
	pages={1407--1416},
	year={2018},
	organization={PMLR}
}

@inproceedings{fujimoto2018,
	title={Addressing function approximation error in actor-critic methods},
	author={Fujimoto, Scott and Hoof, Herke and Meger, David},
	booktitle={International Conference on Machine Learning},
	pages={1587--1596},
	year={2018},
	organization={PMLR}
}

@inproceedings{haarnoja2018,
	title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
	author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
	booktitle={International Conference on Machine Learning},
	pages={1861--1870},
	year={2018},
	organization={PMLR}
}

@book{hansen2008,
	title={Robustness},
	author={Hansen, Lars Peter and Sargent, Thomas J},
	year={2008},
	publisher={Princeton university press}
}

@article{liaw2018,
	title={Tune: A Research Platform for Distributed Model Selection and Training},
	author={Liaw, Richard and Liang, Eric and Nishihara, Robert
	and Moritz, Philipp and Gonzalez, Joseph E and Stoica, Ion},
	journal={arXiv preprint arXiv:1807.05118},
	year={2018}
}

@article{lillicrap2015,
	title={Continuous control with deep reinforcement learning},
	author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
	journal={arXiv preprint arXiv:1509.02971},
	year={2015}
}

@article{graf2021,
	title={Computational Performance of Deep Reinforcement Learning to find Nash Equilibria},
	author={Graf, Christoph and Zobernig, Viktor and Schmidt, Johannes and Kl{\"o}ckl, Claude},
	journal={arXiv preprint arXiv:2104.12895},
	year={2021}
}

@article{ma2020,
	title={Unbounded Dynamic Programming via the Q-Learning Transform},
	author={Ma, Qingyin and Stachurski, John and Toda, Alexis Akira},
	journal={arXiv preprint arXiv:2012.00219},
	year={2020}
}

@article{ma2021,
	title={Dynamic programming deconstructed: Transformations of the bellman equation and computational efficiency},
	author={Ma, Qingyin and Stachurski, John},
	journal={Operations Research},
	year={2021},
	publisher={INFORMS}
}

@inproceedings{maei2009,
	title={Convergent temporal-difference learning with arbitrary smooth function approximation.},
	author={Maei, Hamid Reza and Szepesvari, Csaba and Bhatnagar, Shalabh and Precup, Doina and Silver, David and Sutton, Richard S},
	booktitle={NIPS},
	pages={1204--1212},
	year={2009}
}

@article{mnih2013,
	title={Playing atari with deep reinforcement learning},
	author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
	journal={arXiv preprint arXiv:1312.5602},
	year={2013}
}

@article{nachum2018,
	title={Data-efficient hierarchical reinforcement learning},
	author={Nachum, Ofir and Gu, Shixiang and Lee, Honglak and Levine, Sergey},
	journal={arXiv preprint arXiv:1805.08296},
	year={2018}
}

@article{narvekar2020,
	title={Curriculum learning for reinforcement learning domains: A framework and survey},
	author={Narvekar, Sanmit and Peng, Bei and Leonetti, Matteo and Sinapov, Jivko and Taylor, Matthew E and Stone, Peter},
	journal={Journal of Machine Learning Research},
	volume={21},
	number={181},
	pages={1--50},
	year={2020}
}

@inproceedings{real2020,
	title={AutoML-zero: evolving machine learning algorithms from scratch},
	author={Real, Esteban and Liang, Chen and So, David and Le, Quoc},
	booktitle={International Conference on Machine Learning},
	pages={8007--8019},
	year={2020},
	organization={PMLR}
}

@article{schulman2017,
	title={Proximal policy optimization algorithms},
	author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	journal={arXiv preprint arXiv:1707.06347},
	year={2017}
}

@book{sutton2018,
	title={Reinforcement learning: An introduction},
	author={Sutton, Richard S and Barto, Andrew G},
	year={2018},
	publisher={MIT press}
}

@article{tsitsiklis1994,
	title={Asynchronous stochastic approximation and Q-learning},
	author={Tsitsiklis, John N},
	journal={Machine learning},
	volume={16},
	number={3},
	pages={185--202},
	year={1994},
	publisher={Springer}
}

@inproceedings{wang2018,
	title={Exponentially Weighted Imitation Learning for Batched Historical Data.},
	author={Wang, Qing and Xiong, Jiechao and Han, Lei and Sun, Peng and Liu, Han and Zhang, Tong},
	booktitle={NeurIPS},
	pages={6291--6300},
	year={2018}
}

@article{watkins1989,
	title={Learning from delayed rewards},
	author={Watkins, Christopher John Cornish Hellaby},
	year={1989},
	publisher={King's College, Cambridge United Kingdom}
}

@article{watkins1992,
	title={Q-learning},
	author={Watkins, Christopher JCH and Dayan, Peter},
	journal={Machine learning},
	volume={8},
	number={3-4},
	pages={279--292},
	year={1992},
	publisher={Springer}
}

@article{vinyals2019,
	title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
	author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
	journal={Nature},
	volume={575},
	number={7782},
	pages={350--354},
	year={2019},
	publisher={Nature Publishing Group}
}


