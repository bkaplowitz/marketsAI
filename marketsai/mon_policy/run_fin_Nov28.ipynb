{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# import environment\n",
    "from marketsai.mon_policy.env_mon_fin_dictob import MonPolicyFinite\n",
    "\n",
    "# from marketsai.mon_policy.env_mon_policy_colab import MonPolicyColab\n",
    "\n",
    "# import ray\n",
    "from ray import tune, shutdown, init\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "# from ray.tune.integration.mlflow import MLflowLoggerCallback\n",
    "\n",
    "# For custom metrics (Callbacks)\n",
    "from scipy.stats import linregress\n",
    "from ray.rllib.agents.callbacks import DefaultCallbacks\n",
    "from scipy.stats import linregress\n",
    "from ray.rllib.env import BaseEnv\n",
    "from ray.rllib.evaluation import MultiAgentEpisode, RolloutWorker\n",
    "from ray.rllib.policy import Policy\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "\n",
    "# common imports\n",
    "from typing import Dict\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "\n",
    "# import logging\n",
    "# import random\n",
    "# import math\n",
    "\n",
    "\"\"\" STEP 0: Experiment configs \"\"\"\n",
    "\n",
    "\n",
    "DATE = \"Nov28_\"\n",
    "ENV_LABEL = \"mon_fin\"\n",
    "OBS_IDSHOCK = False\n",
    "INFL_REGIME = \"low\"\n",
    "NATIVE = False\n",
    "TEST = True\n",
    "RUN_TRAINING = True\n",
    "RUN_ANALYSIS = True\n",
    "# in case there is no training\n",
    "INFO_ANALYSIS = \"/Users/matiascovarrubias/Dropbox/RL_macro/Tests/expINFO_native_mon_fin_exp_0_Nov1_PPO_test.json\"\n",
    "SAVE_EXP_INFO = True\n",
    "SAVE_PROGRESS = True\n",
    "PLOT_PROGRESS = True\n",
    "sn.color_palette(\"Set2\")\n",
    "\n",
    "if TEST:\n",
    "    if NATIVE:\n",
    "        OUTPUT_PATH_EXPERS = (\n",
    "            \"/Users/matiascovarrubias/Dropbox/RL_macro/Experiments/ALL/\"\n",
    "        )\n",
    "        OUTPUT_PATH_FIGURES = (\n",
    "            \"/Users/matiascovarrubias/Dropbox/RL_macro/Documents/Figures/ALL/\"\n",
    "        )\n",
    "        OUTPUT_PATH_RESULTS = \"~/ray_results/ALL/\"\n",
    "    else:\n",
    "        OUTPUT_PATH_EXPERS = \"/scratch/mc5851/Experiments/ALL/\"\n",
    "        OUTPUT_PATH_FIGURES = \"/scratch/mc5851/Figures/ALL/\"\n",
    "        OUTPUT_PATH_RESULTS = \"/scratch/mc5851/ray_results/ALL/\"\n",
    "\n",
    "else:\n",
    "    if NATIVE:\n",
    "        OUTPUT_PATH_EXPERS = \"/Users/matiascovarrubias/Dropbox/RL_macro/Experiments/\"\n",
    "        OUTPUT_PATH_FIGURES = (\n",
    "            \"/Users/matiascovarrubias/Dropbox/RL_macro/Documents/Figures/\"\n",
    "        )\n",
    "        OUTPUT_PATH_RESULTS = \"~/ray_results\"\n",
    "    else:\n",
    "        OUTPUT_PATH_EXPERS = \"/scratch/mc5851/Experiments/\"\n",
    "        OUTPUT_PATH_FIGURES = \"/scratch/mc5851/Figures/\"\n",
    "        OUTPUT_PATH_RESULTS = \"/scratch/mc5851/ray_results/\"\n",
    "\n",
    "ALGO = \"PPO\"  # either PPO\" or \"SAC\"\n",
    "if NATIVE:\n",
    "    device = \"native_\"  # either \"native\" or \"server\"\n",
    "else:\n",
    "    device = \"server_\"\n",
    "\n",
    "n_firms_LIST = [2]  # list with number of agents for each run\n",
    "n_inds_LIST = [200]\n",
    "ITERS_TEST = 10  # number of iteration for test\n",
    "ITERS_RUN = 2000  # number of iteration for fullrun\n",
    "\n",
    "\n",
    "# Other economic Hiperparameteres.\n",
    "ENV_HORIZON = 12 * 5\n",
    "EVAL_HORIZON = 12 * 5\n",
    "BETA = 0.95 ** (1 / 12)  # discount parameter\n",
    "\n",
    "# Analysis options\n",
    "PLOT_HIST = True\n",
    "EVAL_RESULTS = True\n",
    "NO_FLEX_HORIZON = 36\n",
    "CHKPT_SELECT_REF = True\n",
    "RESULTS_REF = np.array([1.32, 1.24, 0.12, 0.08, 0.009])\n",
    "CHKPT_SELECT_MANUAL = False\n",
    "CHKPT_id = 0\n",
    "CHKPT_SELECT_MIN = False\n",
    "CHKPT_SELECT_MAX = False\n",
    "\"\"\" STEP 1: Paralleliztion and batch options\"\"\"\n",
    "# Parallelization options\n",
    "NUM_CPUS = 40\n",
    "NUM_CPUS_DRIVER = 1\n",
    "NUM_TRIALS = 40\n",
    "NUM_PAR_TRIALS = 40\n",
    "NUM_ROLLOUT = ENV_HORIZON * 1\n",
    "NUM_ENV_PW = 1  # num_env_per_worker\n",
    "NUM_GPUS = 0\n",
    "BATCH_ROLLOUT = 1\n",
    "NUM_MINI_BATCH = NUM_CPUS_DRIVER\n",
    "\n",
    "N_WORKERS = (NUM_CPUS - NUM_PAR_TRIALS * NUM_CPUS_DRIVER) // NUM_PAR_TRIALS\n",
    "BATCH_SIZE = NUM_ROLLOUT * (max(N_WORKERS, 1)) * NUM_ENV_PW * BATCH_ROLLOUT\n",
    "\n",
    "print(\"number of workers:\", N_WORKERS, \"batch size:\", BATCH_SIZE)\n",
    "\n",
    "# define length of experiment (MAX_STEPS) and experiment name\n",
    "if TEST == True:\n",
    "    MAX_STEPS = ITERS_TEST * BATCH_SIZE\n",
    "else:\n",
    "    MAX_STEPS = ITERS_RUN * BATCH_SIZE\n",
    "\n",
    "# checkpointing, evaluation during trainging and stopage\n",
    "CHKPT_FREQ = 1000\n",
    "if TEST:\n",
    "    EVAL_INTERVAL = ITERS_TEST\n",
    "    EVAL_EPISODES = 10\n",
    "    SIMUL_EPISODES = 10\n",
    "else:\n",
    "    EVAL_INTERVAL = ITERS_RUN\n",
    "    EVAL_EPISODES = 50\n",
    "    SIMUL_EPISODES = 50\n",
    "\n",
    "STOP = {\"timesteps_total\": MAX_STEPS}\n",
    "\n",
    "# Initialize ray\n",
    "shutdown()\n",
    "init(\n",
    "    num_cpus=47,\n",
    "    num_gpus=NUM_GPUS,\n",
    "    log_to_driver=False,\n",
    ")\n",
    "# global configss\n",
    "register_env(ENV_LABEL, MonPolicyFinite)\n",
    "\n",
    "\"\"\" STEP 2: set custom metrics such as discounted rewards to keep track of through leraning\"\"\"\n",
    "# Define custom metrics using the Callbacks class\n",
    "# See rllib documentation on Callbacks. They are a way of inserting code in different parts of the pipeline.\n",
    "\n",
    "# function to get discounted rewards for analysys\n",
    "def process_rewards(r):\n",
    "    \"\"\"Compute discounted reward from a vector of rewards.\"\"\"\n",
    "    discounted_r = np.zeros_like(r)\n",
    "    running_add = 0\n",
    "    for t in reversed(range(0, len(r))):\n",
    "        running_add = running_add * BETA + r[t]\n",
    "        discounted_r[t] = running_add\n",
    "    return discounted_r[0]\n",
    "\n",
    "\n",
    "class MyCallbacks(DefaultCallbacks):\n",
    "    def on_episode_start(\n",
    "        self,\n",
    "        *,\n",
    "        worker: RolloutWorker,\n",
    "        base_env: BaseEnv,\n",
    "        policies: Dict[str, Policy],\n",
    "        episode: MultiAgentEpisode,\n",
    "        env_index: int,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        # Make sure this episode has just been started (only initial obs\n",
    "        # logged so far).\n",
    "\n",
    "        assert episode.length == 0, (\n",
    "            \"ERROR: `on_episode_start()` callback should be called right \"\n",
    "            \"after env reset!\"\n",
    "        )\n",
    "        episode.user_data[\"rewards\"] = []\n",
    "        episode.user_data[\"markup_ij_avge\"] = []\n",
    "        episode.user_data[\"markup_agg\"] = []\n",
    "        episode.user_data[\"freq_p_adj\"] = []\n",
    "        episode.user_data[\"size_adj\"] = []\n",
    "        episode.user_data[\"log_c\"] = []\n",
    "        episode.user_data[\"profits\"] = []\n",
    "\n",
    "    def on_episode_step(\n",
    "        self,\n",
    "        *,\n",
    "        worker: RolloutWorker,\n",
    "        base_env: BaseEnv,\n",
    "        episode: MultiAgentEpisode,\n",
    "        env_index: int,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        if episode.length > 1:  # at t=0, previous rewards are not defined\n",
    "            episode.user_data[\"rewards\"].append(episode.prev_reward_for(0))\n",
    "\n",
    "            episode.user_data[\"markup_ij_avge\"].append(\n",
    "                episode.last_info_for(0)[\"mean_mu_ij\"]\n",
    "            )\n",
    "            episode.user_data[\"markup_agg\"].append(\n",
    "                episode.last_info_for(0)[\"mu\"]\n",
    "            )\n",
    "            episode.user_data[\"freq_p_adj\"].append(\n",
    "                episode.last_info_for(0)[\"move_freq\"]\n",
    "            )\n",
    "            episode.user_data[\"size_adj\"].append(\n",
    "                episode.last_info_for(0)[\"mean_p_change\"]\n",
    "            )\n",
    "            episode.user_data[\"log_c\"].append(episode.last_info_for(0)[\"log_c\"])\n",
    "            episode.user_data[\"profits\"].append(\n",
    "                episode.last_info_for(0)[\"mean_profits\"]\n",
    "            )\n",
    "\n",
    "    def on_episode_end(\n",
    "        self,\n",
    "        *,\n",
    "        worker: RolloutWorker,\n",
    "        base_env: BaseEnv,\n",
    "        policies: Dict[str, Policy],\n",
    "        episode: MultiAgentEpisode,\n",
    "        env_index: int,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        episode.custom_metrics[\"discounted_rewards\"] = process_rewards(\n",
    "            episode.user_data[\"rewards\"][:-NO_FLEX_HORIZON]\n",
    "        )\n",
    "\n",
    "        episode.custom_metrics[\"mean_markup_ij\"] = np.mean(\n",
    "            episode.user_data[\"markup_ij_avge\"][:-NO_FLEX_HORIZON]\n",
    "        )\n",
    "        episode.custom_metrics[\"mean_mu_agg\"] = np.mean(\n",
    "            episode.user_data[\"markup_agg\"][:-NO_FLEX_HORIZON]\n",
    "        )\n",
    "\n",
    "        episode.custom_metrics[\"freq_p_adj\"] = np.mean(\n",
    "            episode.user_data[\"freq_p_adj\"][:-NO_FLEX_HORIZON]\n",
    "        )\n",
    "        episode.custom_metrics[\"size_adj\"] = np.mean(\n",
    "            episode.user_data[\"size_adj\"][:-NO_FLEX_HORIZON]\n",
    "        )\n",
    "        episode.custom_metrics[\"std_log_c\"] = np.std(\n",
    "            episode.user_data[\"log_c\"][:-NO_FLEX_HORIZON]\n",
    "        )\n",
    "        episode.custom_metrics[\"profits\"] = np.mean(\n",
    "            episode.user_data[\"profits\"][:-NO_FLEX_HORIZON]\n",
    "        )\n",
    "\n",
    "        episode.custom_metrics[\"mean_markup_ij_final\"] = np.mean(\n",
    "            episode.user_data[\"markup_ij_avge\"][-12:]\n",
    "        )\n",
    "\n",
    "\n",
    "\"\"\" STEP 3: Environment and Algorithm configuration \"\"\"\n",
    "\n",
    "# environment config including evaluation environment (without exploration)\n",
    "env_config = {\n",
    "    \"horizon\": ENV_HORIZON,\n",
    "    \"n_inds\": n_inds_LIST[0],\n",
    "    \"n_firms\": n_firms_LIST[0],\n",
    "    # \"eval_mode\": False,\n",
    "    # \"random_eval\": True,\n",
    "    # \"analysis_mode\": False,\n",
    "    \"noagg\": False,\n",
    "    \"obs_flex_index\": True,\n",
    "    \"obs_idshock\": OBS_IDSHOCK,\n",
    "    \"infl_regime\": INFL_REGIME,\n",
    "    # \"infl_regime_scale\": [3, 1.3, 2],\n",
    "    # \"seed_eval\": 10000,\n",
    "    # \"seed_analisys\": 3000,\n",
    "    # \"markup_min\": 1,\n",
    "    # \"markup_max\": 2,\n",
    "    # \"markup_star\": 1.3,\n",
    "    # \"final_stage\": 12,\n",
    "    # \"rew_mean\": 0,\n",
    "    # \"rew_std\": 1,\n",
    "    # \"parameters\": {\n",
    "    #     \"beta\": 0.95 ** (1 / 12),\n",
    "    #     \"log_g_bar\": 0.0021,\n",
    "    #     \"rho_g\": 0.61,\n",
    "    #     \"sigma_g\": 0.0019,\n",
    "    #     \"theta\": 1.5,\n",
    "    #     \"eta\": 10.5,\n",
    "    #     \"menu_cost\": 0.17,\n",
    "    #     \"sigma_z\": 0.038,\n",
    "    # },\n",
    "}\n",
    "\n",
    "\n",
    "env_config_eval = env_config.copy()\n",
    "env_config_eval[\"eval_mode\"] = True\n",
    "env_config_eval[\"horizon\"] = EVAL_HORIZON\n",
    "\n",
    "# we instantiate the environment to extrac relevant info\n",
    "\" CHANGE HERE \"\n",
    "env = MonPolicyFinite(env_config)\n",
    "\n",
    "# common configuration\n",
    "\n",
    "\"\"\"\n",
    "NOTE: in order to do hyperparameter optimization, you can select a range of values \n",
    "with tune.choice([0.05,1] for random choice or tune.grid_search([0.05,1]) for fix search.\n",
    "# see https://docs.ray.io/en/master/tune/key-concepts.html#search-spaces for spaces and their definition.\n",
    "# se at the bottom (Annex_env_hyp) for an explanation how to do the same with environment parameters.\n",
    "\"\"\"\n",
    "common_config = {\n",
    "    # CUSTOM METRICS\n",
    "    \"callbacks\": MyCallbacks,\n",
    "    # ENVIRONMENT\n",
    "    \"gamma\": BETA,\n",
    "    \"env\": ENV_LABEL,\n",
    "    \"env_config\": env_config,\n",
    "    \"horizon\": ENV_HORIZON,\n",
    "    # MODEL\n",
    "    \"framework\": \"torch\",\n",
    "    # \"model\": tune.grid_search([{\"use_lstm\": True}, {\"use_lstm\": False}]),\n",
    "    # TRAINING CONFIG\n",
    "    \"num_workers\": N_WORKERS,\n",
    "    \"create_env_on_driver\": False,\n",
    "    \"num_gpus\": NUM_GPUS / NUM_PAR_TRIALS,\n",
    "    \"num_envs_per_worker\": NUM_ENV_PW,\n",
    "    \"num_cpus_for_driver\": NUM_CPUS_DRIVER,\n",
    "    \"rollout_fragment_length\": NUM_ROLLOUT,\n",
    "    \"train_batch_size\": BATCH_SIZE,\n",
    "    # EVALUATION\n",
    "    \"evaluation_interval\": EVAL_INTERVAL,\n",
    "    \"evaluation_num_episodes\": EVAL_EPISODES,\n",
    "    \"evaluation_config\": {\n",
    "        \"explore\": False,\n",
    "        \"env_config\": env_config_eval,\n",
    "    },\n",
    "    # MULTIAGENT,\n",
    "    \"multiagent\": {\n",
    "        \"policies\": {\n",
    "            \"firm_even\": (\n",
    "                None,\n",
    "                env.observation_space[0],\n",
    "                env.action_space[0],\n",
    "                {},\n",
    "            ),\n",
    "            \"firm_odd\": (\n",
    "                None,\n",
    "                env.observation_space[0],\n",
    "                env.action_space[0],\n",
    "                {},\n",
    "            ),\n",
    "        },\n",
    "        \"policy_mapping_fn\": (\n",
    "            lambda agent_id: \"firm_even\" if agent_id % 2 == 0 else \"firm_odd\"\n",
    "        ),\n",
    "        # \"replay_mode\": \"independent\",  # you can change to \"lockstep\".\n",
    "        # OTHERS\n",
    "    },\n",
    "}\n",
    "\n",
    "# Configs specific to the chosel algorithms, INCLUDING THE LEARNING RATE\n",
    "ppo_config = {\n",
    "    # \"lr\": 0.0001,\n",
    "    \"lr_schedule\": [[0, 0.00005], [MAX_STEPS/2, 0.00001]],\n",
    "    \"sgd_minibatch_size\": BATCH_SIZE // NUM_MINI_BATCH,\n",
    "    \"num_sgd_iter\": 1,\n",
    "    \"batch_mode\": \"complete_episodes\",\n",
    "    # \"lambda\": 0.98,\n",
    "    # \"entropy_coeff\": 0,\n",
    "    # \"kl_coeff\": 0.2,\n",
    "    # \"vf_loss_coeff\": 0.5,\n",
    "    \"vf_clip_param\": float(\"inf\"),\n",
    "    # \"entropy_coeff_schedule\": [[0, 0.01], [5120 * 1000, 0]],\n",
    "    \"clip_param\": 0.15,\n",
    "    \"clip_actions\": True,\n",
    "}\n",
    "\n",
    "sac_config = {\"prioritized_replay\": False, \"normalize_actions\": False}\n",
    "\n",
    "if ALGO == \"PPO\":\n",
    "    training_config = {**common_config, **ppo_config}\n",
    "elif ALGO == \"SAC\":\n",
    "    training_config = {**common_config, **sac_config}\n",
    "else:\n",
    "    training_config = common_config"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/scratch/mc5851/.env/lib/python3.8/site-packages/ray/autoscaler/_private/cli_logger.py:57: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of workers: 0 batch size: 60\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-11-28 19:18:36,908\tINFO services.py:1272 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "/scratch/mc5851/.env/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\"\"\" STEP 4: run training \"\"\"\n",
    "\n",
    "if RUN_TRAINING:\n",
    "    exp_names = []\n",
    "    trial_logdirs = []\n",
    "    exp_dirs = []\n",
    "    checkpoints = []\n",
    "    configs = []\n",
    "    learning_dta = []\n",
    "\n",
    "    rewards_eval = []\n",
    "    mu_ij_eval = []\n",
    "    mu_agg_eval = []\n",
    "    mu_ij_final_eval = []\n",
    "    freq_p_adj_eval = []\n",
    "    size_adj_eval = []\n",
    "    std_log_c_eval = []\n",
    "    profits_eval = []\n",
    "\n",
    "    rewards = []\n",
    "    mu_ij = []\n",
    "    mu_agg =[]\n",
    "    mu_ij_final = []\n",
    "    freq_p_adj = []\n",
    "    size_adj = []\n",
    "    std_log_c = []\n",
    "    profits = []\n",
    "\n",
    "    # RUN TRAINER\n",
    "    env_configs = []\n",
    "\n",
    "    for ind, n_firms in enumerate(n_firms_LIST):\n",
    "        EXP_LABEL = device + ENV_LABEL + f\"_exp_{ind}_\"\n",
    "        if TEST == True:\n",
    "            EXP_NAME = EXP_LABEL + DATE + ALGO + \"_test\"\n",
    "        else:\n",
    "            EXP_NAME = EXP_LABEL + DATE + ALGO + \"_run\"\n",
    "\n",
    "        env_config[\"n_firms\"] = n_firms\n",
    "        env_config_eval[\"n_firms\"] = n_firms\n",
    "\n",
    "        \"\"\" CHANGE HERE \"\"\"\n",
    "        env = MonPolicyFinite(env_config)\n",
    "        training_config[\"env_config\"] = env_config\n",
    "        training_config[\"evaluation_config\"][\"env_config\"] = env_config_eval\n",
    "        training_config[\"multiagent\"] = {\n",
    "            \"policies\": {\n",
    "                \"firm_even\": (\n",
    "                    None,\n",
    "                    env.observation_space[0],\n",
    "                    env.action_space[0],\n",
    "                    {},\n",
    "                ),\n",
    "                \"firm_odd\": (\n",
    "                    None,\n",
    "                    env.observation_space[0],\n",
    "                    env.action_space[0],\n",
    "                    {},\n",
    "                ),\n",
    "            },\n",
    "            \"policy_mapping_fn\": (\n",
    "                lambda agent_id: \"firm_even\" if agent_id % 2 == 0 else \"firm_odd\"\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        analysis = tune.run(\n",
    "            ALGO,\n",
    "            name=EXP_NAME,\n",
    "            config=training_config,\n",
    "            stop=STOP,\n",
    "            checkpoint_freq=CHKPT_FREQ,\n",
    "            checkpoint_at_end=True,\n",
    "            # metric=\"evaluation/custom_metrics/discounted_rewards_mean\",\n",
    "            # metric=\"custom_metrics/discounted_rewards_mean\",\n",
    "            # mode=\"max\",\n",
    "            num_samples=NUM_TRIALS,\n",
    "            local_dir=OUTPUT_PATH_RESULTS,\n",
    "            verbose=1,\n",
    "            # resources_per_trial={\"gpu\": 0.5},\n",
    "        )\n",
    "\n",
    "        rewards_eval.append(\n",
    "            [\n",
    "                list(analysis.results.values())[i][\"evaluation\"][\"custom_metrics\"][\n",
    "                    \"discounted_rewards_mean\"\n",
    "                ]\n",
    "                for i in range(NUM_TRIALS)\n",
    "            ]\n",
    "        )\n",
    "        mu_ij_eval.append(\n",
    "            [\n",
    "                list(analysis.results.values())[i][\"evaluation\"][\"custom_metrics\"][\n",
    "                    \"mean_markup_ij_mean\"\n",
    "                ]\n",
    "                for i in range(NUM_TRIALS)\n",
    "            ]\n",
    "        )\n",
    "        mu_agg_eval.append(\n",
    "            [\n",
    "                list(analysis.results.values())[i][\"evaluation\"][\"custom_metrics\"][\n",
    "                    \"mu_agg_mean\"\n",
    "                ]\n",
    "                for i in range(NUM_TRIALS)\n",
    "            ]\n",
    "        )\n",
    "        mu_ij_final_eval.append(\n",
    "            [\n",
    "                list(analysis.results.values())[i][\"evaluation\"][\"custom_metrics\"][\n",
    "                    \"mean_markup_ij_final_mean\"\n",
    "                ]\n",
    "                for i in range(NUM_TRIALS)\n",
    "            ]\n",
    "        )\n",
    "        freq_p_adj_eval.append(\n",
    "            [\n",
    "                list(analysis.results.values())[i][\"evaluation\"][\"custom_metrics\"][\n",
    "                    \"freq_p_adj_mean\"\n",
    "                ]\n",
    "                for i in range(NUM_TRIALS)\n",
    "            ]\n",
    "        )\n",
    "        size_adj_eval.append(\n",
    "            [\n",
    "                list(analysis.results.values())[i][\"evaluation\"][\"custom_metrics\"][\n",
    "                    \"size_adj_mean\"\n",
    "                ]\n",
    "                for i in range(NUM_TRIALS)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        std_log_c_eval.append(\n",
    "            [\n",
    "                list(analysis.results.values())[i][\"evaluation\"][\"custom_metrics\"][\n",
    "                    \"std_log_c_mean\"\n",
    "                ]\n",
    "                for i in range(NUM_TRIALS)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        profits_eval.append(\n",
    "            [\n",
    "                list(analysis.results.values())[i][\"custom_metrics\"][\"profits_mean\"]\n",
    "                for i in range(NUM_TRIALS)\n",
    "            ]\n",
    "        )\n",
    "        rewards.append(\n",
    "            [\n",
    "                list(analysis.results.values())[i][\"custom_metrics\"][\n",
    "                    \"discounted_rewards_mean\"\n",
    "                ]\n",
    "                for i in range(NUM_TRIALS)\n",
    "            ]\n",
    "        )\n",
    "        mu_ij.append(\n",
    "            [\n",
    "                list(analysis.results.values())[i][\"custom_metrics\"][\n",
    "                    \"mean_markup_ij_mean\"\n",
    "                ]\n",
    "                for i in range(NUM_TRIALS)\n",
    "            ]\n",
    "        )\n",
    "        mu_agg.append(\n",
    "            [\n",
    "                list(analysis.results.values())[i][\"custom_metrics\"][\n",
    "                    \"mean_mu_agg\"\n",
    "                ]\n",
    "                for i in range(NUM_TRIALS)\n",
    "            ]\n",
    "        )\n",
    "        mu_ij_final.append(\n",
    "            [\n",
    "                list(analysis.results.values())[i][\"custom_metrics\"][\n",
    "                    \"mean_markup_ij_final_mean\"\n",
    "                ]\n",
    "                for i in range(NUM_TRIALS)\n",
    "            ]\n",
    "        )\n",
    "        freq_p_adj.append(\n",
    "            [\n",
    "                list(analysis.results.values())[i][\"custom_metrics\"][\"freq_p_adj_mean\"]\n",
    "                for i in range(NUM_TRIALS)\n",
    "            ]\n",
    "        )\n",
    "        size_adj.append(\n",
    "            [\n",
    "                list(analysis.results.values())[i][\"custom_metrics\"][\"size_adj_mean\"]\n",
    "                for i in range(NUM_TRIALS)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        std_log_c.append(\n",
    "            [\n",
    "                list(analysis.results.values())[i][\"custom_metrics\"][\"std_log_c_mean\"]\n",
    "                for i in range(NUM_TRIALS)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        profits.append(\n",
    "            [\n",
    "                list(analysis.results.values())[i][\"custom_metrics\"][\"profits_mean\"]\n",
    "                for i in range(NUM_TRIALS)\n",
    "            ]\n",
    "        )\n",
    "        exp_names.append(EXP_NAME)\n",
    "        exp_dirs.append(analysis._experiment_dir)\n",
    "        trial_logdirs.append([analysis.trials[i].logdir for i in range(NUM_TRIALS)])\n",
    "        configs.append(\n",
    "            [\n",
    "                {\n",
    "                    \"env_config\": analysis.trials[i].config[\"env_config\"],\n",
    "                    # \"lr\": analysis.trials[i].config[\"lr\"],\n",
    "                    \"lr_schedule\": analysis.trials[i].config[\"lr_schedule\"],\n",
    "                }\n",
    "                for i in range(NUM_TRIALS)\n",
    "            ]\n",
    "        )\n",
    "        checkpoints.append(\n",
    "            [analysis.trials[i].checkpoint.value for i in range(NUM_TRIALS)]\n",
    "        )\n",
    "\n",
    "        # learning_dta.append(\n",
    "        #     analysis.best_dataframe[\n",
    "        #         [\"episodes_total\", \"evaluation/custom_metrics/discounted_rewards_mean\"]\n",
    "        #     ]\n",
    "        # )\n",
    "        if SAVE_PROGRESS:\n",
    "            learning_dta.append(\n",
    "                [\n",
    "                    list(analysis.trial_dataframes.values())[i][\n",
    "                        [\n",
    "                            # \"episodes_total\",\n",
    "                            \"custom_metrics/discounted_rewards_mean\",\n",
    "                            \"custom_metrics/mean_markup_ij_mean\",\n",
    "                            \"custom_metrics/mean_mu_agg_mean\",\n",
    "                            \"custom_metrics/mean_markup_ij_final_mean\",\n",
    "                            \"custom_metrics/freq_p_adj_mean\",\n",
    "                            \"custom_metrics/size_adj_mean\",\n",
    "                            \"custom_metrics/std_log_c_mean\",\n",
    "                            \"custom_metrics/profits_mean\",\n",
    "                        ]\n",
    "                    ]\n",
    "                    for i in range(NUM_TRIALS)\n",
    "                ]\n",
    "            )\n",
    "            for i in range(NUM_TRIALS):\n",
    "                learning_dta[ind][i].columns = [\n",
    "                    # \"episodes_total\",\n",
    "                    f\"discounted_rewards_trial_{i}\",\n",
    "                    f\"mu_ij_trial_{i}\",\n",
    "                    f\"mu_agg_trial_{i}\",\n",
    "                    f\"mu_ij_final_trial_{i}\",\n",
    "                    f\"freq_p_adj_trial_{i}\",\n",
    "                    f\"size_adj_trial_{i}\",\n",
    "                    f\"std_log_c_trial_{i}\",\n",
    "                    f\"profits_trial_{i}\",\n",
    "                ]\n",
    "                # learning_dta[ind][i].set_index(\"episodes_total\")\n",
    "            pd.concat(learning_dta[ind], axis=1).to_csv(\n",
    "                OUTPUT_PATH_EXPERS + \"progress_\" + exp_names[ind] + \".csv\"\n",
    "            )\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.2/188.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/47 CPUs, 0/0 GPUs, 0.0/112.04 GiB heap, 0.0/52.01 GiB objects<br>Result logdir: /scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test<br>Number of trials: 40/40 (40 ERROR)<br>Number of errored trials: 40<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_mon_fin_e6984_00000</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00000_0_2021-11-28_19-18-39/error.txt </td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00001</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00001_1_2021-11-28_19-18-39/error.txt </td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00002</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00002_2_2021-11-28_19-18-39/error.txt </td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00003</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00003_3_2021-11-28_19-18-39/error.txt </td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00004</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00004_4_2021-11-28_19-18-39/error.txt </td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00005</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00005_5_2021-11-28_19-18-39/error.txt </td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00006</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00006_6_2021-11-28_19-18-39/error.txt </td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00007</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00007_7_2021-11-28_19-18-39/error.txt </td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00008</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00008_8_2021-11-28_19-18-39/error.txt </td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00009</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00009_9_2021-11-28_19-18-39/error.txt </td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00010</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00010_10_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00011</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00011_11_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00012</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00012_12_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00013</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00013_13_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00014</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00014_14_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00015</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00015_15_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00016</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00016_16_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00017</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00017_17_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00018</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00018_18_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00019</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00019_19_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00020</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00020_20_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00021</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00021_21_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00022</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00022_22_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00023</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00023_23_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00024</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00024_24_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00025</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00025_25_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00026</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00026_26_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00027</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00027_27_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00028</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00028_28_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00029</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00029_29_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00030</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00030_30_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00031</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00031_31_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00032</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00032_32_2021-11-28_19-18-39/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00033</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00033_33_2021-11-28_19-18-40/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00034</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00034_34_2021-11-28_19-18-40/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00035</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00035_35_2021-11-28_19-18-40/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00036</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00036_36_2021-11-28_19-18-40/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00037</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00037_37_2021-11-28_19-18-40/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00038</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00038_38_2021-11-28_19-18-40/error.txt</td></tr>\n",
       "<tr><td>PPO_mon_fin_e6984_00039</td><td style=\"text-align: right;\">           1</td><td>/scratch/mc5851/ray_results/ALL/server_mon_fin_exp_0_Nov28_PPO_test/PPO_mon_fin_e6984_00039_39_2021-11-28_19-18-40/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [PPO_mon_fin_e6984_00000, PPO_mon_fin_e6984_00001, PPO_mon_fin_e6984_00002, PPO_mon_fin_e6984_00003, PPO_mon_fin_e6984_00004, PPO_mon_fin_e6984_00005, PPO_mon_fin_e6984_00006, PPO_mon_fin_e6984_00007, PPO_mon_fin_e6984_00008, PPO_mon_fin_e6984_00009, PPO_mon_fin_e6984_00010, PPO_mon_fin_e6984_00011, PPO_mon_fin_e6984_00012, PPO_mon_fin_e6984_00013, PPO_mon_fin_e6984_00014, PPO_mon_fin_e6984_00015, PPO_mon_fin_e6984_00016, PPO_mon_fin_e6984_00017, PPO_mon_fin_e6984_00018, PPO_mon_fin_e6984_00019, PPO_mon_fin_e6984_00020, PPO_mon_fin_e6984_00021, PPO_mon_fin_e6984_00022, PPO_mon_fin_e6984_00023, PPO_mon_fin_e6984_00024, PPO_mon_fin_e6984_00025, PPO_mon_fin_e6984_00026, PPO_mon_fin_e6984_00027, PPO_mon_fin_e6984_00028, PPO_mon_fin_e6984_00029, PPO_mon_fin_e6984_00030, PPO_mon_fin_e6984_00031, PPO_mon_fin_e6984_00032, PPO_mon_fin_e6984_00033, PPO_mon_fin_e6984_00034, PPO_mon_fin_e6984_00035, PPO_mon_fin_e6984_00036, PPO_mon_fin_e6984_00037, PPO_mon_fin_e6984_00038, PPO_mon_fin_e6984_00039])",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7c2b44570539>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m         }\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         analysis = tune.run(\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mALGO\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEXP_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mc5851/.env/lib/python3.8/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, loggers, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint, _remote)\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [PPO_mon_fin_e6984_00000, PPO_mon_fin_e6984_00001, PPO_mon_fin_e6984_00002, PPO_mon_fin_e6984_00003, PPO_mon_fin_e6984_00004, PPO_mon_fin_e6984_00005, PPO_mon_fin_e6984_00006, PPO_mon_fin_e6984_00007, PPO_mon_fin_e6984_00008, PPO_mon_fin_e6984_00009, PPO_mon_fin_e6984_00010, PPO_mon_fin_e6984_00011, PPO_mon_fin_e6984_00012, PPO_mon_fin_e6984_00013, PPO_mon_fin_e6984_00014, PPO_mon_fin_e6984_00015, PPO_mon_fin_e6984_00016, PPO_mon_fin_e6984_00017, PPO_mon_fin_e6984_00018, PPO_mon_fin_e6984_00019, PPO_mon_fin_e6984_00020, PPO_mon_fin_e6984_00021, PPO_mon_fin_e6984_00022, PPO_mon_fin_e6984_00023, PPO_mon_fin_e6984_00024, PPO_mon_fin_e6984_00025, PPO_mon_fin_e6984_00026, PPO_mon_fin_e6984_00027, PPO_mon_fin_e6984_00028, PPO_mon_fin_e6984_00029, PPO_mon_fin_e6984_00030, PPO_mon_fin_e6984_00031, PPO_mon_fin_e6984_00032, PPO_mon_fin_e6984_00033, PPO_mon_fin_e6984_00034, PPO_mon_fin_e6984_00035, PPO_mon_fin_e6984_00036, PPO_mon_fin_e6984_00037, PPO_mon_fin_e6984_00038, PPO_mon_fin_e6984_00039])"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\" Organize and Plot multi firm expers \"\"\"\n",
    "\n",
    "# global experiment name\n",
    "if len(exp_names) > 1:\n",
    "    EXP_LABEL = device + f\"_multiexp_\"\n",
    "    if TEST == True:\n",
    "        EXP_NAME = EXP_LABEL + ENV_LABEL + \"_test_\" + DATE + ALGO\n",
    "    else:\n",
    "        EXP_NAME = EXP_LABEL + ENV_LABEL + \"_run_\" + DATE + ALGO\n",
    "\n",
    "# create CSV with information on each experiment\n",
    "if SAVE_EXP_INFO:\n",
    "\n",
    "    exp_dict = {\n",
    "        \"n_agents\": n_firms_LIST,\n",
    "        \"exp_names\": exp_names,\n",
    "        \"exp_dirs\": exp_dirs,\n",
    "        \"trial_dirs\": trial_logdirs,\n",
    "        \"checkpoints\": checkpoints,\n",
    "        \"configs\": configs,\n",
    "        \"results_eval\": [\n",
    "            rewards_eval,\n",
    "            mu_ij_eval,\n",
    "            mu_agg_eval,\n",
    "            mu_ij_final_eval,\n",
    "            freq_p_adj_eval,\n",
    "            size_adj_eval,\n",
    "            std_log_c_eval,\n",
    "            profits_eval,\n",
    "        ],\n",
    "        \"results\": [\n",
    "            rewards,\n",
    "            mu_ij,\n",
    "            mu_agg,\n",
    "            mu_ij_final,\n",
    "            freq_p_adj,\n",
    "            size_adj,\n",
    "            std_log_c,\n",
    "            profits,\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        \"mu_ij\",\n",
    "        mu_ij_eval,\n",
    "        \"\\n\",\n",
    "        \"mu_agg\",\n",
    "        mu_agg_eval,\n",
    "        \"\\n\",\n",
    "        \"mu_ij_final\",\n",
    "        mu_ij_final_eval,\n",
    "        \"\\n\",\n",
    "        \"freq_p_adj:\",\n",
    "        freq_p_adj_eval,\n",
    "        \"\\n\",\n",
    "        \"size_adj\",\n",
    "        size_adj_eval,\n",
    "        \"\\n\",\n",
    "        \"std_log_c:\",\n",
    "        std_log_c_eval,\n",
    "    )\n",
    "\n",
    "    with open(OUTPUT_PATH_EXPERS + \"expINFO_\" + EXP_NAME + \".json\", \"w+\") as f:\n",
    "        json.dump(exp_dict, f)\n",
    "\n",
    "    # exp_df = pd.DataFrame(exp_dict)\n",
    "    # exp_df.to_csv(OUTPUT_PATH_EXPERS + \"exp_info\" + EXP_NAME + \".csv\")\n",
    "    print(OUTPUT_PATH_EXPERS + \"expINFO_\" + EXP_NAME + \".json\")\n",
    "\n",
    "# Plot and save progress\n",
    "if PLOT_PROGRESS:\n",
    "    for ind, n_firms in enumerate(n_firms_LIST):\n",
    "        for i in range(NUM_TRIALS):\n",
    "            learning_plot = sn.lineplot(\n",
    "                data=learning_dta[ind][i],\n",
    "                y=f\"discounted_rewards_trial_{i}\",\n",
    "                x=learning_dta[ind][i].index,\n",
    "            )\n",
    "        learning_plot = learning_plot.get_figure()\n",
    "        plt.ylabel(\"Discounted utility\")\n",
    "        plt.xlabel(\"Episodes (5 years)\")\n",
    "        # plt.legend(labels=[f\"trial {i}\" for i in range(NUM_TRIALS)])\n",
    "        learning_plot.savefig(\n",
    "            OUTPUT_PATH_FIGURES + \"progress_rewards\" + exp_names[ind] + \".png\"\n",
    "        )\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        for i in range(NUM_TRIALS):\n",
    "            learning_plot = sn.lineplot(\n",
    "                data=learning_dta[ind][i],\n",
    "                y=f\"mu_ij_trial_{i}\",\n",
    "                x=learning_dta[ind][i].index,\n",
    "            )\n",
    "        learning_plot = learning_plot.get_figure()\n",
    "        plt.ylabel(\"Average Markup\")\n",
    "        plt.xlabel(\"Episodes (5 years)\")\n",
    "        # plt.legend(labels=[f\"trial {i}\" for i in range(NUM_TRIALS)])\n",
    "        learning_plot.savefig(\n",
    "            OUTPUT_PATH_FIGURES + \"progress_mu_ij\" + exp_names[ind] + \".png\"\n",
    "        )\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        for i in range(NUM_TRIALS):\n",
    "            learning_plot = sn.lineplot(\n",
    "                data=learning_dta[ind][i],\n",
    "                y=f\"mu_ij_final_trial_{i}\",\n",
    "                x=learning_dta[ind][i].index,\n",
    "            )\n",
    "        learning_plot = learning_plot.get_figure()\n",
    "        plt.ylabel(\"Average Markup flexible stage\")\n",
    "        plt.xlabel(\"Episodes (5 years)\")\n",
    "        # plt.legend(labels=[f\"trial {i}\" for i in range(NUM_TRIALS)])\n",
    "        learning_plot.savefig(\n",
    "            OUTPUT_PATH_FIGURES + \"progress_mu_ij_final\" + exp_names[ind] + \".png\"\n",
    "        )\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        for i in range(NUM_TRIALS):\n",
    "            learning_plot = sn.lineplot(\n",
    "                data=learning_dta[ind][i],\n",
    "                y=f\"freq_p_adj_trial_{i}\",\n",
    "                x=learning_dta[ind][i].index,\n",
    "            )\n",
    "        learning_plot = learning_plot.get_figure()\n",
    "        plt.ylabel(\"Frequency of price adjustment\")\n",
    "        plt.xlabel(\"Episodes (10 years)\")\n",
    "        # plt.legend(labels=[f\"trial {i}\" for i in range(NUM_TRIALS)])\n",
    "        learning_plot.savefig(\n",
    "            OUTPUT_PATH_FIGURES + \"progress_freq_p_adj\" + exp_names[ind] + \".png\"\n",
    "        )\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        for i in range(NUM_TRIALS):\n",
    "            learning_plot = sn.lineplot(\n",
    "                data=learning_dta[ind][i],\n",
    "                y=f\"size_adj_trial_{i}\",\n",
    "                x=learning_dta[ind][i].index,\n",
    "            )\n",
    "        learning_plot = learning_plot.get_figure()\n",
    "        plt.ylabel(\"Size of adjustment\")\n",
    "        plt.xlabel(\"Episodes (10 years)\")\n",
    "        # plt.legend(labels=[f\"trial {i}\" for i in range(NUM_TRIALS)])\n",
    "        learning_plot.savefig(\n",
    "            OUTPUT_PATH_FIGURES + \"progress_size_adj\" + exp_names[ind] + \".png\"\n",
    "        )\n",
    "        plt.show()\n",
    "        plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\" Step 5 Run Analysis \"\"\"\n",
    "\n",
    "if RUN_ANALYSIS:\n",
    "    # If there is no training, import exp info\n",
    "    if not RUN_TRAINING:\n",
    "        with open(INFO_ANALYSIS) as f:\n",
    "            exp_dict = json.load(f)\n",
    "    # Choose weather you want leval results or live results\n",
    "    if EVAL_RESULTS:\n",
    "        results_data = exp_dict[\"results_eval\"]\n",
    "    else:\n",
    "        results_data = exp_dict[\"results\"]\n",
    "    exp_names = exp_dict[\"exp_names\"]\n",
    "    checkpoints = exp_dict[\"checkpoints\"][0]\n",
    "    results = {\n",
    "        \"Markups\": np.array(results_data[1][0]),\n",
    "        \"Agg. Markups\": np.array(results_data[2][0]),\n",
    "        \"Flexible Markups\": np.array(results_data[3][0]),\n",
    "        \"Freq. of Adj.\": np.array(results_data[4][0]),\n",
    "        \"Size of Adj.\": np.array(results_data[5][0]),\n",
    "        \"S.D. of log C\": np.array(results_data[6][0]),\n",
    "        \"Profits\": np.array(results_data[7][0]),\n",
    "    }\n",
    "\n",
    "    results_stats = {\n",
    "        \"Mean Markups\": np.mean(results[\"Markups\"]),\n",
    "        \"S.D. Markups\": np.std(results[\"Markups\"]),\n",
    "        \"Mean Agg. Markups\": np.mean(results[\"Agg. Markups\"]),\n",
    "        \"S.D. Agg. Markups\": np.std(results[\"Agg. Markups\"]),\n",
    "        \"Mean Flexible Markups\": np.mean(results[\"Flexible Markups\"]),\n",
    "        \"S.D. Flexible Markups\": np.std(results[\"Flexible Markups\"]),\n",
    "        \"Mean Freq. of Adj.\": np.mean(results[\"Freq. of Adj.\"]),\n",
    "        \"S.D. Freq. of Adj.\": np.std(results[\"Freq. of Adj.\"]),\n",
    "        \"Mean Size of Adj.\": np.mean(results[\"Size of Adj.\"]),\n",
    "        \"S.D. Size of Adj.\": np.std(results[\"Size of Adj.\"]),\n",
    "        \"Mean S.D. of log C\": np.mean(results[\"S.D. of log C\"]),\n",
    "        \"S.D. S.D. of log C\": np.std(results[\"S.D. of log C\"]),\n",
    "        \"Mean Profits\": np.mean(results[\"Profits\"]),\n",
    "        \"S.D. Profits\": np.std(results[\"Profits\"]),\n",
    "    }\n",
    "\n",
    "    # task, I one to calculate the index of the result that is closer in eucledian distance to a point that I give.\n",
    "    results_list = [\n",
    "        [\n",
    "            results[\"Markups\"][i],\n",
    "            results[\"Agg. Markups\"][i],\n",
    "            results[\"Flexible Markups\"][i],\n",
    "            results[\"Freq. of Adj.\"][i],\n",
    "            results[\"Size of Adj.\"][i],\n",
    "            results[\"S.D. of log C\"][i],\n",
    "        ]\n",
    "        for i in range(NUM_TRIALS)\n",
    "    ]\n",
    "    if CHKPT_SELECT_REF:\n",
    "\n",
    "        distance_agg = np.array(\n",
    "            [\n",
    "                (\n",
    "                    (results[\"Markups\"][i] - RESULTS_REF[0])\n",
    "                    / results_stats[\"S.D. Markups\"]\n",
    "                )\n",
    "                ** 2\n",
    "                + (\n",
    "                    (results[\"Freq. of Adj.\"][i] - RESULTS_REF[1])\n",
    "                    / results_stats[\"S.D. Freq. of Adj.\"]\n",
    "                )\n",
    "                ** 2\n",
    "                + (\n",
    "                    (results[\"Size of Adj.\"][i] - RESULTS_REF[2])\n",
    "                    / results_stats[\"S.D. Size of Adj.\"]\n",
    "                )\n",
    "                ** 2\n",
    "                + (\n",
    "                    (results[\"S.D. of log C\"][i] - RESULTS_REF[3])\n",
    "                    / results_stats[\"S.D. S.D. of log C\"]\n",
    "                )\n",
    "                ** 2\n",
    "                for i in range(NUM_TRIALS)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        selected_id = distance_agg.argmin()\n",
    "\n",
    "    if CHKPT_SELECT_MIN:\n",
    "        selected_id = results[\"Markups\"].argmin()\n",
    "\n",
    "    if CHKPT_SELECT_MAX:\n",
    "        selected_id = results[\"Markups\"].argmax()\n",
    "\n",
    "    if CHKPT_SELECT_MANUAL:\n",
    "        selected_id = CHKPT_id\n",
    "\n",
    "    selected_stats = results_list[selected_id]\n",
    "    print(\"Selected chekpoint;\", selected_stats)\n",
    "    INPUT_PATH_CHECKPOINT = checkpoints[selected_id]\n",
    "\n",
    "    print(\"results_stats:\", results_stats)\n",
    "    # Create statistics table\n",
    "\n",
    "    if PLOT_HIST:\n",
    "        for i, x in results.items():\n",
    "            plt.hist(x)\n",
    "            plt.title(i)\n",
    "            plt.savefig(\n",
    "                OUTPUT_PATH_FIGURES + \"hist_\" + f\"{i}\" + \"_\" + exp_names[0] + \".png\"\n",
    "            )\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "    \"\"\" Inspect Policy Functions \"\"\"\n",
    "\n",
    "    shutdown()\n",
    "    init(\n",
    "        num_cpus=12,\n",
    "        log_to_driver=False,\n",
    "    )\n",
    "\n",
    "    # register environment\n",
    "    env_label = \"mon_policy_finite\"\n",
    "    register_env(env_label, MonPolicyFinite)\n",
    "    config_algo = training_config.copy()\n",
    "    config_algo[\"explore\"] = False\n",
    "    trained_trainer = PPOTrainer(env=env_label, config=config_algo)\n",
    "    trained_trainer.restore(INPUT_PATH_CHECKPOINT)\n",
    "\n",
    "    \"\"\" Policy function with respect to own markup \"\"\"\n",
    "\n",
    "    markup = [1.2 + (i / 19)*(0.6) for i in range(20)]\n",
    "    if not OBS_IDSHOCK:\n",
    "        obs_reaction_lowmu = [\n",
    "        {\n",
    "            \"obs_ind\": np.array([markup[i], 1.2], dtype=np.float32,),\n",
    "            \"obs_agg\": np.array([1.165, math.e ** env.params[\"log_g_bar\"]], dtype=np.float32),\n",
    "            \"time\": 24,\n",
    "            \"flex_index\": 0,\n",
    "        }\n",
    "            for i in range(20)\n",
    "        ]\n",
    "        obs_reaction_medmu = [\n",
    "        {\n",
    "            \"obs_ind\": np.array([markup[i], selected_stats[0]], dtype=np.float32,),\n",
    "            \"obs_agg\": np.array([selected_stats[1], math.e ** env.params[\"log_g_bar\"]], dtype=np.float32),\n",
    "            \"time\": 24,\n",
    "            \"flex_index\": 0,\n",
    "        }\n",
    "            for i in range(20)\n",
    "        ]\n",
    "        obs_reaction_highmu = [\n",
    "        {\n",
    "            \"obs_ind\": np.array([markup[i], 1.5], dtype=np.float32,),\n",
    "            \"obs_agg\": np.array([selected_stats[1], math.e ** env.params[\"log_g_bar\"]], dtype=np.float32),\n",
    "            \"time\": 24,\n",
    "            \"flex_index\": 0,\n",
    "        }\n",
    "            for i in range(20)\n",
    "        ]\n",
    "    else:\n",
    "        obs_reaction_lowmu = [\n",
    "        {\n",
    "            \"obs_ind\": np.array([markup[i], 1.2, 1, 1], dtype=np.float32,),\n",
    "            \"obs_agg\": np.array([selected_stats[1], math.e ** env.params[\"log_g_bar\"]], dtype=np.float32),\n",
    "            \"time\": 24,\n",
    "            \"flex_index\": 0,\n",
    "        }\n",
    "            for i in range(20)\n",
    "        ]\n",
    "        obs_reaction_medmu = [\n",
    "        {\n",
    "            \"obs_ind\": np.array([markup[i], selected_stats[0], 1, 1], dtype=np.float32,),\n",
    "            \"obs_agg\": np.array([selected_stats[1], math.e ** env.params[\"log_g_bar\"]], dtype=np.float32),\n",
    "            \"time\": 24,\n",
    "            \"flex_index\": 0,\n",
    "        }\n",
    "            for i in range(20)\n",
    "        ]\n",
    "        obs_reaction_highmu = [\n",
    "        {\n",
    "            \"obs_ind\": np.array([markup[i], 1.5, 1, 1], dtype=np.float32,),\n",
    "            \"obs_agg\": np.array([selected_stats[1], math.e ** env.params[\"log_g_bar\"]], dtype=np.float32),\n",
    "            \"time\": 24,\n",
    "            \"flex_index\": 0,\n",
    "        }\n",
    "            for i in range(20)\n",
    "        ]\n",
    "\n",
    "    actions_reaction_lowmu = [\n",
    "        trained_trainer.compute_action(obs_reaction_lowmu[i], policy_id=\"firm_even\")\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    actions_reaction_medmu = [\n",
    "        trained_trainer.compute_action(obs_reaction_medmu[i], policy_id=\"firm_even\")\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    actions_reaction_highmu = [\n",
    "        trained_trainer.compute_action(obs_reaction_highmu[i], policy_id=\"firm_even\")\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    move_prob_lowmu = [(actions_reaction_lowmu[i][0] + 1) / 2 for i in range(20)]\n",
    "    reset_lowmu = [1 + (actions_reaction_lowmu[i][1] + 1) / 2 for i in range(20)]\n",
    "    move_prob_medmu = [(actions_reaction_medmu[i][0] + 1) / 2 for i in range(20)]\n",
    "    reset_medmu = [1 + (actions_reaction_medmu[i][1] + 1) / 2 for i in range(20)]\n",
    "    move_prob_highmu = [(actions_reaction_highmu[i][0] + 1) / 2 for i in range(20)]\n",
    "    reset_highmu = [1 + (actions_reaction_highmu[i][1] + 1) / 2 for i in range(20)]\n",
    "\n",
    "    x = markup\n",
    "    plt.plot(x, move_prob_lowmu, '-o')\n",
    "    plt.plot(x, move_prob_medmu,'-+')\n",
    "    plt.plot(x, move_prob_highmu, '-x')\n",
    "    plt.axvline(x=1.2, linestyle='--')\n",
    "    plt.axvline(x=selected_stats[0], linestyle='--')\n",
    "    plt.axvline(x=1.5, linestyle='--')\n",
    "    plt.legend(\n",
    "        [\"Low Competition Markup\", \"Med Competition Markup\", \"High Competition Markup\"]\n",
    "    )\n",
    "    plt.xlabel(\"Own Markup\")\n",
    "    plt.ylabel(\"Prob. of Adjustment\")\n",
    "    # plt.title(\"Probability of Adjustment\")\n",
    "    # plt.title(\"MIN\")\n",
    "\n",
    "    plt.savefig(OUTPUT_PATH_FIGURES + \"polown_prob_\" + \"_\" + exp_names[0] + \"_min\" + \".png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(x, reset_lowmu,'-o')\n",
    "    plt.plot(x, reset_medmu,'-+')\n",
    "    plt.plot(x, reset_highmu,'-x')\n",
    "    plt.axvline(x=1.2, linestyle='--')\n",
    "    plt.axvline(x=selected_stats[0], linestyle='--')\n",
    "    plt.axvline(x=1.5, linestyle='--')\n",
    "    plt.legend(\n",
    "        [\"Low Competition Markup\", \"Med Competition Markup\", \"High Competition Markup\"]\n",
    "    )\n",
    "    plt.xlabel(\"Own Markup\")\n",
    "    plt.ylabel(\"Reset Markup\")\n",
    "    # plt.title(\"Reset Markup\")\n",
    "    # plt.title(\"MIN\")\n",
    "    plt.savefig(OUTPUT_PATH_FIGURES + \"polown_reset_\" + \"_\" + exp_names[0] + \"_min\" + \".png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    reg_react_prob_low = linregress(markup, move_prob_lowmu)\n",
    "    reg_react_prob_med = linregress(markup, move_prob_medmu)\n",
    "    reg_react_prob_high = linregress(markup, move_prob_highmu)\n",
    "    reg_react_reset_low = linregress(markup, reset_lowmu)\n",
    "    reg_react_reset_med = linregress(markup, reset_medmu)\n",
    "    reg_react_reset_high = linregress(markup, reset_highmu)\n",
    "    slope_react_prob_low = reg_react_prob_low[0]\n",
    "    slope_react_prob_med = reg_react_prob_med[0]\n",
    "    slope_react_prob_high = reg_react_prob_high[0]\n",
    "    slope_react_reset_low = reg_react_reset_low[0]\n",
    "    slope_react_reset_med = reg_react_reset_med[0]\n",
    "    slope_react_reset_high = reg_react_reset_high[0]\n",
    "\n",
    "    print(\"Slope of own react, low\", [slope_react_prob_low, slope_react_reset_low])\n",
    "    print(\"Slope of own react, med\", [slope_react_prob_med, slope_react_reset_med])\n",
    "    print(\"Slope of own react, high\", [slope_react_prob_high, slope_react_reset_high])\n",
    "\n",
    "    \"\"\" Policy Function with respect to monetary policy. \"\"\"\n",
    "\n",
    "    mon_policy = [0.75       \n",
    "        + (i / 19) * 0.5\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    # print(mon_policy)\n",
    "    if not OBS_IDSHOCK:\n",
    "        obs_monpol_lowmu = [\n",
    "        {\n",
    "            \"obs_ind\": np.array([1.2, selected_stats[0]],dtype=np.float32),\n",
    "            \"obs_agg\": np.array([selected_stats[1], mon_policy[i]], dtype=np.float32),\n",
    "            \"time\": 24,\n",
    "            \"flex_index\": 0,\n",
    "        }\n",
    "            for i in range(20)\n",
    "        ]\n",
    "        obs_monpol_medmu = [\n",
    "        {\n",
    "            \"obs_ind\": np.array([selected_stats[0], selected_stats[0]],dtype=np.float32),\n",
    "            \"obs_agg\": np.array([selected_stats[1], mon_policy[i]], dtype=np.float32),\n",
    "            \"time\": 24,\n",
    "            \"flex_index\": 0,\n",
    "        }\n",
    "            for i in range(20)\n",
    "        ]\n",
    "        obs_monpol_highmu = [\n",
    "        {\n",
    "            \"obs_ind\": np.array([1.5, selected_stats[0]],dtype=np.float32),\n",
    "            \"obs_agg\": np.array([selected_stats[1], mon_policy[i]], dtype=np.float32),\n",
    "            \"time\": 24,\n",
    "            \"flex_index\": 0,\n",
    "        }\n",
    "            for i in range(20)\n",
    "        ]\n",
    "    else:\n",
    "        obs_monpol_lowmu = [\n",
    "        {\n",
    "            \"obs_ind\": np.array([1.2, selected_stats[0],1,1],dtype=np.float32),\n",
    "            \"obs_agg\": np.array([selected_stats[1], mon_policy[i]], dtype=np.float32),\n",
    "            \"time\": 24,\n",
    "            \"flex_index\": 0,\n",
    "        }\n",
    "            for i in range(20)\n",
    "        ]\n",
    "        obs_monpol_medmu = [\n",
    "        {\n",
    "            \"obs_ind\": np.array([selected_stats[0], selected_stats[0],1,1],dtype=np.float32),\n",
    "            \"obs_agg\": np.array([selected_stats[1], mon_policy[i]], dtype=np.float32),\n",
    "            \"time\": 24,\n",
    "            \"flex_index\": 0,\n",
    "        }\n",
    "            for i in range(20)\n",
    "        ]\n",
    "        obs_monpol_highmu = [\n",
    "        {\n",
    "            \"obs_ind\": np.array([1.5, selected_stats[0],1,1],dtype=np.float32),\n",
    "            \"obs_agg\": np.array([selected_stats[1], mon_policy[i]], dtype=np.float32),\n",
    "            \"time\": 24,\n",
    "            \"flex_index\": 0,\n",
    "        }\n",
    "            for i in range(20)\n",
    "        ]\n",
    "\n",
    "    actions_monpol_lowmu = [\n",
    "        trained_trainer.compute_action(obs_monpol_lowmu[i], policy_id=\"firm_even\")\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    actions_monpol_medmu = [\n",
    "        trained_trainer.compute_action(obs_monpol_medmu[i], policy_id=\"firm_even\")\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    actions_monpol_highmu = [\n",
    "        trained_trainer.compute_action(obs_monpol_highmu[i], policy_id=\"firm_even\")\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    move_prob_lowmu = [(actions_monpol_lowmu[i][0] + 1) / 2 for i in range(20)]\n",
    "    reset_lowmu = [1 + (actions_monpol_lowmu[i][1] + 1) / 2 for i in range(20)]\n",
    "    move_prob_medmu = [(actions_monpol_medmu[i][0] + 1) / 2 for i in range(20)]\n",
    "    reset_medmu = [1 + (actions_monpol_medmu[i][1] + 1) / 2 for i in range(20)]\n",
    "    move_prob_highmu = [(actions_monpol_highmu[i][0] + 1) / 2 for i in range(20)]\n",
    "    reset_highmu = [1 + (actions_monpol_highmu[i][1] + 1) / 2 for i in range(20)]\n",
    "    # print(actions_monpol_lowmu, \"\\n\",\n",
    "    #     actions_monpol_highmu)\n",
    "    x = mon_policy\n",
    "    plt.plot(x, move_prob_lowmu, '-o')\n",
    "    # plt.plot(x,move_prob_medmu)\n",
    "    plt.plot(x, move_prob_highmu,'-+')\n",
    "    plt.axvline(x=1.0212, linestyle='--')\n",
    "    plt.legend([\"Low Markup Firms\", \"High Markup Firms\"])\n",
    "    plt.xlabel(\"Money Growth\")\n",
    "    plt.ylabel(\"Prob. of Adjustment\")\n",
    "    # plt.title(\"Effect of money growth on Prob. of Adj.\")\n",
    "    # plt.title(\"MIN\")\n",
    "    plt.savefig(OUTPUT_PATH_FIGURES + \"polmon_prob_\" + exp_names[0] + \"_min\" + \".png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(x, reset_lowmu,'-o')\n",
    "    # plt.plot(x,reset_medmu)\n",
    "    plt.plot(x, reset_highmu,'-+')\n",
    "    plt.axvline(x=1.0212, linestyle='--')\n",
    "    plt.legend([\"Low Markup Firms\", \"High Markup Firms\"])\n",
    "    plt.xlabel(\"Money Growth\")\n",
    "    plt.ylabel(\"Reset Markup\")\n",
    "\n",
    "    # plt.title(\"Effec of money growth on Size of Adj.\")\n",
    "    # plt.title(\"MIN\")\n",
    "    plt.savefig(OUTPUT_PATH_FIGURES + \"polmon_reset_\" + exp_names[0] + \"_min\" + \".png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    reg_mon_prob_low = linregress(mon_policy, move_prob_lowmu)\n",
    "    slope_mon_prob_low = reg_mon_prob_low[0]\n",
    "    reg_mon_prob_high = linregress(mon_policy, move_prob_highmu)\n",
    "    slope_mon_prob_high = reg_mon_prob_high[0]\n",
    "\n",
    "    reg_mon_reset_low = linregress(mon_policy, reset_lowmu)\n",
    "    slope_mon_reset_low = reg_mon_prob_low[0]\n",
    "    reg_mon_reset_high = linregress(mon_policy, reset_highmu)\n",
    "    slope_mon_reset_high = reg_mon_reset_high[0]\n",
    "\n",
    "    print(\"Slope to mon, low\", [slope_mon_prob_low, slope_mon_reset_low])\n",
    "    print(\"Slope to mon, high\", [slope_mon_prob_high, slope_mon_reset_high])\n",
    "\n",
    "    \"\"\" Reaction function to Competition Markup with constant z \"\"\"\n",
    "\n",
    "    markup = [1 + (i / 19) for i in range(20)]\n",
    "    if not OBS_IDSHOCK:\n",
    "        obs_reaction_lowmu = [\n",
    "            {\n",
    "                \"obs_ind\": np.array([1.1, markup[i]], dtype=np.float32),\n",
    "                \"obs_agg\": np.array(\n",
    "                    [selected_stats[1], math.e ** env.params[\"log_g_bar\"]],\n",
    "                    dtype=np.float32,\n",
    "                ),\n",
    "                \"time\": 24,\n",
    "                \"flex_index\": 0,\n",
    "            }\n",
    "            for i in range(20)\n",
    "        ]\n",
    "\n",
    "        obs_reaction_medmu = [\n",
    "            {\n",
    "                \"obs_ind\": np.array([selected_stats[0], markup[i]], dtype=np.float32),\n",
    "                \"obs_agg\": np.array(\n",
    "                    [selected_stats[1], math.e ** env.params[\"log_g_bar\"]],\n",
    "                    dtype=np.float32,\n",
    "                ),\n",
    "                \"time\": 24,\n",
    "                \"flex_index\": 0,\n",
    "            }\n",
    "            for i in range(20)\n",
    "        ]\n",
    "\n",
    "        obs_reaction_highmu = [\n",
    "            {\n",
    "                \"obs_ind\": np.array([1.5, markup[i]], dtype=np.float32),\n",
    "                \"obs_agg\": np.array(\n",
    "                    [selected_stats[1], math.e ** env.params[\"log_g_bar\"]],\n",
    "                    dtype=np.float32,\n",
    "                ),\n",
    "                \"time\": 24,\n",
    "                \"flex_index\": 0,\n",
    "            }\n",
    "            for i in range(20)\n",
    "        ]\n",
    "\n",
    "    else:\n",
    "        obs_reaction_lowmu = [\n",
    "            {\n",
    "                \"obs_ind\": np.array([1.1, markup[i], 1, 1], dtype=np.float32),\n",
    "                \"obs_agg\": np.array(\n",
    "                    [selected_stats[1], math.e ** env.params[\"log_g_bar\"]],\n",
    "                    dtype=np.float32,\n",
    "                ),\n",
    "                \"time\": 24,\n",
    "                \"flex_index\": 0,\n",
    "            }\n",
    "            for i in range(20)\n",
    "        ]\n",
    "\n",
    "        obs_reaction_medmu = [\n",
    "            {\n",
    "                \"obs_ind\": np.array([selected_stats[0], markup[i], 1, 1], dtype=np.float32),\n",
    "                \"obs_agg\": np.array(\n",
    "                    [selected_stats[1], math.e ** env.params[\"log_g_bar\"]],\n",
    "                    dtype=np.float32,\n",
    "                ),\n",
    "                \"time\": 24,\n",
    "                \"flex_index\": 0,\n",
    "            }\n",
    "            for i in range(20)\n",
    "        ]\n",
    "\n",
    "        obs_reaction_highmu = [\n",
    "            {\n",
    "                \"obs_ind\": np.array([1.5, markup[i], 1, 1], dtype=np.float32),\n",
    "                \"obs_agg\": np.array(\n",
    "                    [selected_stats[1], math.e ** env.params[\"log_g_bar\"]],\n",
    "                    dtype=np.float32,\n",
    "                ),\n",
    "                \"time\": 24,\n",
    "                \"flex_index\": 0,\n",
    "            }\n",
    "            for i in range(20)\n",
    "        ]\n",
    "\n",
    "    actions_reaction_lowmu = [\n",
    "        trained_trainer.compute_action(obs_reaction_lowmu[i], policy_id=\"firm_even\")\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    actions_reaction_medmu = [\n",
    "        trained_trainer.compute_action(obs_reaction_medmu[i], policy_id=\"firm_even\")\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    actions_reaction_highmu = [\n",
    "        trained_trainer.compute_action(obs_reaction_highmu[i], policy_id=\"firm_even\")\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    move_prob_lowmu = [(actions_reaction_lowmu[i][0] + 1) / 2 for i in range(20)]\n",
    "    reset_lowmu = [1 + (actions_reaction_lowmu[i][1] + 1) / 2 for i in range(20)]\n",
    "    move_prob_medmu = [(actions_reaction_medmu[i][0] + 1) / 2 for i in range(20)]\n",
    "    reset_medmu = [1 + (actions_reaction_medmu[i][1] + 1) / 2 for i in range(20)]\n",
    "    move_prob_highmu = [(actions_reaction_highmu[i][0] + 1) / 2 for i in range(20)]\n",
    "    reset_highmu = [1 + (actions_reaction_highmu[i][1] + 1) / 2 for i in range(20)]\n",
    "\n",
    "    x = markup\n",
    "    plt.plot(x, move_prob_lowmu, '-o')\n",
    "    plt.plot(x, move_prob_medmu,'-+')\n",
    "    plt.plot(x, move_prob_highmu, '-x')\n",
    "    plt.legend([\"Low Markup Firms\", \"Med Markup Firms\", \"High Markup Firms\"])\n",
    "    plt.xlabel(\"Markup of Competition\")\n",
    "    plt.ylabel(\"Prob. of Adjustment\")\n",
    "    plt.title(\"Reaction Function - Probability of Adjustment\")\n",
    "    plt.savefig(OUTPUT_PATH_FIGURES + \"polreact_prob_\" + exp_names[0] + \".png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(x, reset_lowmu, '-o')\n",
    "    plt.plot(x, reset_medmu,'-+')\n",
    "    plt.plot(x, reset_highmu, '-x')\n",
    "    plt.legend([\"Low Markup Firms\", \"Med Markup Firms\", \"High Markup Firms\"])\n",
    "    plt.xlabel(\"Markup of Competition\")\n",
    "    plt.ylabel(\"Reset Markup\")\n",
    "    plt.title(\"Reaction Function - Reset Markup\")\n",
    "    plt.savefig(OUTPUT_PATH_FIGURES + \"polreact_reset_\" + exp_names[0] + \".png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    reg_react_prob_low = linregress(markup, move_prob_lowmu)\n",
    "    reg_react_prob_med = linregress(markup, move_prob_medmu)\n",
    "    reg_react_prob_high = linregress(markup, move_prob_highmu)\n",
    "    reg_react_reset_low = linregress(markup, reset_lowmu)\n",
    "    reg_react_reset_med = linregress(markup, reset_medmu)\n",
    "    reg_react_reset_high = linregress(markup, reset_highmu)\n",
    "    slope_react_prob_low = reg_react_prob_low[0]\n",
    "    slope_react_prob_med = reg_react_prob_med[0]\n",
    "    slope_react_prob_high = reg_react_prob_high[0]\n",
    "    slope_react_reset_low = reg_react_reset_low[0]\n",
    "    slope_react_reset_med = reg_react_reset_med[0]\n",
    "    slope_react_reset_high = reg_react_reset_high[0]\n",
    "\n",
    "    print(\"Slope of react, low\", [slope_react_prob_low, slope_react_reset_low])\n",
    "    print(\"Slope of react, med\", [slope_react_prob_med, slope_react_reset_med])\n",
    "    print(\"Slope of react, high\", [slope_react_prob_high, slope_react_reset_high])\n",
    "\n",
    "    \"\"\" Reaction Function to comepition markup with changing z \"\"\"\n",
    "    # markup = [1 + (i / 19) for i in range(20)]\n",
    "    if OBS_IDSHOCK:\n",
    "        markup_z = [\n",
    "            1.4\n",
    "            / (\n",
    "                math.e ** env.params[\"log_g_bar\"]\n",
    "                * math.e ** (4 * env.params[\"sigma_z\"])\n",
    "            )\n",
    "            + (i / 19)\n",
    "            * (\n",
    "                1.4\n",
    "                / (\n",
    "                    math.e ** env.params[\"log_g_bar\"]\n",
    "                    * math.e ** (-4 * env.params[\"sigma_z\"])\n",
    "                )\n",
    "                - 1.4\n",
    "                / (\n",
    "                    math.e ** env.params[\"log_g_bar\"]\n",
    "                    * math.e ** (4 * env.params[\"sigma_z\"])\n",
    "                )\n",
    "            )\n",
    "            for i in range(20)\n",
    "        ]\n",
    "        z = [\n",
    "            math.e ** (4 * env.params[\"sigma_z\"])\n",
    "            + i\n",
    "            / 19\n",
    "            * (\n",
    "                math.e ** (-4 * env.params[\"sigma_z\"])\n",
    "                - math.e ** (4 * env.params[\"sigma_z\"])\n",
    "            )\n",
    "            for i in range(20)\n",
    "        ]\n",
    "\n",
    "        obs_reaction_zshock = [\n",
    "            {\n",
    "                \"obs_ind\": np.array([selected_stats[0], markup_z[i], 1, z[i]], dtype=np.float32),\n",
    "                \"obs_agg\": np.array(\n",
    "                    [selected_stats[1], math.e ** env.params[\"log_g_bar\"]],\n",
    "                    dtype=np.float32,\n",
    "                ),\n",
    "                \"time\": 24,\n",
    "                \"flex_index\": 0,\n",
    "            }\n",
    "            for i in range(20)\n",
    "        ]\n",
    "\n",
    "        obs_reaction_stratdev = [\n",
    "            {\n",
    "                \"obs_ind\": np.array([selected_stats[0], markup_z[i], 1, 1], dtype=np.float32),\n",
    "                \"obs_agg\": np.array(\n",
    "                    [selected_stats[1], math.e ** env.params[\"log_g_bar\"]],\n",
    "                    dtype=np.float32,\n",
    "                ),\n",
    "                \"time\": 24,\n",
    "                \"flex_index\": 0,\n",
    "            }\n",
    "            for i in range(20)\n",
    "        ]\n",
    "\n",
    "        actions_reaction_zshock = [\n",
    "            trained_trainer.compute_action(\n",
    "                obs_reaction_zshock[i], policy_id=\"firm_even\"\n",
    "            )\n",
    "            for i in range(20)\n",
    "        ]\n",
    "        actions_reaction_stratdev = [\n",
    "            trained_trainer.compute_action(\n",
    "                obs_reaction_stratdev[i], policy_id=\"firm_even\"\n",
    "            )\n",
    "            for i in range(20)\n",
    "        ]\n",
    "\n",
    "        move_prob_zshock = [(actions_reaction_zshock[i][0] + 1) / 2 for i in range(20)]\n",
    "        reset_zshock = [1 + (actions_reaction_zshock[i][1] + 1) / 2 for i in range(20)]\n",
    "        move_prob_stratdev = [\n",
    "            (actions_reaction_stratdev[i][0] + 1) / 2 for i in range(20)\n",
    "        ]\n",
    "        reset_stratdev = [\n",
    "            1 + (actions_reaction_stratdev[i][1] + 1) / 2 for i in range(20)\n",
    "        ]\n",
    "\n",
    "        x = markup_z\n",
    "        plt.plot(x, move_prob_zshock,'-o')\n",
    "        plt.plot(x, move_prob_stratdev,'-+')\n",
    "        plt.legend([\"Z shock to com.\", \"Strat. deviation of com.\"])\n",
    "        plt.xlabel(\"Markup of Competition\")\n",
    "        plt.ylabel(\"Prob. of Adjustment\")\n",
    "        plt.title(\"Reaction to z shock vs strat deviation - Probability of Adjustment\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        plt.plot(x, reset_zshock,'-o')\n",
    "        plt.plot(x, reset_stratdev,'-+')\n",
    "        plt.legend([\"Z shock to com.\", \"Strat. deviation of com.\"])\n",
    "        plt.xlabel(\"Markup of Competition\")\n",
    "        plt.ylabel(\"Reset Markup\")\n",
    "        plt.title(\"Reaction to z shock vs strat deviation - Reset Markup\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        reg_react_prob_zshock = linregress(markup_z, move_prob_zshock)\n",
    "        reg_react_reset_zshock = linregress(markup_z, reset_zshock)\n",
    "        slope_react_prob_zshock = reg_react_prob_zshock[0]\n",
    "        slope_react_reset_zshock = reg_react_reset_zshock[0]\n",
    "\n",
    "        reg_react_prob_stratdev = linregress(markup_z, move_prob_stratdev)\n",
    "        reg_react_reset_stratdev = linregress(markup_z, reset_stratdev)\n",
    "        slope_react_prob_stratdev = reg_react_prob_stratdev[0]\n",
    "        slope_react_reset_stratdev = reg_react_reset_stratdev[0]\n",
    "\n",
    "        print(\n",
    "            \"Slope of react to z shock\",\n",
    "            [slope_react_prob_zshock, slope_react_reset_zshock],\n",
    "        )\n",
    "        print(\n",
    "            \"Slope of react to strat. deviation\",\n",
    "            [slope_react_prob_stratdev, slope_react_reset_stratdev],\n",
    "        )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\" Simulate Episodes and Calculate Regressions\"\"\"\n",
    "\n",
    "shutdown()\n",
    "init(\n",
    "    # num_cpus=12,\n",
    "    log_to_driver=False,\n",
    ")\n",
    "# register environment\n",
    "env_label = \"mon_policy_finite\"\n",
    "register_env(env_label, MonPolicyFinite)\n",
    "# We instantiate the environment to extract information.\n",
    "\"\"\" CHANGE HERE \"\"\"\n",
    "env_config_simul = env_config_eval.copy()\n",
    "env_config_simul[\"random_eval\"] = False\n",
    "env_config_noagg = env_config_simul.copy()\n",
    "env_config_noagg[\"no_agg\"] = True\n",
    "env_config_noagg = env_config_eval.copy()\n",
    "env_config_noagg[\"no_agg\"] = True\n",
    "env = MonPolicyFinite(env_config_simul)\n",
    "env_noagg = MonPolicyFinite(env_config_noagg)\n",
    "\n",
    "\"\"\" Restore trainer \"\"\"\n",
    "\n",
    "# restore the trainer\n",
    "\n",
    "trained_trainer = PPOTrainer(env=env_label, config=config_algo)\n",
    "trained_trainer.restore(INPUT_PATH_CHECKPOINT)\n",
    "\n",
    "\"\"\" Simulate an episode (SIMUL_PERIODS timesteps) \"\"\"\n",
    "profits_list = []\n",
    "mu_ij_list = []\n",
    "mu_ij_final_list = []\n",
    "freq_p_adj_list = []\n",
    "size_adj_list = []\n",
    "freq_adj_lowmu_list = []\n",
    "freq_adj_highmu_list = []\n",
    "size_adj_list = []\n",
    "size_adj_lowmu_list = []\n",
    "size_adj_highmu_list = []\n",
    "\n",
    "log_c_list = []\n",
    "epsilon_g_list = []\n",
    "\n",
    "profits_list_noagg = []\n",
    "mu_ij_list_noagg = []\n",
    "freq_p_adj_list_noagg = []\n",
    "freq_adj_lowmu_list_noagg = []\n",
    "freq_adj_highmu_list_noagg = []\n",
    "size_adj_list_noagg = []\n",
    "size_adj_lowmu_list_noagg = []\n",
    "size_adj_highmu_list_noagg = []\n",
    "log_c_list_noagg = []\n",
    "\n",
    "log_c_filt_list = []\n",
    "freq_adj_lowmu_filt_list = []\n",
    "freq_adj_highmu_filt_list = []\n",
    "size_adj_lowmu_filt_list = []\n",
    "size_adj_highmu_filt_list = []\n",
    "\n",
    "# loop with agg\n",
    "obs = env.reset()\n",
    "obs_noagg = env_noagg.reset()\n",
    "for t in range(SIMUL_EPISODES * ENV_HORIZON):\n",
    "    if t % env.horizon == 0:\n",
    "        seed = random.randrange(100000)\n",
    "        env.seed_eval = seed\n",
    "        env_noagg.seed_eval = seed\n",
    "        print(\"time:\", t)\n",
    "        obs = env.reset()\n",
    "        obs_noagg = env_noagg.reset()\n",
    "    action = {\n",
    "        i: trained_trainer.compute_action(obs[i], policy_id=\"firm_even\")\n",
    "        if i % 2 == 0\n",
    "        else trained_trainer.compute_action(obs[i], policy_id=\"firm_odd\")\n",
    "        for i in range(env.n_agents)\n",
    "    }\n",
    "    action_noagg = {\n",
    "        i: trained_trainer.compute_action(obs_noagg[i], policy_id=\"firm_even\")\n",
    "        if i % 2 == 0\n",
    "        else trained_trainer.compute_action(obs_noagg[i], policy_id=\"firm_odd\")\n",
    "        for i in range(env.n_agents)\n",
    "    }\n",
    "\n",
    "    obs, rew, done, info = env.step(action)\n",
    "    obs_noagg, rew_noagg, done_noagg, info_noagg = env_noagg.step(action_noagg)\n",
    "\n",
    "    if t % env.horizon < NO_FLEX_HORIZON:\n",
    "        profits_list.append(info[0][\"mean_profits\"])\n",
    "        mu_ij_list.append(info[0][\"mean_mu_ij\"])\n",
    "        freq_p_adj_list.append(info[0][\"move_freq\"])\n",
    "        freq_adj_lowmu_list.append(info[0][\"move_freq_lowmu\"])\n",
    "        freq_adj_highmu_list.append(info[0][\"move_freq_highmu\"])\n",
    "        size_adj_list.append(info[0][\"mean_p_change\"])\n",
    "        size_adj_lowmu_list.append(info[0][\"size_adj_lowmu\"])\n",
    "        size_adj_highmu_list.append(info[0][\"size_adj_highmu\"])\n",
    "        log_c_list.append(info[0][\"log_c\"])\n",
    "        epsilon_g_list.append(env.epsilon_g)\n",
    "        profits_list_noagg.append(info_noagg[0][\"mean_profits\"])\n",
    "        mu_ij_list_noagg.append(info_noagg[0][\"mean_mu_ij\"])\n",
    "        freq_p_adj_list_noagg.append(info_noagg[0][\"move_freq\"])\n",
    "        freq_adj_lowmu_list_noagg.append(info_noagg[0][\"move_freq_lowmu\"])\n",
    "        freq_adj_highmu_list_noagg.append(info_noagg[0][\"move_freq_highmu\"])\n",
    "        size_adj_list_noagg.append(info_noagg[0][\"mean_p_change\"])\n",
    "        size_adj_lowmu_list_noagg.append(info_noagg[0][\"size_adj_lowmu\"])\n",
    "        size_adj_highmu_list_noagg.append(info_noagg[0][\"size_adj_highmu\"])\n",
    "        log_c_list_noagg.append(info_noagg[0][\"log_c\"])\n",
    "        log_c_filt_list.append(log_c_list[-1] - log_c_list_noagg[-1])\n",
    "        freq_adj_lowmu_filt_list.append(\n",
    "            freq_adj_lowmu_list[-1] - freq_adj_lowmu_list_noagg[-1]\n",
    "        )\n",
    "        freq_adj_highmu_filt_list.append(\n",
    "            freq_adj_highmu_list[-1] - freq_adj_highmu_list_noagg[-1]\n",
    "        )\n",
    "        size_adj_lowmu_filt_list.append(\n",
    "            size_adj_lowmu_list[-1] - size_adj_lowmu_list_noagg[-1]\n",
    "        )\n",
    "        size_adj_highmu_filt_list.append(\n",
    "            size_adj_highmu_list[-1] - size_adj_highmu_list_noagg[-1]\n",
    "        )\n",
    "    if t % env.horizon > env.horizon - env.final_stage:\n",
    "        mu_ij_final_list.append(info[0][\"mean_mu_ij\"])\n",
    "\n",
    "\"\"\" STEP 4, PLOT IRS and PROCESS RESULTS\"\"\"\n",
    "\n",
    "simul_results_dict = {\n",
    "    \"Mean Profits\": [],\n",
    "    \"S.D. Profits\": [],\n",
    "    \"Max Profits\": [],\n",
    "    \"Min Profits\": [],\n",
    "    \"Mean Markups\": [],\n",
    "    \"S.D. Markups\": [],\n",
    "    \"Max Markups\": [],\n",
    "    \"Min Markups\": [],\n",
    "    \"Mean Freq. of Adj.\": [],\n",
    "    \"S.D. Freq. of Adj.\": [],\n",
    "    \"Max Freq. of Adj.\": [],\n",
    "    \"Min Freq. of Adj.\": [],\n",
    "    \"Mean Size of Adj.\": [],\n",
    "    \"S.D. Size of Adj.\": [],\n",
    "    \"Max Size of Adj.\": [],\n",
    "    \"Min Size of Adj.\": [],\n",
    "    \"S.D. log C\": [],\n",
    "    \"Mean Flex. Markup\": [],\n",
    "    \"IRs\": [],\n",
    "    \"cum_IRs\": [],\n",
    "}\n",
    "epsilon_g_pereps = [\n",
    "    epsilon_g_list[i * NO_FLEX_HORIZON : i * NO_FLEX_HORIZON + NO_FLEX_HORIZON]\n",
    "    for i in range(SIMUL_EPISODES)\n",
    "]\n",
    "log_c_filt_pereps = [\n",
    "    log_c_filt_list[i * NO_FLEX_HORIZON : i * NO_FLEX_HORIZON + NO_FLEX_HORIZON]\n",
    "    for i in range(SIMUL_EPISODES)\n",
    "]\n",
    "freq_adj_lowmu_pereps = [\n",
    "    freq_adj_lowmu_filt_list[\n",
    "        i * NO_FLEX_HORIZON : i * NO_FLEX_HORIZON + NO_FLEX_HORIZON\n",
    "    ]\n",
    "    for i in range(SIMUL_EPISODES)\n",
    "]\n",
    "freq_adj_highmu_pereps = [\n",
    "    freq_adj_highmu_filt_list[\n",
    "        i * NO_FLEX_HORIZON : i * NO_FLEX_HORIZON + NO_FLEX_HORIZON\n",
    "    ]\n",
    "    for i in range(SIMUL_EPISODES)\n",
    "]\n",
    "size_adj_lowmu_pereps = [\n",
    "    size_adj_lowmu_filt_list[\n",
    "        i * NO_FLEX_HORIZON : i * NO_FLEX_HORIZON + NO_FLEX_HORIZON\n",
    "    ]\n",
    "    for i in range(SIMUL_EPISODES)\n",
    "]\n",
    "size_adj_highmu_pereps = [\n",
    "    size_adj_highmu_filt_list[\n",
    "        i * NO_FLEX_HORIZON : i * NO_FLEX_HORIZON + NO_FLEX_HORIZON\n",
    "    ]\n",
    "    for i in range(SIMUL_EPISODES)\n",
    "]\n",
    "delta_log_c_pereps = [\n",
    "    [j - i for i, j in zip(log_c_filt_pereps[k][:-1], log_c_filt_pereps[k][1:])]\n",
    "    for k in range(SIMUL_EPISODES)\n",
    "]\n",
    "# print(\"log_c_filt:\", log_c_filt_list, \"\\n\",\n",
    "#     #\"delta_log_c:\", delta_log_c,\n",
    "#     \"\\n\"\n",
    "print(\n",
    "    \"corr betweeen cons:\",\n",
    "    np.corrcoef(log_c_list, log_c_list_noagg),\n",
    ")\n",
    "plt.plot(log_c_filt_list)\n",
    "plt.title(\"A. Log C filtered\")\n",
    "# plt.show()\n",
    "plt.close()\n",
    "\n",
    "IRs = [0 for t in range(13)]\n",
    "IRs_freqlow = [0 for t in range(13)]\n",
    "IRs_freqhigh = [0 for t in range(13)]\n",
    "IRs_sizelow = [0 for t in range(13)]\n",
    "IRs_sizehigh = [0 for t in range(13)]\n",
    "for t in range(0, 13):\n",
    "    epsilon_g_pereps_reg = [\n",
    "        epsilon_g_pereps[i][: -(t + 1)] for i in range(SIMUL_EPISODES)\n",
    "    ]\n",
    "    delta_log_c_pereps_reg = [\n",
    "        delta_log_c_pereps[i][t:] for i in range(SIMUL_EPISODES)\n",
    "    ]\n",
    "    freq_adj_lowmu_pereps_reg = [\n",
    "        freq_adj_lowmu_pereps[i][t:] for i in range(SIMUL_EPISODES)\n",
    "    ]\n",
    "    freq_adj_highmu_pereps_reg = [\n",
    "        freq_adj_highmu_pereps[i][t:] for i in range(SIMUL_EPISODES)\n",
    "    ]\n",
    "    size_adj_lowmu_pereps_reg = [\n",
    "        size_adj_lowmu_pereps[i][t:] for i in range(SIMUL_EPISODES)\n",
    "    ]\n",
    "    size_adj_highmu_pereps_reg = [\n",
    "        size_adj_highmu_pereps[i][t:] for i in range(SIMUL_EPISODES)\n",
    "    ]\n",
    "    epsilon_g_reg = [item for sublist in epsilon_g_pereps_reg for item in sublist]\n",
    "    delta_log_c_reg = [\n",
    "        item for sublist in delta_log_c_pereps_reg for item in sublist\n",
    "    ]\n",
    "    freq_adj_lowmu_reg = [\n",
    "        item for sublist in freq_adj_lowmu_pereps_reg for item in sublist\n",
    "    ]\n",
    "    freq_adj_highmu_reg = [\n",
    "        item for sublist in freq_adj_highmu_pereps_reg for item in sublist\n",
    "    ]\n",
    "    size_adj_lowmu_reg = [\n",
    "        item for sublist in size_adj_lowmu_pereps_reg for item in sublist\n",
    "    ]\n",
    "    size_adj_highmu_reg = [\n",
    "        item for sublist in size_adj_highmu_pereps_reg for item in sublist\n",
    "    ]\n",
    "\n",
    "    epsilon_g_reg_filt = [i for i in epsilon_g_reg if i > 0]\n",
    "    delta_log_c_reg_filt = [\n",
    "        delta_log_c_reg[i]\n",
    "        for i in range(len(epsilon_g_reg))\n",
    "        if epsilon_g_reg[i] > 0\n",
    "    ]\n",
    "    freq_adj_lowmu_reg_filt = [\n",
    "        freq_adj_lowmu_reg[i]\n",
    "        for i in range(len(epsilon_g_reg))\n",
    "        if epsilon_g_reg[i] > 0\n",
    "    ]\n",
    "    freq_adj_highmu_reg_filt = [\n",
    "        freq_adj_highmu_reg[i]\n",
    "        for i in range(len(epsilon_g_reg))\n",
    "        if epsilon_g_reg[i] > 0\n",
    "    ]\n",
    "    size_adj_lowmu_reg_filt = [\n",
    "        size_adj_lowmu_reg[i]\n",
    "        for i in range(len(epsilon_g_reg))\n",
    "        if epsilon_g_reg[i] > 0\n",
    "    ]\n",
    "    size_adj_highmu_reg_filt = [\n",
    "        size_adj_highmu_reg[i]\n",
    "        for i in range(len(epsilon_g_reg))\n",
    "        if epsilon_g_reg[i] > 0\n",
    "    ]\n",
    "    # epsilon_g_reg_filt = [i for i in epsilon_g_reg if i>0.007]\n",
    "    # delta_log_c_reg_filt = [delta_log_c_reg[i] for i in range(len(epsilon_g_reg)) if epsilon_g_reg[i]>0.007]\n",
    "    # freq_adj_lowmu_reg_filt = [freq_adj_lowmu_reg[i] for i in range(len(epsilon_g_reg)) if epsilon_g_reg[i]>0.007]\n",
    "    # freq_adj_highmu_reg_filt = [freq_adj_highmu_reg[i] for i in range(len(epsilon_g_reg)) if epsilon_g_reg[i]>0.007]\n",
    "    # size_adj_lowmu_reg_filt = [size_adj_lowmu_reg[i] for i in range(len(epsilon_g_reg)) if epsilon_g_reg[i]>0.007]\n",
    "    # size_adj_highmu_reg_filt = [size_adj_highmu_reg[i] for i in range(len(epsilon_g_reg)) if epsilon_g_reg[i]>0.007]\n",
    "\n",
    "    # regressions\n",
    "    reg_c = linregress(delta_log_c_reg, epsilon_g_reg)\n",
    "    IRs[t] = reg_c[0] * env.params[\"sigma_g\"] * 100\n",
    "    reg_freqlow = linregress(freq_adj_lowmu_reg_filt, epsilon_g_reg_filt)\n",
    "    IRs_freqlow[t] = reg_freqlow[0] * env.params[\"sigma_g\"] * 100\n",
    "    reg_freqhigh = linregress(freq_adj_highmu_reg_filt, epsilon_g_reg_filt)\n",
    "    IRs_freqhigh[t] = reg_freqhigh[0] * env.params[\"sigma_g\"] * 100\n",
    "    reg_sizelow = linregress(size_adj_lowmu_reg_filt, epsilon_g_reg_filt)\n",
    "    IRs_sizelow[t] = reg_sizelow[0] * env.params[\"sigma_g\"] * 100\n",
    "    reg_sizehigh = linregress(size_adj_highmu_reg_filt, epsilon_g_reg_filt)\n",
    "    IRs_sizehigh[t] = reg_sizehigh[0] * env.params[\"sigma_g\"] * 100\n",
    "cum_IRs = [np.sum(IRs[:t]) for t in range(13)]\n",
    "cum_IRs_freqlow = [np.sum(IRs_freqlow[:t]) for t in range(13)]\n",
    "cum_IRs_freqhigh = [np.sum(IRs_freqhigh[:t]) for t in range(13)]\n",
    "cum_IRs_sizelow = [np.sum(IRs_sizelow[:t]) for t in range(13)]\n",
    "cum_IRs_sizehigh = [np.sum(IRs_sizehigh[:t]) for t in range(13)]\n",
    "\n",
    "print(\n",
    "    \"cum_IRs_freqlow:\",\n",
    "    cum_IRs_freqlow[3],\n",
    "    \"\\n\",\n",
    "    \"cum_IRs_freqhigh:\",\n",
    "    cum_IRs_freqhigh[3],\n",
    "    \"\\n\",\n",
    "    \"cum_IRs_sizelow:\",\n",
    "    cum_IRs_sizelow[3],\n",
    "    \"\\n\",\n",
    "    \"cum_IRs_sizehigh:\",\n",
    "    cum_IRs_sizehigh[3],\n",
    "    \"\\n\",\n",
    ")\n",
    "\n",
    "simul_results_dict[\"Mean Profits\"].append(np.mean(profits_list))\n",
    "simul_results_dict[\"S.D. Profits\"].append(np.std(profits_list))\n",
    "simul_results_dict[\"Max Profits\"].append(np.max(profits_list))\n",
    "simul_results_dict[\"Min Profits\"].append(np.min(profits_list))\n",
    "simul_results_dict[\"Mean Markups\"].append(np.mean(mu_ij_list))\n",
    "simul_results_dict[\"S.D. Markups\"].append(np.std(mu_ij_list))\n",
    "simul_results_dict[\"Max Markups\"].append(np.max(mu_ij_list))\n",
    "simul_results_dict[\"Min Markups\"].append(np.min(mu_ij_list))\n",
    "simul_results_dict[\"Mean Freq. of Adj.\"].append(np.mean(freq_p_adj_list))\n",
    "simul_results_dict[\"S.D. Freq. of Adj.\"].append(np.std(freq_p_adj_list))\n",
    "simul_results_dict[\"Max Freq. of Adj.\"].append(np.max(freq_p_adj_list))\n",
    "simul_results_dict[\"Min Freq. of Adj.\"].append(np.min(freq_p_adj_list))\n",
    "simul_results_dict[\"Mean Size of Adj.\"].append(np.mean(size_adj_list))\n",
    "simul_results_dict[\"S.D. Size of Adj.\"].append(np.std(size_adj_list))\n",
    "simul_results_dict[\"Max Size of Adj.\"].append(np.max(size_adj_list))\n",
    "simul_results_dict[\"Min Size of Adj.\"].append(np.min(size_adj_list))\n",
    "simul_results_dict[\"S.D. log C\"].append(np.std(log_c_filt_list))\n",
    "simul_results_dict[\"Mean Flex. Markup\"].append(np.mean(mu_ij_final_list))\n",
    "simul_results_dict[\"IRs\"].append(IRs)\n",
    "simul_results_dict[\"cum_IRs\"].append(cum_IRs)\n",
    "# simul_results_dict[\"IRs_freqlow\"].append(IRs_freqlow)\n",
    "# simul_results_dict[\"IRs_freqhigh\"].append(IRs_freqhigh)\n",
    "# simul_results_dict[\"IRs_sizelow\"].append(IRs_sizelow)\n",
    "# simul_results_dict[\"IRs_sizehigh\"].append(IRs_sizehigh)\n",
    "\n",
    "print(\"Simul_results_dict:\", simul_results_dict)\n",
    "# print(\n",
    "#     \"std_log_c:\",\n",
    "#     simul_results_dict[\"S.D. log C\"],\n",
    "#     \"\\n\" + \"mu_ij:\",\n",
    "#     simul_results_dict[\"Mean Markups\"],\n",
    "#     \"\\n\" + \"freq_p_adj:\",\n",
    "#     simul_results_dict[\"Mean Freq. of Adj.\"],\n",
    "#     \"\\n\" + \"size_adj:\",\n",
    "#     simul_results_dict[\"Mean Size of Adj.\"],\n",
    "#     \"\\n\" + \"mu_ij_final:\",\n",
    "#     simul_results_dict[\"Mean Flex. Markup\"],\n",
    "# )\n",
    "\n",
    "\"\"\" Plot IRs \"\"\"\n",
    "x = [i for i in range(13)]\n",
    "IRs = simul_results_dict[\"IRs\"][-1]\n",
    "plt.plot(x, IRs)\n",
    "# learning_plot = learning_plot.get_figure()\n",
    "plt.ylabel(\"Delta log C_t * 100\")\n",
    "plt.xlabel(\"Month t\")\n",
    "plt.title(\"A. IRF - Consumption\")\n",
    "plt.savefig(OUTPUT_PATH_FIGURES + \"IRs_\" + exp_names[0] + \".png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "cum_IRs = simul_results_dict[\"cum_IRs\"][-1]\n",
    "plt.plot(x, cum_IRs)\n",
    "# learning_plot = learning_plot.get_figure()\n",
    "plt.ylabel(\"Delta log C_t * 100 \")\n",
    "plt.xlabel(\"Month t\")\n",
    "plt.title(\"B. Cumulative IRF - Consumption\")\n",
    "plt.savefig(OUTPUT_PATH_FIGURES + \"cum_IRs_\" + exp_names[0] + \".png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(x, IRs_freqlow, '-o')\n",
    "plt.plot(x, IRs_freqhigh, '-+')\n",
    "plt.legend([\"Low Markup Firms\", \"High Markup Firms\"])\n",
    "# learning_plot = learning_plot.get_figure()\n",
    "plt.ylabel(\"IRF - Levels * 100\")\n",
    "plt.xlabel(\"Month t\")\n",
    "plt.title(\"IRF - Frquency of Adjustment for High vs Low Markup Firms\")\n",
    "plt.savefig(OUTPUT_PATH_FIGURES + \"IRs_freq_\" + exp_names[0] + \".png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(x, IRs_sizelow, '-o')\n",
    "plt.plot(x, IRs_sizehigh, '-+')\n",
    "plt.legend([\"Low Markup Firms\", \"High Markup Firms\"])\n",
    "# learning_plot = learning_plot.get_figure()\n",
    "plt.ylabel(\"IRF - Levels * 100\")\n",
    "plt.xlabel(\"Month t\")\n",
    "plt.title(\"IRF - Size of Adjustment for High vs Low Markup Firms\")\n",
    "plt.savefig(OUTPUT_PATH_FIGURES + \"IRs_size_\" + exp_names[0] + \".png\")\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit"
  },
  "interpreter": {
   "hash": "8224d246b14b2208f890fdb89e47115b5f8e692495415cd25627316c2fdf7014"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}