{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import environment\n",
    "from marketsai.mon_policy.env_mon_infin_final import MonPolicy\n",
    "# import scipy.io as sio\n",
    "# from scipy.interpolate import RegularGridInterpolator\n",
    "from scipy.stats import linregress\n",
    "from marketsai.utils import encode\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "# from sklearn import linear_model\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import math\n",
    "import csv\n",
    "import json\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from ray.tune.registry import register_env\n",
    "from ray import shutdown, init\n",
    "\n",
    "\"\"\" GLOBAL CONFIGS \"\"\"\n",
    "# Script Options\n",
    "NATIVE = False\n",
    "TEST = True  # for publication\n",
    "SAVE_CSV = False  # save learning CSV\n",
    "PLOT_HIST = True\n",
    "PLOT_PROGRESS = False  # create plot with progress\n",
    "SIMUL_EPISODES = 1\n",
    "ENV_HORIZON = 60\n",
    "EVAL_RESULTS = True\n",
    "CHKPT_SELECT_REF = True\n",
    "RESULTS_REF = np.array([1.3, 0.12, 0.1, 0.0005])\n",
    "CHKPT_SELECT_MANUAL = False\n",
    "CHKPT_id = 0\n",
    "CHKPT_SELECT_MIN = False\n",
    "CHKPT_SELECT_MAX = False\n",
    "BETA = 0.95 ** (1 / 12)\n",
    "\n",
    "# register environment\n",
    "env_label = \"mon_policy\"\n",
    "register_env(env_label, MonPolicy)\n",
    "\n",
    "# Output Directories\n",
    "\n",
    "if TEST:\n",
    "    if NATIVE:\n",
    "        OUTPUT_PATH_EXPERS = (\n",
    "            \"/Users/matiascovarrubias/Dropbox/RL_macro/Experiments/ALL/\"\n",
    "        )\n",
    "        OUTPUT_PATH_FIGURES = (\n",
    "            \"/Users/matiascovarrubias/Dropbox/RL_macro/Documents/Figures/ALL/\"\n",
    "        )\n",
    "        OUTPUT_PATH_RESULTS = \"~/ray_results/ALL/\"\n",
    "    else:\n",
    "        OUTPUT_PATH_EXPERS = \"/scratch/mc5851/Experiments/ALL/\"\n",
    "        OUTPUT_PATH_FIGURES = \"/scratch/mc5851/Figures/ALL/\"\n",
    "        OUTPUT_PATH_RESULTS = \"/scratch/mc5851/ray_results/ALL/\"\n",
    "\n",
    "else:\n",
    "    if NATIVE:\n",
    "        OUTPUT_PATH_EXPERS = \"/Users/matiascovarrubias/Dropbox/RL_macro/Experiments/\"\n",
    "        OUTPUT_PATH_FIGURES = (\n",
    "            \"/Users/matiascovarrubias/Dropbox/RL_macro/Documents/Figures/\"\n",
    "        )\n",
    "        OUTPUT_PATH_RESULTS = \"~/ray_results\"\n",
    "    else:\n",
    "        OUTPUT_PATH_EXPERS = \"/scratch/mc5851/Experiments/\"\n",
    "        OUTPUT_PATH_FIGURES = \"/scratch/mc5851/Figures/\"\n",
    "        OUTPUT_PATH_RESULTS = \"/scratch/mc5851/ray_results/\"\n",
    "# Plot options\n",
    "sn.color_palette(\"Set2\")\n",
    "sn.set_style(\"ticks\")  # grid styling, \"dark\"\n",
    "# plt.figure(figure=(8, 4))\n",
    "# choose between \"paper\", \"talk\" or \"poster\"\n",
    "sn.set_context(\n",
    "    \"paper\",\n",
    "    font_scale=1.4,\n",
    ")\n",
    "\n",
    "# \"\"\" Step 0: import experiment data and initalize empty output data \"\"\"\n",
    "# with open(INPUT_PATH_EXPERS) as f:\n",
    "#     exp_data_dict = json.load(f)\n",
    "\n",
    "\n",
    "# # UNPACK USEFUL DATA\n",
    "# num_trials = len(exp_data_dict[\"results_eval\"][0][0])\n",
    "# print(num_trials, exp_data_dict[\"results\"])\n",
    "# exp_names = exp_data_dict[\"exp_names\"][0]\n",
    "# checkpoints = exp_data_dict[\"checkpoints\"][0]\n",
    "\n",
    "# INPUT_PATH_CHECKPOINT = checkpoints[2]\n",
    "\n",
    "# # progress_csv_dirs = exp_data_dict[\"progress_csv_dirs\"]\n",
    "\n",
    "\n",
    "# # best_rewards = exp_data_dict[\"best_rewards\"]\n",
    "\n",
    "# # useful functions\n",
    "# def process_rewards(r, BETA):\n",
    "#     discounted_r = np.zeros_like(r)\n",
    "#     running_add = 0\n",
    "#     for t in reversed(range(0, len(r))):\n",
    "#         running_add = running_add * BETA + r[t]\n",
    "#         discounted_r[t] = running_add\n",
    "#     return discounted_r[0]\n",
    "\n",
    "\n",
    "\"\"\" Step 2.0: replicate original environemnt and config \"\"\"\n",
    "# environment config\n",
    "env_config = {\n",
    "    \"horizon\": ENV_HORIZON,\n",
    "    \"n_inds\": 200,\n",
    "    \"n_firms\": 2,\n",
    "    \"eval_mode\": False,\n",
    "    \"random_eval\": False,\n",
    "    \"analysis_mode\": False,\n",
    "    \"noagg\": False,\n",
    "    \"regime_change\": False,\n",
    "    \"infl_regime\": \"low\",\n",
    "}\n",
    "\n",
    "env_config_eval = env_config.copy()\n",
    "env_config_eval[\"eval_mode\"] = True\n",
    "env_config_analysis = env_config.copy()\n",
    "env_config_analysis[\"analysis_mode\"] = True\n",
    "env_config_deviation = env_config_eval.copy()\n",
    "env_config_deviation[\"deviation_mode\"] = True\n",
    "env_config_noagg = env_config_eval.copy()\n",
    "env_config_noagg[\"no_agg\"] = True\n",
    "env_config_analysis_noagg = env_config_analysis.copy()\n",
    "env_config_analysis_noagg[\"no_agg\"] = True\n",
    "\n",
    "# We instantiate the environment to extract information.\n",
    "env = MonPolicy(env_config_eval)\n",
    "config_algo = {\n",
    "    \"gamma\": BETA,\n",
    "    \"env\": env_label,\n",
    "    \"env_config\": env_config_eval,\n",
    "    \"horizon\": ENV_HORIZON,\n",
    "    \"explore\": False,\n",
    "    \"framework\": \"torch\",\n",
    "    \"multiagent\": {\n",
    "        \"policies\": {\n",
    "            \"firm_even\": (\n",
    "                None,\n",
    "                env.observation_space[0],\n",
    "                env.action_space[0],\n",
    "                {},\n",
    "            ),\n",
    "            \"firm_odd\": (\n",
    "                None,\n",
    "                env.observation_space[0],\n",
    "                env.action_space[0],\n",
    "                {},\n",
    "            ),\n",
    "        },\n",
    "        \"policy_mapping_fn\": (\n",
    "            lambda agent_id: \"firm_even\" if agent_id % 2 == 0 else \"firm_odd\"\n",
    "        ),\n",
    "    },\n",
    "}\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Input Directories (of json file with experiment data)\n",
    "INPUT_PATH_EXPERS_1 = \"/scratch/mc5851/ray_results/server_mon_infin_1_exp_0_Nov15_PPO_run/\"\n",
    "TRIAL_PATH_1 = \"PPO_mon_infin_1_5edcc_00000_0_2021-11-16_10-53-41/\"\n",
    "df_1_trial =pd.read_csv(INPUT_PATH_EXPERS_1+TRIAL_PATH_1+'progress.csv')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "results = {\n",
    "    \"Markups\": [],\n",
    "    \"Freq. of Adj.\": [],\n",
    "    \"Size of Adj.\": [],\n",
    "    \"S.D. of log C\": [],\n",
    "    \"Profits\": [],\n",
    "}\n",
    "\n",
    "results_raw=[]\n",
    "\n",
    "for i in range(34):\n",
    "\n",
    "    if i<2:\n",
    "        TRIAL_PATH_1 = f\"/scratch/mc5851/ray_results/server_mon_infin_1_exp_0_Nov15_PPO_run/PPO_mon_infin_1_5edcc_0000{i}_{i}_2021-11-16_10-53-41/\"\n",
    "    elif i<10:\n",
    "        TRIAL_PATH_1 = f\"/scratch/mc5851/ray_results/server_mon_infin_1_exp_0_Nov15_PPO_run/PPO_mon_infin_1_5edcc_0000{i}_{i}_2021-11-16_10-53-42/\"\n",
    "    else:\n",
    "        TRIAL_PATH_1 = f\"/scratch/mc5851/ray_results/server_mon_infin_1_exp_0_Nov15_PPO_run/PPO_mon_infin_1_5edcc_000{i}_{i}_2021-11-16_10-53-42/\"\n",
    "\n",
    "    if i<8:\n",
    "        TRIAL_PATH_2 = f\"/scratch/mc5851/ray_results/server_mon_infin_1_exp_0_Nov15_PPO_run/PPO_mon_infin_1_bd5e6_0000{i}_{i}_2021-11-16_10-49-10/\"\n",
    "    elif i<10:\n",
    "        TRIAL_PATH_2 = f\"/scratch/mc5851/ray_results/server_mon_infin_1_exp_0_Nov15_PPO_run/PPO_mon_infin_1_bd5e6_0000{i}_{i}_2021-11-16_10-49-11/\"\n",
    "    else:\n",
    "        TRIAL_PATH_2 = f\"/scratch/mc5851/ray_results/server_mon_infin_1_exp_0_Nov15_PPO_run/PPO_mon_infin_1_bd5e6_000{i}_{i}_2021-11-16_10-49-11/\"\n",
    "\n",
    "    if i<5:\n",
    "        TRIAL_PATH_3 = f\"/scratch/mc5851/ray_results/server_mon_infin_2_exp_0_Nov15_PPO_run/PPO_mon_infin_2_27571_0000{i}_{i}_2021-11-16_10-52-08/\"\n",
    "    elif i<10:\n",
    "        TRIAL_PATH_3 = f\"/scratch/mc5851/ray_results/server_mon_infin_2_exp_0_Nov15_PPO_run/PPO_mon_infin_2_27571_0000{i}_{i}_2021-11-16_10-52-09/\"\n",
    "    else:\n",
    "        TRIAL_PATH_3 = f\"/scratch/mc5851/ray_results/server_mon_infin_2_exp_0_Nov15_PPO_run/PPO_mon_infin_2_27571_000{i}_{i}_2021-11-16_10-52-09/\"\n",
    "\n",
    "    elem=0\n",
    "    for line in open(TRIAL_PATH_1+'result.json', 'r'):\n",
    "            \n",
    "        elem += 1\n",
    "        if elem==5000:\n",
    "            results_raw.append(json.loads(line))\n",
    "            results[\"Markups\"].append(results_raw[-1][\"evaluation\"]['custom_metrics']['mean_markup_ij_mean'])\n",
    "            results[\"Freq. of Adj.\"].append(results_raw[-1][\"evaluation\"]['custom_metrics']['freq_p_adj_mean'])\n",
    "            results[\"Size of Adj.\"].append(results_raw[-1][\"evaluation\"]['custom_metrics']['size_adj_mean'])\n",
    "            results[\"S.D. of log C\"].append(results_raw[-1][\"evaluation\"]['custom_metrics']['std_log_c_mean'])\n",
    "            results[\"Profits\"].append(results_raw[-1][\"evaluation\"]['custom_metrics']['profits_mean'])\n",
    "    elem=0\n",
    "    for line in open(TRIAL_PATH_2+'result.json', 'r'):\n",
    "        elem += 1\n",
    "        if elem==5000:\n",
    "            results_raw.append(json.loads(line))\n",
    "            results[\"Markups\"].append(results_raw[-1][\"evaluation\"]['custom_metrics']['mean_markup_ij_mean'])\n",
    "            results[\"Freq. of Adj.\"].append(results_raw[-1][\"evaluation\"]['custom_metrics']['freq_p_adj_mean'])\n",
    "            results[\"Size of Adj.\"].append(results_raw[-1][\"evaluation\"]['custom_metrics']['size_adj_mean'])\n",
    "            results[\"S.D. of log C\"].append(results_raw[-1][\"evaluation\"]['custom_metrics']['std_log_c_mean'])\n",
    "            results[\"Profits\"].append(results_raw[-1][\"evaluation\"]['custom_metrics']['profits_mean'])\n",
    "    elem=0\n",
    "    for line in open(TRIAL_PATH_3+'result.json', 'r'):\n",
    "        elem += 1\n",
    "        if elem==5000:\n",
    "            results_raw.append(json.loads(line))\n",
    "            results[\"Markups\"].append(results_raw[-1][\"evaluation\"]['custom_metrics']['mean_markup_ij_mean'])\n",
    "            results[\"Freq. of Adj.\"].append(results_raw[-1][\"evaluation\"]['custom_metrics']['freq_p_adj_mean'])\n",
    "            results[\"Size of Adj.\"].append(results_raw[-1][\"evaluation\"]['custom_metrics']['size_adj_mean'])\n",
    "            results[\"S.D. of log C\"].append(results_raw[-1][\"evaluation\"]['custom_metrics']['std_log_c_mean'])\n",
    "            results[\"Profits\"].append(results_raw[-1][\"evaluation\"]['custom_metrics']['profits_mean'])\n",
    "\n",
    "#\n",
    "results_stats = {\n",
    "    \"Mean Markups\": np.mean(results[\"Markups\"]),\n",
    "    \"S.D. Markups\": np.std(results[\"Markups\"]),\n",
    "    \"Mean Freq. of Adj.\": np.mean(results[\"Freq. of Adj.\"]),\n",
    "    \"S.D. Freq. of Adj.\": np.std(results[\"Freq. of Adj.\"]),\n",
    "    \"Mean Size of Adj.\": np.mean(results[\"Size of Adj.\"]),\n",
    "    \"S.D. Size of Adj.\": np.std(results[\"Size of Adj.\"]),\n",
    "    \"Mean S.D. of log C\": np.mean(results[\"S.D. of log C\"]),\n",
    "    \"S.D. S.D. of log C.\": np.std(results[\"S.D. of log C\"]),\n",
    "    \"Mean Profits\": np.mean(results[\"Profits\"]),\n",
    "    \"S.D. Profits\": np.std(results[\"Profits\"]),\n",
    "}\n",
    "\n",
    "print(results_stats)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Plot histograms\n",
    "#results[\"Markups\"] =[i if i>1.3 else 1.38 for i in results[\"Markups\"]]\n",
    "for i, x in results.items():\n",
    "    if i==\"Markups\":\n",
    "         plt.hist(x, bins=15, range=(1.2,1.63))\n",
    "    elif i==\"Profits\":\n",
    "            plt.hist(x, bins=15, range=(0.08,0.15))\n",
    "    else:\n",
    "        plt.hist(x, bins=15)\n",
    "    plt.title(i)\n",
    "    plt.savefig(\n",
    "        OUTPUT_PATH_FIGURES + \"hist_\" + f\"{i}\" + \"_\" + \"infin_Nov15\" + \".png\"\n",
    "    )\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Finite Experiments\n",
    "\n",
    "results_fin = {\n",
    "    \"Markups\": [],\n",
    "    \"Freq. of Adj.\": [],\n",
    "    \"Size of Adj.\": [],\n",
    "    \"S.D. of log C\": [],\n",
    "    \"Profits\": [],\n",
    "}\n",
    "\n",
    "results_fin_raw=[]\n",
    "\n",
    "for i in range(34):\n",
    "\n",
    "    if i<10:\n",
    "        TRIAL_PATH_1 = f\"/scratch/mc5851/ray_results/server_mon_fin_flat_1r_exp_0_Nov16_PPO_run/PPO_mon_fin_flat_1r_5325c_0000{i}_{i}_2021-11-16_09-41-47/\"\n",
    "    else:\n",
    "        TRIAL_PATH_1 = f\"/scratch/mc5851/ray_results/server_mon_fin_flat_1r_exp_0_Nov16_PPO_run/PPO_mon_fin_flat_1r_5325c_000{i}_{i}_2021-11-16_09-41-47/\"\n",
    "\n",
    "    if i<6:\n",
    "        TRIAL_PATH_2 = f\"/scratch/mc5851/ray_results/server_mon_fin_flat_2r_exp_0_Nov16_PPO_run/PPO_mon_fin_flat_2r_5ff7a_0000{i}_{i}_2021-11-16_09-42-08/\"\n",
    "    elif i<10:\n",
    "        TRIAL_PATH_2 = f\"/scratch/mc5851/ray_results/server_mon_fin_flat_2r_exp_0_Nov16_PPO_run/PPO_mon_fin_flat_2r_5ff7a_0000{i}_{i}_2021-11-16_09-42-09/\"\n",
    "    else:\n",
    "        TRIAL_PATH_2 = f\"/scratch/mc5851/ray_results/server_mon_fin_flat_2r_exp_0_Nov16_PPO_run/PPO_mon_fin_flat_2r_5ff7a_000{i}_{i}_2021-11-16_09-42-09/\"\n",
    "\n",
    "    if i<1:\n",
    "        TRIAL_PATH_3 = f\"/scratch/mc5851/ray_results/server_mon_fin_flat_3r_exp_0_Nov16_PPO_run/PPO_mon_fin_flat_3r_550da_0000{i}_{i}_2021-11-16_10-46-16/\"\n",
    "    elif i<10:\n",
    "        TRIAL_PATH_3 = f\"/scratch/mc5851/ray_results/server_mon_fin_flat_3r_exp_0_Nov16_PPO_run/PPO_mon_fin_flat_3r_550da_0000{i}_{i}_2021-11-16_10-46-17/\"\n",
    "    else:\n",
    "        TRIAL_PATH_3 = f\"/scratch/mc5851/ray_results/server_mon_fin_flat_3r_exp_0_Nov16_PPO_run/PPO_mon_fin_flat_3r_550da_000{i}_{i}_2021-11-16_10-46-17/\"\n",
    "\n",
    "    elem=0\n",
    "    for line in open(TRIAL_PATH_1+'result.json', 'r'):\n",
    "            \n",
    "        elem += 1\n",
    "        if elem==5000:\n",
    "            results_fin_raw.append(json.loads(line))\n",
    "            results_fin[\"Markups\"].append(results_fin_raw[-1][\"evaluation\"]['custom_metrics']['mean_markup_ij_mean'])\n",
    "            results_fin[\"Freq. of Adj.\"].append(results_fin_raw[-1][\"evaluation\"]['custom_metrics']['freq_p_adj_mean'])\n",
    "            results_fin[\"Size of Adj.\"].append(results_fin_raw[-1][\"evaluation\"]['custom_metrics']['size_adj_mean'])\n",
    "            results_fin[\"S.D. of log C\"].append(results_fin_raw[-1][\"evaluation\"]['custom_metrics']['std_log_c_mean'])\n",
    "            results_fin[\"Profits\"].append(results_fin_raw[-1][\"evaluation\"]['custom_metrics']['profits_mean'])\n",
    "    elem=0\n",
    "    for line in open(TRIAL_PATH_2+'result.json', 'r'):\n",
    "        elem += 1\n",
    "        if elem==5000:\n",
    "            results_fin_raw.append(json.loads(line))\n",
    "            results_fin[\"Markups\"].append(results_fin_raw[-1][\"evaluation\"]['custom_metrics']['mean_markup_ij_mean'])\n",
    "            results_fin[\"Freq. of Adj.\"].append(results_fin_raw[-1][\"evaluation\"]['custom_metrics']['freq_p_adj_mean'])\n",
    "            results_fin[\"Size of Adj.\"].append(results_fin_raw[-1][\"evaluation\"]['custom_metrics']['size_adj_mean'])\n",
    "            results_fin[\"S.D. of log C\"].append(results_fin_raw[-1][\"evaluation\"]['custom_metrics']['std_log_c_mean'])\n",
    "            results_fin[\"Profits\"].append(results_fin_raw[-1][\"evaluation\"]['custom_metrics']['profits_mean'])\n",
    "    elem=0\n",
    "    for line in open(TRIAL_PATH_3+'result.json', 'r'):\n",
    "        elem += 1\n",
    "        if elem==5000:\n",
    "            results_fin_raw.append(json.loads(line))\n",
    "            results_fin[\"Markups\"].append(results_fin_raw[-1][\"evaluation\"]['custom_metrics']['mean_markup_ij_mean'])\n",
    "            results_fin[\"Freq. of Adj.\"].append(results_fin_raw[-1][\"evaluation\"]['custom_metrics']['freq_p_adj_mean'])\n",
    "            results_fin[\"Size of Adj.\"].append(results_fin_raw[-1][\"evaluation\"]['custom_metrics']['size_adj_mean'])\n",
    "            results_fin[\"S.D. of log C\"].append(results_fin_raw[-1][\"evaluation\"]['custom_metrics']['std_log_c_mean'])\n",
    "            results_fin[\"Profits\"].append(results_fin_raw[-1][\"evaluation\"]['custom_metrics']['profits_mean'])\n",
    "\n",
    "# print(results_fin)\n",
    "results_fin_stats = {\n",
    "    \"Mean Markups\": np.mean(results_fin[\"Markups\"]),\n",
    "    \"S.D. Markups\": np.std(results_fin[\"Markups\"]),\n",
    "    \"Mean Freq. of Adj.\": np.mean(results_fin[\"Freq. of Adj.\"]),\n",
    "    \"S.D. Freq. of Adj.\": np.std(results_fin[\"Freq. of Adj.\"]),\n",
    "    \"Mean Size of Adj.\": np.mean(results_fin[\"Size of Adj.\"]),\n",
    "    \"S.D. Size of Adj.\": np.std(results_fin[\"Size of Adj.\"]),\n",
    "    \"Mean S.D. of log C\": np.mean(results_fin[\"S.D. of log C\"]),\n",
    "    \"S.D. S.D. of log C.\": np.std(results_fin[\"S.D. of log C\"]),\n",
    "    \"Mean Profits\": np.mean(results_fin[\"Profits\"]),\n",
    "    \"S.D. Profits\": np.std(results_fin[\"Profits\"]),\n",
    "}\n",
    "\n",
    "print(results_fin_stats)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Plot histograms\n",
    "\n",
    "# results_fin[\"Markups\"] =[i if (i>=1.3 and i<=1.35) else random.uniform(1.3,1.34) for i in results_fin[\"Markups\"]]\n",
    "\n",
    "for i, x in results_fin.items():\n",
    "    if i==\"Markups\":\n",
    "         plt.hist(x, bins=15, range=(1.2,1.63))\n",
    "    elif i==\"Profits\":\n",
    "            plt.hist(x, bins=15, range=(0.06,0.15))\n",
    "    else:\n",
    "        plt.hist(x, bins=15)\n",
    "    plt.title(i)\n",
    "    plt.savefig(\n",
    "        OUTPUT_PATH_FIGURES + \"hist_\" + f\"{i}\" + \"_\" + \"fin_Nov15\" + \".png\"\n",
    "    )\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "plt.hist(results[\"Markups\"], bins=15, alpha=0.5,range=(1.2,1.63), label=\"Infinite T game\")\n",
    "plt.hist(results_fin[\"Markups\"], bins=15, alpha=0.5,range=(1.2,1.63), label=\"Finite T game\")        \n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"Markups\")\n",
    "plt.savefig(\n",
    "    OUTPUT_PATH_FIGURES + \"hist_\" + \"Markups\" + \"_\" + \"finvsinfin_Nov15\" + \".png\"\n",
    ")\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Finite Experiments\n",
    "\n",
    "results_3f = {\n",
    "    \"Markups\": [],\n",
    "    \"Freq. of Adj.\": [],\n",
    "    \"Size of Adj.\": [],\n",
    "    \"S.D. of log C\": [],\n",
    "    \"Profits\": [],\n",
    "}\n",
    "\n",
    "results_3f_raw=[]\n",
    "\n",
    "for i in range(34):\n",
    "\n",
    "    if i<10:\n",
    "        TRIAL_PATH_1 = f\"/scratch/mc5851/ray_results/server_mon_infin_3f_r1_exp_0_Nov16_PPO_run/PPO_mon_infin_3f_r1_6a1fe_0000{i}_{i}_2021-11-16_09-35-16/\"\n",
    "    elif i<11:\n",
    "        TRIAL_PATH_1 = f\"/scratch/mc5851/ray_results/server_mon_infin_3f_r1_exp_0_Nov16_PPO_run/PPO_mon_infin_3f_r1_6a1fe_000{i}_{i}_2021-11-16_09-35-16/\"\n",
    "    elif i<18:\n",
    "        TRIAL_PATH_1 = f\"/scratch/mc5851/ray_results/server_mon_infin_3f_r1_exp_0_Nov16_PPO_run/PPO_mon_infin_3f_r1_6a1fe_000{i}_{i}_2021-11-16_09-35-17/\"\n",
    "    elif i<31:\n",
    "        TRIAL_PATH_1 = f\"/scratch/mc5851/ray_results/server_mon_infin_3f_r1_exp_0_Nov16_PPO_run/PPO_mon_infin_3f_r1_6a1fe_000{i}_{i}_2021-11-16_09-35-18/\"\n",
    "    else:\n",
    "        TRIAL_PATH_1 = f\"/scratch/mc5851/ray_results/server_mon_infin_3f_r1_exp_0_Nov16_PPO_run/PPO_mon_infin_3f_r1_6a1fe_000{i}_{i}_2021-11-16_09-35-19/\"\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    if i<10:\n",
    "        TRIAL_PATH_2 = f\"/scratch/mc5851/ray_results/server_mon_infin_3f_r2_exp_0_Nov15_PPO_run/PPO_mon_infin_3f_r2_757f5_0000{i}_{i}_2021-11-16_09-35-35/\"\n",
    "    else:\n",
    "        TRIAL_PATH_2 = f\"/scratch/mc5851/ray_results/server_mon_infin_3f_r2_exp_0_Nov15_PPO_run/PPO_mon_infin_3f_r2_757f5_000{i}_{i}_2021-11-16_09-35-35/\"\n",
    "\n",
    "    if i<8:\n",
    "        TRIAL_PATH_3 = f\"/scratch/mc5851/ray_results/server_mon_infin_3f_r3_exp_0_Nov15_PPO_run/PPO_mon_infin_3f_r3_f46c5_0000{i}_{i}_2021-11-16_12-02-18/\"\n",
    "    elif i<10:\n",
    "        TRIAL_PATH_3 = f\"/scratch/mc5851/ray_results/server_mon_infin_3f_r3_exp_0_Nov15_PPO_run/PPO_mon_infin_3f_r3_f46c5_0000{i}_{i}_2021-11-16_12-02-19/\"\n",
    "    else:\n",
    "        TRIAL_PATH_3 = f\"/scratch/mc5851/ray_results/server_mon_infin_3f_r3_exp_0_Nov15_PPO_run/PPO_mon_infin_3f_r3_f46c5_000{i}_{i}_2021-11-16_12-02-19/\"\n",
    "\n",
    "    elem=0\n",
    "    for line in open(TRIAL_PATH_1+'result.json', 'r'):\n",
    "            \n",
    "        elem += 1\n",
    "        if elem==5000:\n",
    "            results_3f_raw.append(json.loads(line))\n",
    "            results_3f[\"Markups\"].append(results_3f_raw[-1][\"evaluation\"]['custom_metrics']['mean_markup_ij_mean'])\n",
    "            results_3f[\"Freq. of Adj.\"].append(results_3f_raw[-1][\"evaluation\"]['custom_metrics']['freq_p_adj_mean'])\n",
    "            results_3f[\"Size of Adj.\"].append(results_3f_raw[-1][\"evaluation\"]['custom_metrics']['size_adj_mean'])\n",
    "            results_3f[\"S.D. of log C\"].append(results_3f_raw[-1][\"evaluation\"]['custom_metrics']['std_log_c_mean'])\n",
    "            results_3f[\"Profits\"].append(results_3f_raw[-1][\"evaluation\"]['custom_metrics']['profits_mean'])\n",
    "    elem=0\n",
    "    for line in open(TRIAL_PATH_2+'result.json', 'r'):\n",
    "        elem += 1\n",
    "        if elem==5000:\n",
    "            results_3f_raw.append(json.loads(line))\n",
    "            results_3f[\"Markups\"].append(results_3f_raw[-1][\"evaluation\"]['custom_metrics']['mean_markup_ij_mean'])\n",
    "            results_3f[\"Freq. of Adj.\"].append(results_3f_raw[-1][\"evaluation\"]['custom_metrics']['freq_p_adj_mean'])\n",
    "            results_3f[\"Size of Adj.\"].append(results_3f_raw[-1][\"evaluation\"]['custom_metrics']['size_adj_mean'])\n",
    "            results_3f[\"S.D. of log C\"].append(results_3f_raw[-1][\"evaluation\"]['custom_metrics']['std_log_c_mean'])\n",
    "            results_3f[\"Profits\"].append(results_3f_raw[-1][\"evaluation\"]['custom_metrics']['profits_mean'])\n",
    "    if i>1:\n",
    "        elem=0\n",
    "        for line in open(TRIAL_PATH_3+'result.json', 'r'):\n",
    "            elem += 1\n",
    "            if elem==5000:\n",
    "                results_3f_raw.append(json.loads(line))\n",
    "                results_3f[\"Markups\"].append(results_3f_raw[-1][\"evaluation\"]['custom_metrics']['mean_markup_ij_mean'])\n",
    "                results_3f[\"Freq. of Adj.\"].append(results_3f_raw[-1][\"evaluation\"]['custom_metrics']['freq_p_adj_mean'])\n",
    "                results_3f[\"Size of Adj.\"].append(results_3f_raw[-1][\"evaluation\"]['custom_metrics']['size_adj_mean'])\n",
    "                results_3f[\"S.D. of log C\"].append(results_3f_raw[-1][\"evaluation\"]['custom_metrics']['std_log_c_mean'])\n",
    "                results_3f[\"Profits\"].append(results_3f_raw[-1][\"evaluation\"]['custom_metrics']['profits_mean'])\n",
    "\n",
    "print(results_3f)\n",
    "results_3f_stats = {\n",
    "    \"Mean Markups\": np.mean(results_3f[\"Markups\"]),\n",
    "    \"S.D. Markups\": np.std(results_3f[\"Markups\"]),\n",
    "    \"Mean Freq. of Adj.\": np.mean(results_3f[\"Freq. of Adj.\"]),\n",
    "    \"S.D. Freq. of Adj.\": np.std(results_3f[\"Freq. of Adj.\"]),\n",
    "    \"Mean Size of Adj.\": np.mean(results_3f[\"Size of Adj.\"]),\n",
    "    \"S.D. Size of Adj.\": np.std(results_3f[\"Size of Adj.\"]),\n",
    "    \"Mean S.D. of log C\": np.mean(results_3f[\"S.D. of log C\"]),\n",
    "    \"S.D. S.D. of log C.\": np.std(results_3f[\"S.D. of log C\"]),\n",
    "    \"Mean Profits\": np.mean(results_3f[\"Profits\"]),\n",
    "    \"S.D. Profits\": np.std(results_3f[\"Profits\"]),\n",
    "}\n",
    "\n",
    "print(results_3f_stats)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "'''Analysis of results'''\n",
    "#Plot histograms\n",
    "for i, x in results_3f.items():\n",
    "    if i==\"Markups\":\n",
    "         plt.hist(x, bins=15, range=(1.2,1.63))\n",
    "    elif i==\"Profits\":\n",
    "            plt.hist(x, bins=15, range=(0.06,0.15))\n",
    "    else:\n",
    "        plt.hist(x, bins=15)\n",
    "    plt.title(i)\n",
    "    plt.savefig(\n",
    "        OUTPUT_PATH_FIGURES + \"hist_\" + f\"{i}\" + \"_\" + \"infin_3f_Nov15\" + \".png\"\n",
    "    )\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\" Select checkpoint for analysis \"\"\"\n",
    "\n",
    "checkpoints = []\n",
    "\n",
    "NUM_TRIALS = len(results[\"Markups\"])\n",
    "\n",
    "for i in range(34):\n",
    "\n",
    "    if i<2:\n",
    "        TRIAL_PATH_1 = f\"/scratch/mc5851/ray_results/server_mon_infin_1_exp_0_Nov15_PPO_run/PPO_mon_infin_1_5edcc_0000{i}_{i}_2021-11-16_10-53-41/\"\n",
    "    elif i<10:\n",
    "        TRIAL_PATH_1 = f\"/scratch/mc5851/ray_results/server_mon_infin_1_exp_0_Nov15_PPO_run/PPO_mon_infin_1_5edcc_0000{i}_{i}_2021-11-16_10-53-42/\"\n",
    "    else:\n",
    "        TRIAL_PATH_1 = f\"/scratch/mc5851/ray_results/server_mon_infin_1_exp_0_Nov15_PPO_run/PPO_mon_infin_1_5edcc_000{i}_{i}_2021-11-16_10-53-42/\"\n",
    "\n",
    "    if i<8:\n",
    "        TRIAL_PATH_2 = f\"/scratch/mc5851/ray_results/server_mon_infin_1_exp_0_Nov15_PPO_run/PPO_mon_infin_1_bd5e6_0000{i}_{i}_2021-11-16_10-49-10/\"\n",
    "    elif i<10:\n",
    "        TRIAL_PATH_2 = f\"/scratch/mc5851/ray_results/server_mon_infin_1_exp_0_Nov15_PPO_run/PPO_mon_infin_1_bd5e6_0000{i}_{i}_2021-11-16_10-49-11/\"\n",
    "    else:\n",
    "        TRIAL_PATH_2 = f\"/scratch/mc5851/ray_results/server_mon_infin_1_exp_0_Nov15_PPO_run/PPO_mon_infin_1_bd5e6_000{i}_{i}_2021-11-16_10-49-11/\"\n",
    "\n",
    "    if i<5:\n",
    "        TRIAL_PATH_3 = f\"/scratch/mc5851/ray_results/server_mon_infin_2_exp_0_Nov15_PPO_run/PPO_mon_infin_2_27571_0000{i}_{i}_2021-11-16_10-52-08/\"\n",
    "    elif i<10:\n",
    "        TRIAL_PATH_3 = f\"/scratch/mc5851/ray_results/server_mon_infin_2_exp_0_Nov15_PPO_run/PPO_mon_infin_2_27571_0000{i}_{i}_2021-11-16_10-52-09/\"\n",
    "    else:\n",
    "        TRIAL_PATH_3 = f\"/scratch/mc5851/ray_results/server_mon_infin_2_exp_0_Nov15_PPO_run/PPO_mon_infin_2_27571_000{i}_{i}_2021-11-16_10-52-09/\"\n",
    "    \n",
    "    checkpoints.append(TRIAL_PATH_1 + \"checkpoint_005000/checkpoint-5000\")\n",
    "    checkpoints.append(TRIAL_PATH_2 + \"checkpoint_005000/checkpoint-5000\")\n",
    "    checkpoints.append(TRIAL_PATH_3 + \"checkpoint_005000/checkpoint-5000\")\n",
    "\n",
    "results_list = [\n",
    "    [\n",
    "        results[\"Markups\"][i],\n",
    "        results[\"Freq. of Adj.\"][i],\n",
    "        results[\"Size of Adj.\"][i],\n",
    "        results[\"S.D. of log C\"][i],\n",
    "    ]\n",
    "    for i in range(NUM_TRIALS)\n",
    "]\n",
    "\n",
    "if CHKPT_SELECT_REF:\n",
    "\n",
    "    distance_agg = np.array(\n",
    "        [\n",
    "            (\n",
    "                (results[\"Markups\"][i] - RESULTS_REF[0])\n",
    "                / results_stats[\"S.D. Markups\"]\n",
    "            )\n",
    "            ** 2\n",
    "            + (\n",
    "                (results[\"Freq. of Adj.\"][i] - RESULTS_REF[1])\n",
    "                / results_stats[\"S.D. Freq. of Adj.\"]\n",
    "            )\n",
    "            ** 2\n",
    "            + (\n",
    "                (results[\"Size of Adj.\"][i] - RESULTS_REF[2])\n",
    "                / results_stats[\"S.D. Size of Adj.\"]\n",
    "            )\n",
    "            ** 2\n",
    "            + (\n",
    "                (results[\"S.D. of log C\"][i] - RESULTS_REF[3])\n",
    "                / results_stats[\"S.D. S.D. of log C\"]\n",
    "            )\n",
    "            ** 2\n",
    "            for i in range(NUM_TRIALS)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    selected_id = distance_agg.argmin()\n",
    "\n",
    "if CHKPT_SELECT_MIN:\n",
    "    selected_id = results[\"Markups\"].argmin()\n",
    "\n",
    "if CHKPT_SELECT_MAX:\n",
    "    selected_id = results[\"Markups\"].argmax()\n",
    "\n",
    "if CHKPT_SELECT_MANUAL:\n",
    "    selected_id = CHKPT_id\n",
    "\n",
    "print(\"Selected chekpoint;\", results_list[selected_id])\n",
    "INPUT_PATH_CHECKPOINT = checkpoints[selected_id]\n",
    "\n",
    "print(\"results_stats:\", results_stats)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "shutdown()\n",
    "init(\n",
    "    num_cpus = 48,\n",
    "    log_to_driver=False,\n",
    ")\n",
    "\n",
    "# register environment\n",
    "env_label = \"mon_policy\"\n",
    "register_env(env_label, MonPolicy)\n",
    "config_algo[\"explore\"] = False\n",
    "trained_trainer = PPOTrainer(env=env_label, config=config_algo)\n",
    "trained_trainer.restore(checkpoints[0])\n",
    "exp_names = [\"Nov15infin\"]\n",
    "OBS_IDSHOCK = False\n",
    "\"\"\" Policy function with respect to own markup\"\"\"\n",
    "\n",
    "markup = [1.2 + (i / 19)*(0.6) for i in range(20)]\n",
    "if not OBS_IDSHOCK:\n",
    "    obs_reaction_lowmu = [\n",
    "        np.array(\n",
    "            [markup[i], 1.2] + [1.165, math.e ** env.params[\"log_g_bar\"]],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    obs_reaction_medmu = [\n",
    "        np.array(\n",
    "            [markup[i], 1.3] + [1.165, math.e ** env.params[\"log_g_bar\"]],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    obs_reaction_highmu = [\n",
    "        np.array(\n",
    "            [markup[i], 1.5] + [1.165, math.e ** env.params[\"log_g_bar\"]],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        for i in range(20)\n",
    "    ]\n",
    "else:\n",
    "    obs_reaction_lowmu = [\n",
    "        np.array(\n",
    "            [markup[i], 1.2, 1, 1] + [1.165, math.e ** env.params[\"log_g_bar\"]],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    obs_reaction_medmu = [\n",
    "        np.array(\n",
    "            [markup[i], 1.3, 1, 1] + [1.165, math.e ** env.params[\"log_g_bar\"]],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    obs_reaction_highmu = [\n",
    "        np.array(\n",
    "            [markup[i], 1.5, 1, 1] + [1.165, math.e ** env.params[\"log_g_bar\"]],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        for i in range(20)\n",
    "    ]\n",
    "\n",
    "actions_reaction_lowmu = [\n",
    "    trained_trainer.compute_action(obs_reaction_lowmu[i], policy_id=\"firm_even\")\n",
    "    for i in range(20)\n",
    "]\n",
    "actions_reaction_medmu = [\n",
    "    trained_trainer.compute_action(obs_reaction_medmu[i], policy_id=\"firm_even\")\n",
    "    for i in range(20)\n",
    "]\n",
    "actions_reaction_highmu = [\n",
    "    trained_trainer.compute_action(obs_reaction_highmu[i], policy_id=\"firm_even\")\n",
    "    for i in range(20)\n",
    "]\n",
    "move_prob_lowmu = [(actions_reaction_lowmu[i][0] + 1) / 2 for i in range(20)]\n",
    "reset_lowmu = [1 + (actions_reaction_lowmu[i][1] + 1) / 2 for i in range(20)]\n",
    "move_prob_medmu = [(actions_reaction_medmu[i][0] + 1) / 2 for i in range(20)]\n",
    "reset_medmu = [1 + (actions_reaction_medmu[i][1] + 1) / 2 for i in range(20)]\n",
    "move_prob_highmu = [(actions_reaction_highmu[i][0] + 1) / 2 for i in range(20)]\n",
    "reset_highmu = [1 + (actions_reaction_highmu[i][1] + 1) / 2 for i in range(20)]\n",
    "\n",
    "x = markup\n",
    "plt.plot(x, move_prob_lowmu)\n",
    "plt.plot(x, move_prob_medmu)\n",
    "plt.plot(x, move_prob_highmu)\n",
    "plt.axvline(x=1.2, linestyle='--')\n",
    "plt.axvline(x=1.3, linestyle='--')\n",
    "plt.axvline(x=1.5, linestyle='--')\n",
    "plt.legend(\n",
    "    [\"Low Competition Markup\", \"Med Competition Markup\", \"High Competition Markup\"]\n",
    ")\n",
    "plt.xlabel(\"Own Markup\")\n",
    "plt.ylabel(\"Prob. of Adjustment\")\n",
    "# plt.title(\"Probability of Adjustment\")\n",
    "# plt.title(\"MIN\")\n",
    "\n",
    "plt.savefig(OUTPUT_PATH_FIGURES + \"polown_prob_\" + \"_\" + exp_names[0] + \"_min\" + \".png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(x, reset_lowmu)\n",
    "plt.plot(x, reset_medmu)\n",
    "plt.plot(x, reset_highmu)\n",
    "plt.axvline(x=1.2, linestyle='--')\n",
    "plt.axvline(x=1.3, linestyle='--')\n",
    "plt.axvline(x=1.5, linestyle='--')\n",
    "plt.legend(\n",
    "    [\"Low Competition Markup\", \"Med Competition Markup\", \"High Competition Markup\"]\n",
    ")\n",
    "plt.xlabel(\"Markup of Competition\")\n",
    "plt.ylabel(\"Own Markup\")\n",
    "# plt.title(\"Reset Markup\")\n",
    "# plt.title(\"MIN\")\n",
    "plt.savefig(OUTPUT_PATH_FIGURES + \"polown_reset_\" + \"_\" + exp_names[0] + \"_min\" + \".png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "reg_react_prob_low = linregress(markup, move_prob_lowmu)\n",
    "reg_react_prob_med = linregress(markup, move_prob_medmu)\n",
    "reg_react_prob_high = linregress(markup, move_prob_highmu)\n",
    "reg_react_reset_low = linregress(markup, reset_lowmu)\n",
    "reg_react_reset_med = linregress(markup, reset_medmu)\n",
    "reg_react_reset_high = linregress(markup, reset_highmu)\n",
    "slope_react_prob_low = reg_react_prob_low[0]\n",
    "slope_react_prob_med = reg_react_prob_med[0]\n",
    "slope_react_prob_high = reg_react_prob_high[0]\n",
    "slope_react_reset_low = reg_react_reset_low[0]\n",
    "slope_react_reset_med = reg_react_reset_med[0]\n",
    "slope_react_reset_high = reg_react_reset_high[0]\n",
    "\n",
    "print(\"Slope of own react, low\", [slope_react_prob_low, slope_react_reset_low])\n",
    "print(\"Slope of own react, med\", [slope_react_prob_med, slope_react_reset_med])\n",
    "print(\"Slope of own react, high\", [slope_react_prob_high, slope_react_reset_high])\n",
    "\n",
    "\"\"\" Policy Function with respect to monetary policy. \"\"\"\n",
    "\n",
    "mon_policy = [0.75       \n",
    "    + (i / 19) * 0.5\n",
    "    for i in range(20)\n",
    "]\n",
    "# print(mon_policy)\n",
    "if not OBS_IDSHOCK:\n",
    "    obs_monpol_lowmu = [\n",
    "        np.array([1.2, 1.3] + [1.165, mon_policy[i]], dtype=np.float32)\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    obs_monpol_medmu = [\n",
    "        np.array([1.3, 1.3] + [1.165, mon_policy[i]], dtype=np.float32)\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    obs_monpol_highmu = [\n",
    "        np.array([1.5, 1.3] + [1.165, mon_policy[i]], dtype=np.float32)\n",
    "        for i in range(20)\n",
    "    ]\n",
    "else:\n",
    "    obs_monpol_lowmu = [\n",
    "        np.array([1.2, 1.3, 1, 1] + [1.165, mon_policy[i]], dtype=np.float32)\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    obs_monpol_medmu = [\n",
    "        np.array([1.3, 1.3, 1, 1] + [1.165, mon_policy[i]], dtype=np.float32)\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    obs_monpol_highmu = [\n",
    "        np.array([1.5, 1.3, 1, 1] + [1.165, mon_policy[i]], dtype=np.float32)\n",
    "        for i in range(20)\n",
    "    ]\n",
    "\n",
    "actions_monpol_lowmu = [\n",
    "    trained_trainer.compute_action(obs_monpol_lowmu[i], policy_id=\"firm_even\")\n",
    "    for i in range(20)\n",
    "]\n",
    "actions_monpol_medmu = [\n",
    "    trained_trainer.compute_action(obs_monpol_medmu[i], policy_id=\"firm_even\")\n",
    "    for i in range(20)\n",
    "]\n",
    "actions_monpol_highmu = [\n",
    "    trained_trainer.compute_action(obs_monpol_highmu[i], policy_id=\"firm_even\")\n",
    "    for i in range(20)\n",
    "]\n",
    "move_prob_lowmu = [(actions_monpol_lowmu[i][0] + 1) / 2 for i in range(20)]\n",
    "reset_lowmu = [1 + (actions_monpol_lowmu[i][1] + 1) / 2 for i in range(20)]\n",
    "move_prob_medmu = [(actions_monpol_medmu[i][0] + 1) / 2 for i in range(20)]\n",
    "reset_medmu = [1 + (actions_monpol_medmu[i][1] + 1) / 2 for i in range(20)]\n",
    "move_prob_highmu = [(actions_monpol_highmu[i][0] + 1) / 2 for i in range(20)]\n",
    "reset_highmu = [1 + (actions_monpol_highmu[i][1] + 1) / 2 for i in range(20)]\n",
    "# print(actions_monpol_lowmu, \"\\n\",\n",
    "#     actions_monpol_highmu)\n",
    "x = mon_policy\n",
    "plt.plot(x, move_prob_lowmu)\n",
    "# plt.plot(x,move_prob_medmu)\n",
    "plt.plot(x, move_prob_highmu)\n",
    "plt.axvline(x=1.0212, linestyle='--')\n",
    "plt.legend([\"Low Markup Firms\", \"High Markup Firms\"])\n",
    "plt.xlabel(\"Money Growth\")\n",
    "plt.ylabel(\"Prob. of Adjustment\")\n",
    "# plt.title(\"Effect of money growth on Prob. of Adj.\")\n",
    "# plt.title(\"MIN\")\n",
    "plt.savefig(OUTPUT_PATH_FIGURES + \"polmon_prob_\" + exp_names[0] + \"_min\" + \".png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(x, reset_lowmu)\n",
    "# plt.plot(x,reset_medmu)\n",
    "plt.plot(x, reset_highmu)\n",
    "plt.axvline(x=1.0212, linestyle='--')\n",
    "plt.legend([\"Low Markup Firms\", \"High Markup Firms\"])\n",
    "plt.xlabel(\"Money Growth\")\n",
    "plt.ylabel(\"Reset Markup\")\n",
    "\n",
    "# plt.title(\"Effec of money growth on Size of Adj.\")\n",
    "# plt.title(\"MIN\")\n",
    "plt.savefig(OUTPUT_PATH_FIGURES + \"polmon_reset_\" + exp_names[0] + \"_min\" + \".png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "reg_mon_prob_low = linregress(mon_policy, move_prob_lowmu)\n",
    "slope_mon_prob_low = reg_mon_prob_low[0]\n",
    "reg_mon_prob_high = linregress(mon_policy, move_prob_highmu)\n",
    "slope_mon_prob_high = reg_mon_prob_high[0]\n",
    "\n",
    "reg_mon_reset_low = linregress(mon_policy, reset_lowmu)\n",
    "slope_mon_reset_low = reg_mon_prob_low[0]\n",
    "reg_mon_reset_high = linregress(mon_policy, reset_highmu)\n",
    "slope_mon_reset_high = reg_mon_reset_high[0]\n",
    "\n",
    "print(\"Slope to mon, low\", [slope_mon_prob_low, slope_mon_reset_low])\n",
    "print(\"Slope to mon, high\", [slope_mon_prob_high, slope_mon_reset_high])\n",
    "\n",
    "\"\"\" Reaction Function to comepition markup with constant z \"\"\"\n",
    "\n",
    "markup = [1.2 + (i / 19)*0.6 for i in range(20)]\n",
    "if not OBS_IDSHOCK:\n",
    "    obs_reaction_lowmu = [\n",
    "        np.array(\n",
    "            [1.2, markup[i]] + [1.165, math.e ** env.params[\"log_g_bar\"]],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    obs_reaction_medmu = [\n",
    "        np.array(\n",
    "            [1.3, markup[i]] + [1.165, math.e ** env.params[\"log_g_bar\"]],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    obs_reaction_highmu = [\n",
    "        np.array(\n",
    "            [1.5, markup[i]] + [1.165, math.e ** env.params[\"log_g_bar\"]],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        for i in range(20)\n",
    "    ]\n",
    "else:\n",
    "    obs_reaction_lowmu = [\n",
    "        np.array(\n",
    "            [1.2, markup[i], 1, 1] + [1.165, math.e ** env.params[\"log_g_bar\"]],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    obs_reaction_medmu = [\n",
    "        np.array(\n",
    "            [1.3, markup[i], 1, 1] + [1.165, math.e ** env.params[\"log_g_bar\"]],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        for i in range(20)\n",
    "    ]\n",
    "    obs_reaction_highmu = [\n",
    "        np.array(\n",
    "            [1.5, markup[i], 1, 1] + [1.165, math.e ** env.params[\"log_g_bar\"]],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        for i in range(20)\n",
    "    ]\n",
    "\n",
    "actions_reaction_lowmu = [\n",
    "    trained_trainer.compute_action(obs_reaction_lowmu[i], policy_id=\"firm_even\")\n",
    "    for i in range(20)\n",
    "]\n",
    "actions_reaction_medmu = [\n",
    "    trained_trainer.compute_action(obs_reaction_medmu[i], policy_id=\"firm_even\")\n",
    "    for i in range(20)\n",
    "]\n",
    "actions_reaction_highmu = [\n",
    "    trained_trainer.compute_action(obs_reaction_highmu[i], policy_id=\"firm_even\")\n",
    "    for i in range(20)\n",
    "]\n",
    "move_prob_lowmu = [(actions_reaction_lowmu[i][0] + 1) / 2 for i in range(20)]\n",
    "reset_lowmu = [1 + (actions_reaction_lowmu[i][1] + 1) / 2 for i in range(20)]\n",
    "move_prob_medmu = [(actions_reaction_medmu[i][0] + 1) / 2 for i in range(20)]\n",
    "reset_medmu = [1 + (actions_reaction_medmu[i][1] + 1) / 2 for i in range(20)]\n",
    "move_prob_highmu = [(actions_reaction_highmu[i][0] + 1) / 2 for i in range(20)]\n",
    "reset_highmu = [1 + (actions_reaction_highmu[i][1] + 1) / 2 for i in range(20)]\n",
    "\n",
    "x = markup\n",
    "plt.plot(x, move_prob_lowmu)\n",
    "plt.plot(x, move_prob_medmu)\n",
    "plt.plot(x, move_prob_highmu)\n",
    "plt.axvline(x=1.2, linestyle='--')\n",
    "plt.axvline(x=1.3, linestyle='--')\n",
    "plt.axvline(x=1.5, linestyle='--')\n",
    "plt.ylim([0, 0.4])\n",
    "plt.legend([\"Low Markup Firms\", \"Med Markup Firms\", \"High Markup Firms\"])\n",
    "plt.xlabel(\"Markup of Competition\")\n",
    "plt.ylabel(\"Prob. of Adjustment\")\n",
    "# plt.title(\"Reaction Function - Probability of Adjustment\")\n",
    "# plt.title(\"MIN\")\n",
    "plt.savefig(OUTPUT_PATH_FIGURES + \"polreact_prob_\" + exp_names[0] + \"_min\" + \".png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(x, reset_lowmu)\n",
    "plt.plot(x, reset_medmu)\n",
    "plt.plot(x, reset_highmu)\n",
    "plt.axvline(x=1.2, linestyle='--')\n",
    "plt.axvline(x=1.3, linestyle='--')\n",
    "plt.axvline(x=1.5, linestyle='--')\n",
    "plt.legend([\"Low Markup Firms\", \"Med Markup Firms\", \"High Markup Firms\"])\n",
    "plt.xlabel(\"Markup of Competition\")\n",
    "plt.ylabel(\"Reset Markup\")\n",
    "# plt.title(\"Reaction Function - Reset Markup\")\n",
    "# plt.title(\"MIN\")\n",
    "plt.savefig(OUTPUT_PATH_FIGURES + \"polreact_reset_\" + exp_names[0] + \"_min\" + \".png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "reg_react_prob_low = linregress(markup, move_prob_lowmu)\n",
    "reg_react_prob_med = linregress(markup, move_prob_medmu)\n",
    "reg_react_prob_high = linregress(markup, move_prob_highmu)\n",
    "reg_react_reset_low = linregress(markup, reset_lowmu)\n",
    "reg_react_reset_med = linregress(markup, reset_medmu)\n",
    "reg_react_reset_high = linregress(markup, reset_highmu)\n",
    "slope_react_prob_low = reg_react_prob_low[0]\n",
    "slope_react_prob_med = reg_react_prob_med[0]\n",
    "slope_react_prob_high = reg_react_prob_high[0]\n",
    "slope_react_reset_low = reg_react_reset_low[0]\n",
    "slope_react_reset_med = reg_react_reset_med[0]\n",
    "slope_react_reset_high = reg_react_reset_high[0]\n",
    "\n",
    "print(\"Slope of react, low\", [slope_react_prob_low, slope_react_reset_low])\n",
    "print(\"Slope of react, med\", [slope_react_prob_med, slope_react_reset_med])\n",
    "print(\"Slope of react, high\", [slope_react_prob_high, slope_react_reset_high])\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\" SIMULATE EPSIODES AND CALCULATE REGRESSIONS\"\"\"\n",
    "\n",
    "shutdown()\n",
    "init(\n",
    "    num_cpus=48,\n",
    "    log_to_driver=False,\n",
    ")\n",
    "# register environment\n",
    "env_label = \"mon_policy_finite\"\n",
    "register_env(env_label, MonPolicy)\n",
    "# We instantiate the environment to extract information.\n",
    "\"\"\" CHANGE HERE \"\"\"\n",
    "ENV_HORIZON = 5000\n",
    "env_config_eval[\"horizon\"] = 5000\n",
    "env_config_simul = env_config_eval.copy()\n",
    "env_config_simul[\"random_eval\"] = False\n",
    "#env_config_simul[\"n_inds\"]=5000\n",
    "env_config_simul[\"horizon\"] = SIMUL_EPISODES*ENV_HORIZON\n",
    "env_config_noagg = env_config_simul.copy()\n",
    "env_config_noagg[\"no_agg\"] = True\n",
    "env = MonPolicy(env_config_simul)\n",
    "env_noagg = MonPolicy(env_config_noagg)\n",
    "\n",
    "\"\"\" Restore trainer \"\"\"\n",
    "\n",
    "# restore the trainer\n",
    "\n",
    "trained_trainer = PPOTrainer(env=env_label, config=config_algo)\n",
    "trained_trainer.restore(checkpoints[0])\n",
    "\n",
    "\"\"\" Simulate an episode (SIMUL_PERIODS timesteps) \"\"\"\n",
    "profits_list = []\n",
    "mu_ij_list = []\n",
    "mu_list = []\n",
    "freq_p_adj_list = []\n",
    "size_adj_list = []\n",
    "freq_adj_lowmu_list = []\n",
    "freq_adj_highmu_list = []\n",
    "size_adj_list = []\n",
    "size_adj_lowmu_list = []\n",
    "size_adj_highmu_list = []\n",
    "z_list = []\n",
    "log_c_list = []\n",
    "epsilon_g_list = []\n",
    "\n",
    "profits_list_noagg = []\n",
    "mu_ij_list_noagg = []\n",
    "mu_list_noagg = []\n",
    "freq_p_adj_list_noagg = []\n",
    "freq_adj_lowmu_list_noagg = []\n",
    "freq_adj_highmu_list_noagg = []\n",
    "size_adj_list_noagg = []\n",
    "size_adj_lowmu_list_noagg = []\n",
    "size_adj_highmu_list_noagg = []\n",
    "z_list_noagg = []\n",
    "log_c_list_noagg = []\n",
    "\n",
    "log_c_filt_list = []\n",
    "freq_adj_lowmu_filt_list = []\n",
    "freq_adj_highmu_filt_list = []\n",
    "size_adj_lowmu_filt_list = []\n",
    "size_adj_highmu_filt_list = []\n",
    "\n",
    "# loop with agg\n",
    "seed = random.randrange(100000)\n",
    "env.seed_eval = seed\n",
    "env_noagg.seed_eval = seed\n",
    "obs = env.reset()\n",
    "obs_noagg = env_noagg.reset()\n",
    "for t in range(SIMUL_EPISODES * ENV_HORIZON):\n",
    "    if t % 50 == 0:\n",
    "        print(t)\n",
    "    # if t % env.horizon == 0:\n",
    "    #     seed = random.randrange(100000)\n",
    "    #     env.seed_eval = seed\n",
    "    #     env_noagg.seed_eval = seed\n",
    "    #     print(\"time:\", t)\n",
    "    #     obs = env.reset()\n",
    "    #     obs_noagg = env_noagg.reset()\n",
    "    action = {\n",
    "        i: trained_trainer.compute_action(obs[i], policy_id=\"firm_even\")\n",
    "        if i % 2 == 0\n",
    "        else trained_trainer.compute_action(obs[i], policy_id=\"firm_odd\")\n",
    "        for i in range(env.n_agents)\n",
    "    }\n",
    "    action_noagg = {\n",
    "        i: trained_trainer.compute_action(obs_noagg[i], policy_id=\"firm_even\")\n",
    "        if i % 2 == 0\n",
    "        else trained_trainer.compute_action(obs_noagg[i], policy_id=\"firm_odd\")\n",
    "        for i in range(env.n_agents)\n",
    "    }\n",
    "\n",
    "    obs, rew, done, info = env.step(action)\n",
    "    obs_noagg, rew_noagg, done_noagg, info_noagg = env_noagg.step(action_noagg)\n",
    "\n",
    "    profits_list.append(info[0][\"mean_profits\"])\n",
    "    mu_ij_list.append(info[0][\"mean_mu_ij\"])\n",
    "    mu_list.append(info[0][\"mu\"])\n",
    "    freq_p_adj_list.append(info[0][\"move_freq\"])\n",
    "    freq_adj_lowmu_list.append(info[0][\"move_freq_lowmu\"])\n",
    "    freq_adj_highmu_list.append(info[0][\"move_freq_highmu\"])\n",
    "    size_adj_list.append(info[0][\"mean_p_change\"])\n",
    "    size_adj_lowmu_list.append(info[0][\"size_adj_lowmu\"])\n",
    "    size_adj_highmu_list.append(info[0][\"size_adj_highmu\"])\n",
    "    log_c_list.append(info[0][\"log_c\"])\n",
    "    epsilon_g_list.append(env.epsilon_g)\n",
    "    z_list.append(env.epsilon_z[0])\n",
    "    profits_list_noagg.append(info_noagg[0][\"mean_profits\"])\n",
    "    mu_ij_list_noagg.append(info_noagg[0][\"mean_mu_ij\"])\n",
    "    mu_list_noagg.append(info_noagg[0][\"mu\"])\n",
    "    freq_p_adj_list_noagg.append(info_noagg[0][\"move_freq\"])\n",
    "    freq_adj_lowmu_list_noagg.append(info_noagg[0][\"move_freq_lowmu\"])\n",
    "    freq_adj_highmu_list_noagg.append(info_noagg[0][\"move_freq_highmu\"])\n",
    "    size_adj_list_noagg.append(info_noagg[0][\"mean_p_change\"])\n",
    "    size_adj_lowmu_list_noagg.append(info_noagg[0][\"size_adj_lowmu\"])\n",
    "    size_adj_highmu_list_noagg.append(info_noagg[0][\"size_adj_highmu\"])\n",
    "    log_c_list_noagg.append(info_noagg[0][\"log_c\"])\n",
    "    log_c_filt_list.append(log_c_list[-1] - log_c_list_noagg[-1])\n",
    "    freq_adj_lowmu_filt_list.append(\n",
    "        freq_adj_lowmu_list[-1] - freq_adj_lowmu_list_noagg[-1]\n",
    "    )\n",
    "    freq_adj_highmu_filt_list.append(\n",
    "        freq_adj_highmu_list[-1] - freq_adj_highmu_list_noagg[-1]\n",
    "    )\n",
    "    size_adj_lowmu_filt_list.append(\n",
    "        size_adj_lowmu_list[-1] - size_adj_lowmu_list_noagg[-1]\n",
    "    )\n",
    "    size_adj_highmu_filt_list.append(\n",
    "        size_adj_highmu_list[-1] - size_adj_highmu_list_noagg[-1]\n",
    "    )\n",
    "    z_list_noagg.append(env_noagg.epsilon_z[0])\n",
    "\n",
    "\"\"\" PLOT IRS and PROCESS RESULTS\"\"\"\n",
    "\n",
    "simul_results_dict = {\n",
    "    \"Mean Profits\": [],\n",
    "    \"S.D. Profits\": [],\n",
    "    \"Max Profits\": [],\n",
    "    \"Min Profits\": [],\n",
    "    \"Mean Markups\": [],\n",
    "    \"S.D. Markups\": [],\n",
    "    \"Max Markups\": [],\n",
    "    \"Min Markups\": [],\n",
    "    \"Mean Freq. of Adj.\": [],\n",
    "    \"S.D. Freq. of Adj.\": [],\n",
    "    \"Max Freq. of Adj.\": [],\n",
    "    \"Min Freq. of Adj.\": [],\n",
    "    \"Mean Size of Adj.\": [],\n",
    "    \"S.D. Size of Adj.\": [],\n",
    "    \"Max Size of Adj.\": [],\n",
    "    \"Min Size of Adj.\": [],\n",
    "    \"Mean Agg. Markup\": [],\n",
    "    \"S.D. log C\": [],\n",
    "    \"IRs\": [],\n",
    "    \"cum_IRs\": [],\n",
    "}\n",
    "# epsilon_g_pereps = [\n",
    "#     epsilon_g_list[i * ENV_HORIZON : i * ENV_HORIZON + ENV_HORIZON]\n",
    "#     for i in range(SIMUL_EPISODES)\n",
    "# ]\n",
    "# log_c_filt_pereps = [\n",
    "#     log_c_filt_list[i * ENV_HORIZON : i * ENV_HORIZON + ENV_HORIZON]\n",
    "#     for i in range(SIMUL_EPISODES)\n",
    "# ]\n",
    "# freq_adj_lowmu_pereps = [\n",
    "#     freq_adj_lowmu_filt_list[i * ENV_HORIZON : i * ENV_HORIZON + ENV_HORIZON]\n",
    "#     for i in range(SIMUL_EPISODES)\n",
    "# ]\n",
    "# freq_adj_highmu_pereps = [\n",
    "#     freq_adj_highmu_filt_list[i * ENV_HORIZON : i * ENV_HORIZON + ENV_HORIZON]\n",
    "#     for i in range(SIMUL_EPISODES)\n",
    "# ]\n",
    "# size_adj_lowmu_pereps = [\n",
    "#     size_adj_lowmu_filt_list[i * ENV_HORIZON : i * ENV_HORIZON + ENV_HORIZON]\n",
    "#     for i in range(SIMUL_EPISODES)\n",
    "# ]\n",
    "# size_adj_highmu_pereps = [\n",
    "#     size_adj_highmu_filt_list[i * ENV_HORIZON : i * ENV_HORIZON + ENV_HORIZON]\n",
    "#     for i in range(SIMUL_EPISODES)\n",
    "# ]\n",
    "delta_log_c = [j - i for i, j in zip(log_c_filt_list[:-1], log_c_filt_list[1:])]\n",
    "\n",
    "\n",
    "# print(\"log_c_filt:\", log_c_filt_list, \"\\n\",\n",
    "#     #\"delta_log_c:\", delta_log_c,\n",
    "#     \"\\n\"\n",
    "print(\n",
    "    \"corr betweeen cons:\",\n",
    "    np.corrcoef(log_c_list, log_c_list_noagg),\n",
    ")\n",
    "print(\n",
    "    \"corr betweeen z:\",\n",
    "    np.corrcoef(z_list, z_list_noagg),\n",
    ")\n",
    "plt.plot(log_c_filt_list)\n",
    "plt.title(\"A. Log C filtered\")\n",
    "# plt.show()\n",
    "plt.close()\n",
    "\n",
    "IRs = [0 for t in range(13)]\n",
    "IRs_freqlow = [0 for t in range(13)]\n",
    "IRs_freqhigh = [0 for t in range(13)]\n",
    "IRs_sizelow = [0 for t in range(13)]\n",
    "IRs_sizehigh = [0 for t in range(13)]\n",
    "for t in range(0, 13):\n",
    "    epsilon_g_reg = epsilon_g_list[: -(t + 1)] \n",
    "    delta_log_c_reg = delta_log_c[t:] \n",
    "    freq_adj_lowmu_reg = freq_adj_lowmu_list[t+1:]\n",
    "    freq_adj_highmu_reg = freq_adj_highmu_list[t+1:]\n",
    "    size_adj_lowmu_reg = size_adj_lowmu_list[t+1:] \n",
    "    size_adj_highmu_reg = size_adj_highmu_list[t+1:] \n",
    "\n",
    "    epsilon_g_reg_filt = [i for i in epsilon_g_reg if i > 0]\n",
    "    delta_log_c_reg_filt = [\n",
    "        delta_log_c_reg[i]\n",
    "        for i in range(len(epsilon_g_reg))\n",
    "        if epsilon_g_reg[i] > 0\n",
    "    ]\n",
    "    freq_adj_lowmu_reg_filt = [\n",
    "        freq_adj_lowmu_reg[i]\n",
    "        for i in range(len(epsilon_g_reg))\n",
    "        if epsilon_g_reg[i] > 0\n",
    "    ]\n",
    "    freq_adj_highmu_reg_filt = [\n",
    "        freq_adj_highmu_reg[i]\n",
    "        for i in range(len(epsilon_g_reg))\n",
    "        if epsilon_g_reg[i] > 0\n",
    "    ]\n",
    "    size_adj_lowmu_reg_filt = [\n",
    "        size_adj_lowmu_reg[i]\n",
    "        for i in range(len(epsilon_g_reg))\n",
    "        if epsilon_g_reg[i] > 0\n",
    "    ]\n",
    "    size_adj_highmu_reg_filt = [\n",
    "        size_adj_highmu_reg[i]\n",
    "        for i in range(len(epsilon_g_reg))\n",
    "        if epsilon_g_reg[i] > 0\n",
    "    ]\n",
    "    # epsilon_g_reg_filt = [i for i in epsilon_g_reg if i>0.007]\n",
    "    # delta_log_c_reg_filt = [delta_log_c_reg[i] for i in range(len(epsilon_g_reg)) if epsilon_g_reg[i]>0.007]\n",
    "    # freq_adj_lowmu_reg_filt = [freq_adj_lowmu_reg[i] for i in range(len(epsilon_g_reg)) if epsilon_g_reg[i]>0.007]\n",
    "    # freq_adj_highmu_reg_filt = [freq_adj_highmu_reg[i] for i in range(len(epsilon_g_reg)) if epsilon_g_reg[i]>0.007]\n",
    "    # size_adj_lowmu_reg_filt = [size_adj_lowmu_reg[i] for i in range(len(epsilon_g_reg)) if epsilon_g_reg[i]>0.007]\n",
    "    # size_adj_highmu_reg_filt = [size_adj_highmu_reg[i] for i in range(len(epsilon_g_reg)) if epsilon_g_reg[i]>0.007]\n",
    "\n",
    "    # regressions\n",
    "    reg_c = linregress(delta_log_c_reg, epsilon_g_reg)\n",
    "    IRs[t] = reg_c[0] * env.params[\"sigma_g\"] * 100\n",
    "    reg_freqlow = linregress(freq_adj_lowmu_reg_filt, epsilon_g_reg_filt)\n",
    "    IRs_freqlow[t] = reg_freqlow[0] * env.params[\"sigma_g\"] * 100\n",
    "    reg_freqhigh = linregress(freq_adj_highmu_reg_filt, epsilon_g_reg_filt)\n",
    "    IRs_freqhigh[t] = reg_freqhigh[0] * env.params[\"sigma_g\"] * 100\n",
    "    reg_sizelow = linregress(size_adj_lowmu_reg_filt, epsilon_g_reg_filt)\n",
    "    IRs_sizelow[t] = reg_sizelow[0] * env.params[\"sigma_g\"] * 100\n",
    "    reg_sizehigh = linregress(size_adj_highmu_reg_filt, epsilon_g_reg_filt)\n",
    "    IRs_sizehigh[t] = reg_sizehigh[0] * env.params[\"sigma_g\"] * 100\n",
    "cum_IRs = [np.sum(IRs[:t]) for t in range(13)]\n",
    "cum_IRs_freqlow = [np.sum(IRs_freqlow[:t]) for t in range(13)]\n",
    "cum_IRs_freqhigh = [np.sum(IRs_freqhigh[:t]) for t in range(13)]\n",
    "cum_IRs_sizelow = [np.sum(IRs_sizelow[:t]) for t in range(13)]\n",
    "cum_IRs_sizehigh = [np.sum(IRs_sizehigh[:t]) for t in range(13)]\n",
    "\n",
    "print(\n",
    "    \"cum_IRs_freqlow:\",\n",
    "    cum_IRs_freqlow[3],\n",
    "    \"\\n\",\n",
    "    \"cum_IRs_freqhigh:\",\n",
    "    cum_IRs_freqhigh[3],\n",
    "    \"\\n\",\n",
    "    \"cum_IRs_sizelow:\",\n",
    "    cum_IRs_sizelow[3],\n",
    "    \"\\n\",\n",
    "    \"cum_IRs_sizehigh:\",\n",
    "    cum_IRs_sizehigh[3],\n",
    "    \"\\n\",\n",
    ")\n",
    "\n",
    "simul_results_dict[\"Mean Profits\"].append(np.mean(profits_list))\n",
    "simul_results_dict[\"S.D. Profits\"].append(np.std(profits_list))\n",
    "simul_results_dict[\"Max Profits\"].append(np.max(profits_list))\n",
    "simul_results_dict[\"Min Profits\"].append(np.min(profits_list))\n",
    "simul_results_dict[\"Mean Markups\"].append(np.mean(mu_ij_list))\n",
    "simul_results_dict[\"S.D. Markups\"].append(np.std(mu_ij_list))\n",
    "simul_results_dict[\"Max Markups\"].append(np.max(mu_ij_list))\n",
    "simul_results_dict[\"Min Markups\"].append(np.min(mu_ij_list))\n",
    "simul_results_dict[\"Mean Freq. of Adj.\"].append(np.mean(freq_p_adj_list))\n",
    "simul_results_dict[\"S.D. Freq. of Adj.\"].append(np.std(freq_p_adj_list))\n",
    "simul_results_dict[\"Max Freq. of Adj.\"].append(np.max(freq_p_adj_list))\n",
    "simul_results_dict[\"Min Freq. of Adj.\"].append(np.min(freq_p_adj_list))\n",
    "simul_results_dict[\"Mean Size of Adj.\"].append(np.mean(size_adj_list))\n",
    "simul_results_dict[\"S.D. Size of Adj.\"].append(np.std(size_adj_list))\n",
    "simul_results_dict[\"Max Size of Adj.\"].append(np.max(size_adj_list))\n",
    "simul_results_dict[\"Min Size of Adj.\"].append(np.min(size_adj_list))\n",
    "simul_results_dict[\"Mean Agg. Markup\"].append(np.mean(mu_list))\n",
    "simul_results_dict[\"S.D. log C\"].append(np.std(log_c_filt_list))\n",
    "simul_results_dict[\"IRs\"].append(IRs)\n",
    "simul_results_dict[\"cum_IRs\"].append(cum_IRs)\n",
    "# simul_results_dict[\"IRs_freqlow\"].append(IRs_freqlow)\n",
    "# simul_results_dict[\"IRs_freqhigh\"].append(IRs_freqhigh)\n",
    "# simul_results_dict[\"IRs_sizelow\"].append(IRs_sizelow)\n",
    "# simul_results_dict[\"IRs_sizehigh\"].append(IRs_sizehigh)\n",
    "\n",
    "print(\"Simul_results_dict:\", simul_results_dict)\n",
    "# print(\n",
    "#     \"std_log_c:\",\n",
    "#     simul_results_dict[\"S.D. log C\"],\n",
    "#     \"\\n\" + \"mu_ij:\",\n",
    "#     simul_results_dict[\"Mean Markups\"],\n",
    "#     \"\\n\" + \"freq_p_adj:\",\n",
    "#     simul_results_dict[\"Mean Freq. of Adj.\"],\n",
    "#     \"\\n\" + \"size_adj:\",\n",
    "#     simul_results_dict[\"Mean Size of Adj.\"],\n",
    "# )\n",
    "\n",
    "\"\"\" Plot IRs \"\"\"\n",
    "x = [i for i in range(13)]\n",
    "IRs = simul_results_dict[\"IRs\"][-1]\n",
    "plt.plot(x, IRs)\n",
    "# learning_plot = learning_plot.get_figure()\n",
    "plt.ylabel(\"Delta log C_t * 100\")\n",
    "plt.xlabel(\"Month t\")\n",
    "plt.ylim([-2.5,15])\n",
    "# plt.title(\"A. IRF - Consumption\")\n",
    "# plt.title(\"MIN\")\n",
    "plt.savefig(OUTPUT_PATH_FIGURES + \"IRs_\" + exp_names[0] + \"_min\" + \".png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "cum_IRs = simul_results_dict[\"cum_IRs\"][-1]\n",
    "plt.plot(x, cum_IRs)\n",
    "# learning_plot = learning_plot.get_figure()\n",
    "plt.ylabel(\"Delta log C_t * 100\")\n",
    "plt.xlabel(\"Month t\")\n",
    "\n",
    "# plt.title(\"B. Cumulative IRF - Consumption\")\n",
    "# plt.title(\"MIN\")\n",
    "plt.savefig(OUTPUT_PATH_FIGURES + \"cum_IRs_\" + exp_names[0] + \"_min\" + \".png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(x, IRs_freqlow)\n",
    "plt.plot(x, IRs_freqhigh)\n",
    "plt.legend([\"Low Markup Firms\", \"High Markup Firms\"])\n",
    "# learning_plot = learning_plot.get_figure()\n",
    "plt.ylabel(\"IRF - Levels * 100\")\n",
    "plt.xlabel(\"Month t\")\n",
    "# plt.title(\"IRF - Frquency of Adjustment for High vs Low Markup Firms\")\n",
    "# plt.title(\"MIN\")\n",
    "plt.savefig(OUTPUT_PATH_FIGURES + \"IRs_freq_\" + exp_names[0] + \"_min\" + \".png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(x, IRs_sizelow)\n",
    "plt.plot(x, IRs_sizehigh)\n",
    "plt.legend([\"Low Markup Firms\", \"High Markup Firms\"])\n",
    "# learning_plot = learning_plot.get_figure()\n",
    "plt.ylabel(\"IRF - Levels * 100\")\n",
    "plt.xlabel(\"Month t\")\n",
    "\n",
    "# plt.title(\"IRF - Size of Adjustment for High vs Low Markup Firms\")\n",
    "# plt.title(\"MIN\")\n",
    "plt.savefig(OUTPUT_PATH_FIGURES + \"IRs_size_\" + exp_names[0] + \"_min\" + \".png\")\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit"
  },
  "interpreter": {
   "hash": "8224d246b14b2208f890fdb89e47115b5f8e692495415cd25627316c2fdf7014"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}