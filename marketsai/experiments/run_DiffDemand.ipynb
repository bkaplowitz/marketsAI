{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python387jvsc74a57bd01c99579f0a861f1ade1e1abc4784a15ca138f424327e789e2dba1116d0806699",
   "display_name": "Python 3.8.7 64-bit ('marketsai-reVLCGV_-py3.8')"
  },
  "metadata": {
   "interpreter": {
    "hash": "1c99579f0a861f1ade1e1abc4784a15ca138f424327e789e2dba1116d0806699"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Playing Differentiated Demand Environemnt"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "WARNING:tensorflow:From /Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "{'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "\n",
    "from marketsai.markets.diff_demand import DiffDemand\n",
    "\n",
    "#import ray\n",
    "\n",
    "from ray import tune, shutdown, init\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.agents.a3c.a2c import A2CTrainer\n",
    "from ray.rllib.agents.dqn.dqn import DQNTrainer\n",
    "from ray.tune.integration.mlflow import MLflowLoggerCallback\n",
    "from ray.rllib.utils.schedules.exponential_schedule import ExponentialSchedule\n",
    "\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.202',\n",
       " 'raylet_ip_address': '192.168.1.202',\n",
       " 'redis_address': '192.168.1.202:18536',\n",
       " 'object_store_address': '/tmp/ray/session_2021-04-11_12-42-56_244925_76877/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-04-11_12-42-56_244925_76877/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2021-04-11_12-42-56_244925_76877',\n",
       " 'metrics_export_port': 64203,\n",
       " 'node_id': 'ab4292b0ee968b2d660073a3fe4930d67935de526069de415bb0aaa6'}"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# STEP 0: Inititialize ray\n",
    "NUM_CPUS = 12\n",
    "shutdown()\n",
    "init(num_cpus=NUM_CPUS, \n",
    "    logging_level=logging.ERROR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: register environment\n",
    "register_env(\"diffdemand\", DiffDemand)\n",
    "env = DiffDemand()\n",
    "policy_ids = [f\"policy_{i}\" for i in range(env.n_agents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Experiment configuration\n",
    "\n",
    "MAX_STEPS = 20 * 1000\n",
    "PRICE_BAND_WIDE = 0.1\n",
    "LOWER_PRICE = 1.47 - PRICE_BAND_WIDE\n",
    "HIGHER_PRICE = 1.93 + PRICE_BAND_WIDE\n",
    "DEC_RATE = math.e ** (-4 * 10 ** (-6))\n",
    "DEC_RATE_HIGH = math.e ** (-4 * 10 ** (-6) * 4)\n",
    "\n",
    "env_config = {\n",
    "    \"mkt_config\": {\n",
    "    \"lower_price\": [LOWER_PRICE for i in range(env.n_agents)],\n",
    "    \"higher_price\": [HIGHER_PRICE for i in range(env.n_agents)],\n",
    "    \"parameteres\": {\n",
    "                \"cost\": [1 for i in range(env.n_agents)],\n",
    "                \"values\": [2 for i in range(env.n_agents)],\n",
    "                \"ext_demand\": 0,\n",
    "                \"substitution\": 0.25,\n",
    "    },\n",
    "    \"space_type\": \"MultiDiscrete\",\n",
    "    \"gridpoints\": 16,\n",
    "    }\n",
    "}\n",
    "\n",
    "exploration_config = {\n",
    "    \"type\": \"EpsilonGreedy\",\n",
    "    \"epsilon_schedule\": ExponentialSchedule(\n",
    "        schedule_timesteps=1,\n",
    "        framework=None,\n",
    "        initial_p=1,\n",
    "        decay_rate=DEC_RATE,\n",
    "    ),\n",
    "}\n",
    "\n",
    "training_config = {\n",
    "    \"gamma\": 0.95,\n",
    "    \"lr\": 0.15,\n",
    "    \"env\": \"diffdemand\",\n",
    "    \"exploration_config\": exploration_config,\n",
    "    \"env_config\": env_config,\n",
    "    \"horizon\": 100,\n",
    "    \"soft_horizon\": True,\n",
    "    \"no_done_at_end\": True,\n",
    "    \"multiagent\": {\n",
    "        \"policies\": {\n",
    "            policy_ids[i]: (\n",
    "                None,\n",
    "                env.observation_space[\"agent_{}\".format(i)],\n",
    "                env.action_space[\"agent_{}\".format(i)],\n",
    "                {},\n",
    "            )\n",
    "            for i in range(env.n_agents)\n",
    "        },\n",
    "        \"policy_mapping_fn\": (lambda agent_id: policy_ids[int(agent_id.split(\"_\")[1])]),\n",
    "    },\n",
    "    \"framework\": \"torch\",\n",
    "    \"num_workers\": NUM_CPUS - 1,\n",
    "    \"num_gpus\": 0,\n",
    "}\n",
    "\n",
    "stop = {\"info/num_steps_trained\": MAX_STEPS}"
   ]
  },
  {
   "source": [
    "#Step 3: Experiments\n",
    "\n",
    "exp_name = \"DQN_test_April9\"\n",
    "results = tune.run(\n",
    "    \"DQN\",\n",
    "    name=exp_name,\n",
    "    config=training_config,\n",
    "    checkpoint_freq=250,\n",
    "    checkpoint_at_end=True,\n",
    "    stop=stop,\n",
    "    metric=\"episode_reward_mean\",\n",
    "    mode=\"max\",\n",
    "    callbacks=[MLflowLoggerCallback(experiment_name=exp_name, save_artifact=True)],\n",
    ")\n",
    "\n",
    "best_checkpoint = results.best_checkpoint\n",
    "print(\"Best checkpont:\", best_checkpoint)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 12.8/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12/12 CPUs, 0/0 GPUs, 0.0/12.84 GiB heap, 0.0/4.44 GiB objects<br>Result logdir: /Users/matiascovarrubias/ray_results/DQN_test_April9<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc  </th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_diffdemand_f918e_00000</td><td>RUNNING </td><td>     </td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "rrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "\u001b[2m\u001b[36m(pid=78908)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[36m(pid=78903)\u001b[0m /Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "\u001b[2m\u001b[36m(pid=78903)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[36m(pid=78906)\u001b[0m WARNING:tensorflow:From /Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=78906)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=78906)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=78910)\u001b[0m WARNING:tensorflow:From /Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=78910)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=78910)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=78907)\u001b[0m WARNING:tensorflow:From /Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=78907)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=78907)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=78902)\u001b[0m WARNING:tensorflow:From /Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=78902)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=78902)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=78911)\u001b[0m WARNING:tensorflow:From /Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=78911)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=78911)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=78905)\u001b[0m WARNING:tensorflow:From /Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=78905)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=78905)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=78904)\u001b[0m WARNING:tensorflow:From /Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=78904)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=78904)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=78909)\u001b[0m WARNING:tensorflow:From /Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=78909)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=78909)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=78901)\u001b[0m WARNING:tensorflow:From /Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=78901)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=78901)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=78908)\u001b[0m WARNING:tensorflow:From /Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=78908)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=78908)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=78903)\u001b[0m WARNING:tensorflow:From /Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=78903)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=78903)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=78906)\u001b[0m {'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n",
      "\u001b[2m\u001b[36m(pid=78911)\u001b[0m {'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n",
      "\u001b[2m\u001b[36m(pid=78910)\u001b[0m {'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n",
      "\u001b[2m\u001b[36m(pid=78907)\u001b[0m {'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n",
      "\u001b[2m\u001b[36m(pid=78905)\u001b[0m {'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n",
      "\u001b[2m\u001b[36m(pid=78902)\u001b[0m {'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n",
      "\u001b[2m\u001b[36m(pid=78904)\u001b[0m {'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n",
      "\u001b[2m\u001b[36m(pid=78909)\u001b[0m {'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n",
      "\u001b[2m\u001b[36m(pid=78908)\u001b[0m {'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n",
      "\u001b[2m\u001b[36m(pid=78901)\u001b[0m {'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n",
      "\u001b[2m\u001b[36m(pid=78910)\u001b[0m 2021-04-11 12:43:04,322\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78910)\u001b[0m 2021-04-11 12:43:04,328\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78906)\u001b[0m 2021-04-11 12:43:04,316\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78906)\u001b[0m 2021-04-11 12:43:04,322\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78906)\u001b[0m 2021-04-11 12:43:04,362\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78906)\u001b[0m 2021-04-11 12:43:04,367\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78907)\u001b[0m 2021-04-11 12:43:04,357\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78907)\u001b[0m 2021-04-11 12:43:04,364\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78911)\u001b[0m 2021-04-11 12:43:04,364\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78905)\u001b[0m 2021-04-11 12:43:04,346\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78905)\u001b[0m 2021-04-11 12:43:04,353\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78911)\u001b[0m 2021-04-11 12:43:04,371\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78912)\u001b[0m 2021-04-11 12:43:04,422\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78910)\u001b[0m 2021-04-11 12:43:04,375\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78910)\u001b[0m 2021-04-11 12:43:04,379\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78902)\u001b[0m 2021-04-11 12:43:04,377\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78902)\u001b[0m 2021-04-11 12:43:04,383\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78907)\u001b[0m 2021-04-11 12:43:04,409\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78907)\u001b[0m 2021-04-11 12:43:04,414\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78911)\u001b[0m 2021-04-11 12:43:04,416\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78911)\u001b[0m 2021-04-11 12:43:04,422\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78905)\u001b[0m 2021-04-11 12:43:04,396\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78905)\u001b[0m 2021-04-11 12:43:04,400\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78909)\u001b[0m 2021-04-11 12:43:04,418\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78909)\u001b[0m 2021-04-11 12:43:04,425\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78904)\u001b[0m 2021-04-11 12:43:04,383\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78904)\u001b[0m 2021-04-11 12:43:04,389\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78912)\u001b[0m 2021-04-11 12:43:04,429\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78902)\u001b[0m 2021-04-11 12:43:04,432\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78904)\u001b[0m 2021-04-11 12:43:04,433\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78912)\u001b[0m 2021-04-11 12:43:04,474\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78912)\u001b[0m 2021-04-11 12:43:04,478\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78902)\u001b[0m 2021-04-11 12:43:04,436\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78909)\u001b[0m 2021-04-11 12:43:04,468\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78909)\u001b[0m 2021-04-11 12:43:04,472\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78904)\u001b[0m 2021-04-11 12:43:04,437\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78901)\u001b[0m 2021-04-11 12:43:04,467\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78901)\u001b[0m 2021-04-11 12:43:04,472\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78908)\u001b[0m 2021-04-11 12:43:04,473\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78908)\u001b[0m 2021-04-11 12:43:04,479\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78901)\u001b[0m 2021-04-11 12:43:04,508\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78901)\u001b[0m 2021-04-11 12:43:04,511\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78908)\u001b[0m 2021-04-11 12:43:04,513\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78908)\u001b[0m 2021-04-11 12:43:04,516\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78903)\u001b[0m 2021-04-11 12:43:04,494\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78903)\u001b[0m 2021-04-11 12:43:04,499\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78903)\u001b[0m 2021-04-11 12:43:04,531\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78903)\u001b[0m 2021-04-11 12:43:04,534\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78903)\u001b[0m {'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n",
      "\u001b[2m\u001b[36m(pid=78912)\u001b[0m 2021-04-11 12:43:04,572\tWARNING util.py:47 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=78906)\u001b[0m 2021-04-11 12:43:04,581\tWARNING deprecation.py:33 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\n",
      "Result for DQN_diffdemand_f918e_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2021-04-11_12-43-05\n",
      "  done: false\n",
      "  episode_len_mean: .nan\n",
      "  episode_reward_max: .nan\n",
      "  episode_reward_mean: .nan\n",
      "  episode_reward_min: .nan\n",
      "  episodes_this_iter: 0\n",
      "  episodes_total: 0\n",
      "  experiment_id: ee9e90f38ff94c029b1754ffc1ecea6a\n",
      "  hostname: Matiass-MBP.fios-router.home\n",
      "  info:\n",
      "    last_target_update_ts: 1012\n",
      "    learner:\n",
      "      policy_0:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.15\n",
      "        grad_gnorm: 0.3065624237060547\n",
      "        max_q: 0.14168305695056915\n",
      "        mean_q: 0.009598798118531704\n",
      "        mean_td_error: -0.19503958523273468\n",
      "        min_q: -0.12402226030826569\n",
      "      policy_1:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.15\n",
      "        grad_gnorm: 0.49390795826911926\n",
      "        max_q: 0.21436527371406555\n",
      "        mean_q: 0.021365074440836906\n",
      "        mean_td_error: -0.32077279686927795\n",
      "        min_q: -0.14936164021492004\n",
      "    num_steps_sampled: 1012\n",
      "    num_steps_trained: 32\n",
      "    num_target_updates: 1\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.1.202\n",
      "  num_healthy_workers: 11\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.6\n",
      "    ram_util_percent: 45.1\n",
      "  pid: 78912\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf: {}\n",
      "  time_since_restore: 0.6619420051574707\n",
      "  time_this_iter_s: 0.6619420051574707\n",
      "  time_total_s: 0.6619420051574707\n",
      "  timers:\n",
      "    learn_throughput: 2076.677\n",
      "    learn_time_ms: 15.409\n",
      "    update_time_ms: 2.738\n",
      "  timestamp: 1618159385\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1012\n",
      "  training_iteration: 1\n",
      "  trial_id: f918e_00000\n",
      "  \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 14.4/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12/12 CPUs, 0/0 GPUs, 0.0/12.84 GiB heap, 0.0/4.44 GiB objects<br>Result logdir: /Users/matiascovarrubias/ray_results/DQN_test_April9<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_diffdemand_f918e_00000</td><td>RUNNING </td><td>192.168.1.202:78912</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.661942</td><td style=\"text-align: right;\">1012</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">                 nan</td><td style=\"text-align: right;\">               nan</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Result for DQN_diffdemand_f918e_00000:\n  custom_metrics: {}\n  date: 2021-04-11_12-43-11\n  done: false\n  episode_len_mean: 100.0\n  episode_reward_max: 55.75359489802493\n  episode_reward_mean: 54.01029982842044\n  episode_reward_min: 51.842024196182635\n  episodes_this_iter: 11\n  episodes_total: 55\n  experiment_id: ee9e90f38ff94c029b1754ffc1ecea6a\n  hostname: Matiass-MBP.fios-router.home\n  info:\n    last_target_update_ts: 5764\n    learner:\n      policy_0:\n        allreduce_latency: 0.0\n        cur_lr: 0.15\n        grad_gnorm: 6.867670059204102\n        max_q: 20.781890869140625\n        mean_q: 20.386672973632812\n        mean_td_error: -0.8119003176689148\n        min_q: 20.08861541748047\n      policy_1:\n        allreduce_latency: 0.0\n        cur_lr: 0.15\n        grad_gnorm: 10.586507797241211\n        max_q: 29.594013214111328\n        mean_q: 29.096073150634766\n        mean_td_error: -1.4710311889648438\n        min_q: 28.4183292388916\n    num_steps_sampled: 6072\n    num_steps_trained: 3712\n    num_target_updates: 10\n  iterations_since_restore: 6\n  node_ip: 192.168.1.202\n  num_healthy_workers: 11\n  off_policy_estimator: {}\n  perf:\n    cpu_util_percent: 42.5\n    ram_util_percent: 44.5\n  pid: 78912\n  policy_reward_max:\n    policy_0: 28.730953733846743\n    policy_1: 29.077219472189004\n  policy_reward_mean:\n    policy_0: 26.946454232593744\n    policy_1: 27.06384559582671\n  policy_reward_min:\n    policy_0: 24.72852765892512\n    policy_1: 24.648767595460278\n  sampler_perf:\n    mean_action_processing_ms: 0.10804589859093307\n    mean_env_wait_ms: 0.19114056464802534\n    mean_inference_ms: 2.730883630669567\n    mean_raw_obs_processing_ms: 0.30697909044255717\n  time_since_restore: 6.186180114746094\n  time_this_iter_s: 1.131479024887085\n  time_total_s: 6.186180114746094\n  timers:\n    learn_throughput: 2701.449\n    learn_time_ms: 11.845\n    update_time_ms: 2.838\n  timestamp: 1618159391\n  timesteps_since_restore: 0\n  timesteps_total: 6072\n  training_iteration: 6\n  trial_id: f918e_00000\n  \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 14.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12/12 CPUs, 0/0 GPUs, 0.0/12.84 GiB heap, 0.0/4.44 GiB objects<br>Current best trial: f918e_00000 with episode_reward_mean=54.01029982842044 and parameters={'num_workers': 11, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'num_framestacks': 'auto', 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1, 'framestack': True}, 'optimizer': {}, 'gamma': 0.95, 'horizon': 100, 'soft_horizon': True, 'no_done_at_end': True, 'env_config': {'mkt_config': {'lower_price': [1.3699999999999999, 1.3699999999999999], 'higher_price': [2.03, 2.03], 'parameteres': {'cost': [1, 1], 'values': [2, 2], 'ext_demand': 0, 'substitution': 0.25}, 'space_type': 'MultiDiscrete', 'gridpoints': 16}}, 'env': 'diffdemand', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.15, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000, 'epsilon_schedule': <ray.rllib.utils.schedules.exponential_schedule.ExponentialSchedule object at 0x32f522310>}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': True, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 1, 'timesteps_per_iteration': 1000, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'policy_0': (<class 'ray.rllib.policy.policy_template.DQNTorchPolicy'>, MultiDiscrete([16 16]), Discrete(16), {}), 'policy_1': (<class 'ray.rllib.policy.policy_template.DQNTorchPolicy'>, MultiDiscrete([16 16]), Discrete(16), {})}, 'policy_mapping_fn': <function <lambda> at 0x32f4bdf70>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, 'replay_sequence_length': 1, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'target_network_update_freq': 500, 'buffer_size': 50000, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'worker_side_prioritization': False}<br>Result logdir: /Users/matiascovarrubias/ray_results/DQN_test_April9<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_diffdemand_f918e_00000</td><td>RUNNING </td><td>192.168.1.202:78912</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         6.18618</td><td style=\"text-align: right;\">6072</td><td style=\"text-align: right;\"> 54.0103</td><td style=\"text-align: right;\">             55.7536</td><td style=\"text-align: right;\">              51.842</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Result for DQN_diffdemand_f918e_00000:\n  custom_metrics: {}\n  date: 2021-04-11_12-43-16\n  done: false\n  episode_len_mean: 100.0\n  episode_reward_max: 56.43396344392134\n  episode_reward_mean: 54.01199301153643\n  episode_reward_min: 51.842024196182635\n  episodes_this_iter: 11\n  episodes_total: 110\n  experiment_id: ee9e90f38ff94c029b1754ffc1ecea6a\n  hostname: Matiass-MBP.fios-router.home\n  info:\n    last_target_update_ts: 11044\n    learner:\n      policy_0:\n        allreduce_latency: 0.0\n        cur_lr: 0.15\n        grad_gnorm: 0.7731075286865234\n        max_q: 14.714235305786133\n        mean_q: 14.628247261047363\n        mean_td_error: 0.10454440116882324\n        min_q: 14.3974609375\n      policy_1:\n        allreduce_latency: 0.0\n        cur_lr: 0.15\n        grad_gnorm: 9.93505859375\n        max_q: 26.750146865844727\n        mean_q: 26.208890914916992\n        mean_td_error: -1.6404714584350586\n        min_q: 25.756208419799805\n    num_steps_sampled: 11132\n    num_steps_trained: 7392\n    num_target_updates: 20\n  iterations_since_restore: 11\n  node_ip: 192.168.1.202\n  num_healthy_workers: 11\n  off_policy_estimator: {}\n  perf:\n    cpu_util_percent: 36.55\n    ram_util_percent: 44.150000000000006\n  pid: 78912\n  policy_reward_max:\n    policy_0: 28.730953733846743\n    policy_1: 29.40186572145593\n  policy_reward_mean:\n    policy_0: 27.027076465703043\n    policy_1: 26.984916545833393\n  policy_reward_min:\n    policy_0: 24.59819405538378\n    policy_1: 24.648767595460278\n  sampler_perf:\n    mean_action_processing_ms: 0.1103993527873526\n    mean_env_wait_ms: 0.19509420485228557\n    mean_inference_ms: 2.7899230616415087\n    mean_raw_obs_processing_ms: 0.3155182280626627\n  time_since_restore: 11.749414920806885\n  time_this_iter_s: 1.0487399101257324\n  time_total_s: 11.749414920806885\n  timers:\n    learn_throughput: 2869.378\n    learn_time_ms: 11.152\n    update_time_ms: 3.26\n  timestamp: 1618159396\n  timesteps_since_restore: 0\n  timesteps_total: 11132\n  training_iteration: 11\n  trial_id: f918e_00000\n  \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 14.1/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12/12 CPUs, 0/0 GPUs, 0.0/12.84 GiB heap, 0.0/4.44 GiB objects<br>Current best trial: f918e_00000 with episode_reward_mean=54.01199301153643 and parameters={'num_workers': 11, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'num_framestacks': 'auto', 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1, 'framestack': True}, 'optimizer': {}, 'gamma': 0.95, 'horizon': 100, 'soft_horizon': True, 'no_done_at_end': True, 'env_config': {'mkt_config': {'lower_price': [1.3699999999999999, 1.3699999999999999], 'higher_price': [2.03, 2.03], 'parameteres': {'cost': [1, 1], 'values': [2, 2], 'ext_demand': 0, 'substitution': 0.25}, 'space_type': 'MultiDiscrete', 'gridpoints': 16}}, 'env': 'diffdemand', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.15, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000, 'epsilon_schedule': <ray.rllib.utils.schedules.exponential_schedule.ExponentialSchedule object at 0x32f533ee0>}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': True, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 1, 'timesteps_per_iteration': 1000, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'policy_0': (<class 'ray.rllib.policy.policy_template.DQNTorchPolicy'>, MultiDiscrete([16 16]), Discrete(16), {}), 'policy_1': (<class 'ray.rllib.policy.policy_template.DQNTorchPolicy'>, MultiDiscrete([16 16]), Discrete(16), {})}, 'policy_mapping_fn': <function <lambda> at 0x32f4bd160>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, 'replay_sequence_length': 1, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'target_network_update_freq': 500, 'buffer_size': 50000, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'worker_side_prioritization': False}<br>Result logdir: /Users/matiascovarrubias/ray_results/DQN_test_April9<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_diffdemand_f918e_00000</td><td>RUNNING </td><td>192.168.1.202:78912</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         11.7494</td><td style=\"text-align: right;\">11132</td><td style=\"text-align: right;\">  54.012</td><td style=\"text-align: right;\">              56.434</td><td style=\"text-align: right;\">              51.842</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Result for DQN_diffdemand_f918e_00000:\n  custom_metrics: {}\n  date: 2021-04-11_12-43-22\n  done: false\n  episode_len_mean: 100.0\n  episode_reward_max: 56.43396344392134\n  episode_reward_mean: 53.98719032104319\n  episode_reward_min: 51.50473145881207\n  episodes_this_iter: 11\n  episodes_total: 154\n  experiment_id: ee9e90f38ff94c029b1754ffc1ecea6a\n  hostname: Matiass-MBP.fios-router.home\n  info:\n    last_target_update_ts: 15796\n    learner:\n      policy_0:\n        allreduce_latency: 0.0\n        cur_lr: 0.15\n        grad_gnorm: 0.3602942228317261\n        max_q: 11.354568481445312\n        mean_q: 11.246343612670898\n        mean_td_error: -0.07885903120040894\n        min_q: 11.158952713012695\n      policy_1:\n        allreduce_latency: 0.0\n        cur_lr: 0.15\n        grad_gnorm: 4.929232597351074\n        max_q: 23.707910537719727\n        mean_q: 23.138309478759766\n        mean_td_error: 0.618185818195343\n        min_q: 22.65872573852539\n    num_steps_sampled: 16192\n    num_steps_trained: 11072\n    num_target_updates: 29\n  iterations_since_restore: 16\n  node_ip: 192.168.1.202\n  num_healthy_workers: 11\n  off_policy_estimator: {}\n  perf:\n    cpu_util_percent: 36.45\n    ram_util_percent: 43.95\n  pid: 78912\n  policy_reward_max:\n    policy_0: 28.654949301274215\n    policy_1: 29.68592800084589\n  policy_reward_mean:\n    policy_0: 27.030764975205894\n    policy_1: 26.95642534583728\n  policy_reward_min:\n    policy_0: 24.59819405538378\n    policy_1: 24.600700163138292\n  sampler_perf:\n    mean_action_processing_ms: 0.10995674170887001\n    mean_env_wait_ms: 0.1947554002911915\n    mean_inference_ms: 2.7864484816186934\n    mean_raw_obs_processing_ms: 0.3160811837790185\n  time_since_restore: 16.89269733428955\n  time_this_iter_s: 1.0290839672088623\n  time_total_s: 16.89269733428955\n  timers:\n    learn_throughput: 2938.146\n    learn_time_ms: 10.891\n    update_time_ms: 2.578\n  timestamp: 1618159402\n  timesteps_since_restore: 0\n  timesteps_total: 16192\n  training_iteration: 16\n  trial_id: f918e_00000\n  \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 14.0/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12/12 CPUs, 0/0 GPUs, 0.0/12.84 GiB heap, 0.0/4.44 GiB objects<br>Current best trial: f918e_00000 with episode_reward_mean=53.98719032104319 and parameters={'num_workers': 11, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'num_framestacks': 'auto', 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1, 'framestack': True}, 'optimizer': {}, 'gamma': 0.95, 'horizon': 100, 'soft_horizon': True, 'no_done_at_end': True, 'env_config': {'mkt_config': {'lower_price': [1.3699999999999999, 1.3699999999999999], 'higher_price': [2.03, 2.03], 'parameteres': {'cost': [1, 1], 'values': [2, 2], 'ext_demand': 0, 'substitution': 0.25}, 'space_type': 'MultiDiscrete', 'gridpoints': 16}}, 'env': 'diffdemand', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.15, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000, 'epsilon_schedule': <ray.rllib.utils.schedules.exponential_schedule.ExponentialSchedule object at 0x32f5395b0>}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': True, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 1, 'timesteps_per_iteration': 1000, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'policy_0': (<class 'ray.rllib.policy.policy_template.DQNTorchPolicy'>, MultiDiscrete([16 16]), Discrete(16), {}), 'policy_1': (<class 'ray.rllib.policy.policy_template.DQNTorchPolicy'>, MultiDiscrete([16 16]), Discrete(16), {})}, 'policy_mapping_fn': <function <lambda> at 0x32f4bdca0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, 'replay_sequence_length': 1, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'target_network_update_freq': 500, 'buffer_size': 50000, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'worker_side_prioritization': False}<br>Result logdir: /Users/matiascovarrubias/ray_results/DQN_test_April9<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_diffdemand_f918e_00000</td><td>RUNNING </td><td>192.168.1.202:78912</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         16.8927</td><td style=\"text-align: right;\">16192</td><td style=\"text-align: right;\"> 53.9872</td><td style=\"text-align: right;\">              56.434</td><td style=\"text-align: right;\">             51.5047</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Result for DQN_diffdemand_f918e_00000:\n  custom_metrics: {}\n  date: 2021-04-11_12-43-28\n  done: false\n  episode_len_mean: 100.0\n  episode_reward_max: 56.10127282266444\n  episode_reward_mean: 53.91735816583372\n  episode_reward_min: 51.50473145881207\n  episodes_this_iter: 11\n  episodes_total: 198\n  experiment_id: ee9e90f38ff94c029b1754ffc1ecea6a\n  hostname: Matiass-MBP.fios-router.home\n  info:\n    last_target_update_ts: 20020\n    learner:\n      policy_0:\n        allreduce_latency: 0.0\n        cur_lr: 0.15\n        grad_gnorm: 0.3151823580265045\n        max_q: 10.43964672088623\n        mean_q: 10.296015739440918\n        mean_td_error: 0.08040344715118408\n        min_q: 10.209168434143066\n      policy_1:\n        allreduce_latency: 0.0\n        cur_lr: 0.15\n        grad_gnorm: 3.440507411956787\n        max_q: 19.6735782623291\n        mean_q: 19.40223503112793\n        mean_td_error: 0.4582366347312927\n        min_q: 19.154346466064453\n    num_steps_sampled: 20240\n    num_steps_trained: 14016\n    num_target_updates: 37\n  iterations_since_restore: 20\n  node_ip: 192.168.1.202\n  num_healthy_workers: 11\n  off_policy_estimator: {}\n  perf:\n    cpu_util_percent: 36.75\n    ram_util_percent: 43.75\n  pid: 78912\n  policy_reward_max:\n    policy_0: 28.84050154583545\n    policy_1: 29.68592800084589\n  policy_reward_mean:\n    policy_0: 26.868999898409115\n    policy_1: 27.0483582674246\n  policy_reward_min:\n    policy_0: 24.59819405538378\n    policy_1: 24.082724193891053\n  sampler_perf:\n    mean_action_processing_ms: 0.10868567846657048\n    mean_env_wait_ms: 0.19332682578751864\n    mean_inference_ms: 2.7662678330658803\n    mean_raw_obs_processing_ms: 0.3141984354119482\n  time_since_restore: 22.358835220336914\n  time_this_iter_s: 1.5423579216003418\n  time_total_s: 22.358835220336914\n  timers:\n    learn_throughput: 1940.76\n    learn_time_ms: 16.488\n    update_time_ms: 3.881\n  timestamp: 1618159408\n  timesteps_since_restore: 0\n  timesteps_total: 20240\n  training_iteration: 20\n  trial_id: f918e_00000\n  \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 14.0/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12/12 CPUs, 0/0 GPUs, 0.0/12.84 GiB heap, 0.0/4.44 GiB objects<br>Current best trial: f918e_00000 with episode_reward_mean=53.91735816583372 and parameters={'num_workers': 11, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'num_framestacks': 'auto', 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1, 'framestack': True}, 'optimizer': {}, 'gamma': 0.95, 'horizon': 100, 'soft_horizon': True, 'no_done_at_end': True, 'env_config': {'mkt_config': {'lower_price': [1.3699999999999999, 1.3699999999999999], 'higher_price': [2.03, 2.03], 'parameteres': {'cost': [1, 1], 'values': [2, 2], 'ext_demand': 0, 'substitution': 0.25}, 'space_type': 'MultiDiscrete', 'gridpoints': 16}}, 'env': 'diffdemand', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.15, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000, 'epsilon_schedule': <ray.rllib.utils.schedules.exponential_schedule.ExponentialSchedule object at 0x32f540340>}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': True, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 1, 'timesteps_per_iteration': 1000, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'policy_0': (<class 'ray.rllib.policy.policy_template.DQNTorchPolicy'>, MultiDiscrete([16 16]), Discrete(16), {}), 'policy_1': (<class 'ray.rllib.policy.policy_template.DQNTorchPolicy'>, MultiDiscrete([16 16]), Discrete(16), {})}, 'policy_mapping_fn': <function <lambda> at 0x192b3e550>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, 'replay_sequence_length': 1, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'target_network_update_freq': 500, 'buffer_size': 50000, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'worker_side_prioritization': False}<br>Result logdir: /Users/matiascovarrubias/ray_results/DQN_test_April9<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_diffdemand_f918e_00000</td><td>RUNNING </td><td>192.168.1.202:78912</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         22.3588</td><td style=\"text-align: right;\">20240</td><td style=\"text-align: right;\"> 53.9174</td><td style=\"text-align: right;\">             56.1013</td><td style=\"text-align: right;\">             51.5047</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Result for DQN_diffdemand_f918e_00000:\n  custom_metrics: {}\n  date: 2021-04-11_12-43-34\n  done: false\n  episode_len_mean: 100.0\n  episode_reward_max: 56.10127282266444\n  episode_reward_mean: 53.79899414840168\n  episode_reward_min: 51.003203070556395\n  episodes_this_iter: 11\n  episodes_total: 242\n  experiment_id: ee9e90f38ff94c029b1754ffc1ecea6a\n  hostname: Matiass-MBP.fios-router.home\n  info:\n    last_target_update_ts: 24244\n    learner:\n      policy_0:\n        allreduce_latency: 0.0\n        cur_lr: 0.15\n        grad_gnorm: 0.5087904930114746\n        max_q: 9.608529090881348\n        mean_q: 9.54943561553955\n        mean_td_error: 0.1322161853313446\n        min_q: 9.494189262390137\n      policy_1:\n        allreduce_latency: 0.0\n        cur_lr: 0.15\n        grad_gnorm: 2.358651638031006\n        max_q: 15.642867088317871\n        mean_q: 15.448034286499023\n        mean_td_error: 0.3398239314556122\n        min_q: 15.209811210632324\n    num_steps_sampled: 24288\n    num_steps_trained: 16960\n    num_target_updates: 45\n  iterations_since_restore: 24\n  node_ip: 192.168.1.202\n  num_healthy_workers: 11\n  off_policy_estimator: {}\n  perf:\n    cpu_util_percent: 36.5\n    ram_util_percent: 43.8\n  pid: 78912\n  policy_reward_max:\n    policy_0: 28.84050154583545\n    policy_1: 29.082719721760657\n  policy_reward_mean:\n    policy_0: 26.64331426228827\n    policy_1: 27.155679886113397\n  policy_reward_min:\n    policy_0: 24.18760285252851\n    policy_1: 24.082724193891053\n  sampler_perf:\n    mean_action_processing_ms: 0.11165376060901101\n    mean_env_wait_ms: 0.19935071507958022\n    mean_inference_ms: 2.851764221900887\n    mean_raw_obs_processing_ms: 0.3252905693204509\n  time_since_restore: 28.542337894439697\n  time_this_iter_s: 1.5917787551879883\n  time_total_s: 28.542337894439697\n  timers:\n    learn_throughput: 1870.612\n    learn_time_ms: 17.107\n    update_time_ms: 5.388\n  timestamp: 1618159414\n  timesteps_since_restore: 0\n  timesteps_total: 24288\n  training_iteration: 24\n  trial_id: f918e_00000\n  \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 14.0/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12/12 CPUs, 0/0 GPUs, 0.0/12.84 GiB heap, 0.0/4.44 GiB objects<br>Current best trial: f918e_00000 with episode_reward_mean=53.79899414840168 and parameters={'num_workers': 11, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'num_framestacks': 'auto', 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1, 'framestack': True}, 'optimizer': {}, 'gamma': 0.95, 'horizon': 100, 'soft_horizon': True, 'no_done_at_end': True, 'env_config': {'mkt_config': {'lower_price': [1.3699999999999999, 1.3699999999999999], 'higher_price': [2.03, 2.03], 'parameteres': {'cost': [1, 1], 'values': [2, 2], 'ext_demand': 0, 'substitution': 0.25}, 'space_type': 'MultiDiscrete', 'gridpoints': 16}}, 'env': 'diffdemand', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.15, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000, 'epsilon_schedule': <ray.rllib.utils.schedules.exponential_schedule.ExponentialSchedule object at 0x32f534670>}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': True, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 1, 'timesteps_per_iteration': 1000, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'policy_0': (<class 'ray.rllib.policy.policy_template.DQNTorchPolicy'>, MultiDiscrete([16 16]), Discrete(16), {}), 'policy_1': (<class 'ray.rllib.policy.policy_template.DQNTorchPolicy'>, MultiDiscrete([16 16]), Discrete(16), {})}, 'policy_mapping_fn': <function <lambda> at 0x32f52c670>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, 'replay_sequence_length': 1, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'target_network_update_freq': 500, 'buffer_size': 50000, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'worker_side_prioritization': False}<br>Result logdir: /Users/matiascovarrubias/ray_results/DQN_test_April9<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_diffdemand_f918e_00000</td><td>RUNNING </td><td>192.168.1.202:78912</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         28.5423</td><td style=\"text-align: right;\">24288</td><td style=\"text-align: right;\">  53.799</td><td style=\"text-align: right;\">             56.1013</td><td style=\"text-align: right;\">             51.0032</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Result for DQN_diffdemand_f918e_00000:\n  custom_metrics: {}\n  date: 2021-04-11_12-43-39\n  done: false\n  episode_len_mean: 100.0\n  episode_reward_max: 56.05073768323267\n  episode_reward_mean: 53.78382867242093\n  episode_reward_min: 51.003203070556395\n  episodes_this_iter: 11\n  episodes_total: 264\n  experiment_id: ee9e90f38ff94c029b1754ffc1ecea6a\n  hostname: Matiass-MBP.fios-router.home\n  info:\n    last_target_update_ts: 26884\n    learner:\n      policy_0:\n        allreduce_latency: 0.0\n        cur_lr: 0.15\n        grad_gnorm: 0.17977513372898102\n        max_q: 8.541720390319824\n        mean_q: 8.428948402404785\n        mean_td_error: -0.06360691785812378\n        min_q: 8.32476806640625\n      policy_1:\n        allreduce_latency: 0.0\n        cur_lr: 0.15\n        grad_gnorm: 0.8584436178207397\n        max_q: 12.674427032470703\n        mean_q: 12.554797172546387\n        mean_td_error: 0.14714717864990234\n        min_q: 12.41058349609375\n    num_steps_sampled: 27324\n    num_steps_trained: 19168\n    num_target_updates: 50\n  iterations_since_restore: 27\n  node_ip: 192.168.1.202\n  num_healthy_workers: 11\n  off_policy_estimator: {}\n  perf:\n    cpu_util_percent: 39.8\n    ram_util_percent: 43.8\n  pid: 78912\n  policy_reward_max:\n    policy_0: 28.555810872526383\n    policy_1: 29.262369698938862\n  policy_reward_mean:\n    policy_0: 26.641414495677868\n    policy_1: 27.142414176743056\n  policy_reward_min:\n    policy_0: 24.18760285252851\n    policy_1: 24.082724193891053\n  sampler_perf:\n    mean_action_processing_ms: 0.11458076528641735\n    mean_env_wait_ms: 0.20486359426203446\n    mean_inference_ms: 2.9294371034362494\n    mean_raw_obs_processing_ms: 0.3352249933879363\n  time_since_restore: 33.292524576187134\n  time_this_iter_s: 1.5895278453826904\n  time_total_s: 33.292524576187134\n  timers:\n    learn_throughput: 1857.163\n    learn_time_ms: 17.231\n    update_time_ms: 4.664\n  timestamp: 1618159419\n  timesteps_since_restore: 0\n  timesteps_total: 27324\n  training_iteration: 27\n  trial_id: f918e_00000\n  \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 14.0/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12/12 CPUs, 0/0 GPUs, 0.0/12.84 GiB heap, 0.0/4.44 GiB objects<br>Current best trial: f918e_00000 with episode_reward_mean=53.78382867242093 and parameters={'num_workers': 11, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'num_framestacks': 'auto', 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1, 'framestack': True}, 'optimizer': {}, 'gamma': 0.95, 'horizon': 100, 'soft_horizon': True, 'no_done_at_end': True, 'env_config': {'mkt_config': {'lower_price': [1.3699999999999999, 1.3699999999999999], 'higher_price': [2.03, 2.03], 'parameteres': {'cost': [1, 1], 'values': [2, 2], 'ext_demand': 0, 'substitution': 0.25}, 'space_type': 'MultiDiscrete', 'gridpoints': 16}}, 'env': 'diffdemand', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.15, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000, 'epsilon_schedule': <ray.rllib.utils.schedules.exponential_schedule.ExponentialSchedule object at 0x32f534910>}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': True, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 1, 'timesteps_per_iteration': 1000, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'policy_0': (<class 'ray.rllib.policy.policy_template.DQNTorchPolicy'>, MultiDiscrete([16 16]), Discrete(16), {}), 'policy_1': (<class 'ray.rllib.policy.policy_template.DQNTorchPolicy'>, MultiDiscrete([16 16]), Discrete(16), {})}, 'policy_mapping_fn': <function <lambda> at 0x32f47de50>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, 'replay_sequence_length': 1, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'target_network_update_freq': 500, 'buffer_size': 50000, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'worker_side_prioritization': False}<br>Result logdir: /Users/matiascovarrubias/ray_results/DQN_test_April9<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_diffdemand_f918e_00000</td><td>RUNNING </td><td>192.168.1.202:78912</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         33.2925</td><td style=\"text-align: right;\">27324</td><td style=\"text-align: right;\"> 53.7838</td><td style=\"text-align: right;\">             56.0507</td><td style=\"text-align: right;\">             51.0032</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Result for DQN_diffdemand_f918e_00000:\n  custom_metrics: {}\n  date: 2021-04-11_12-43-43\n  done: true\n  episode_len_mean: 100.0\n  episode_reward_max: 56.05073768323267\n  episode_reward_mean: 53.68502238109662\n  episode_reward_min: 51.003203070556395\n  episodes_this_iter: 11\n  episodes_total: 286\n  experiment_id: ee9e90f38ff94c029b1754ffc1ecea6a\n  hostname: Matiass-MBP.fios-router.home\n  info:\n    last_target_update_ts: 28996\n    learner:\n      policy_0:\n        allreduce_latency: 0.0\n        cur_lr: 0.15\n        grad_gnorm: 0.3377199172973633\n        max_q: 8.102686882019043\n        mean_q: 8.039983749389648\n        mean_td_error: 0.12461180984973907\n        min_q: 7.962584018707275\n      policy_1:\n        allreduce_latency: 0.0\n        cur_lr: 0.15\n        grad_gnorm: 0.2324407547712326\n        max_q: 10.982880592346191\n        mean_q: 10.808721542358398\n        mean_td_error: -0.041232407093048096\n        min_q: 10.645918846130371\n    num_steps_sampled: 29348\n    num_steps_trained: 20640\n    num_target_updates: 54\n  iterations_since_restore: 29\n  node_ip: 192.168.1.202\n  num_healthy_workers: 11\n  off_policy_estimator: {}\n  perf:\n    cpu_util_percent: 39.349999999999994\n    ram_util_percent: 43.8\n  pid: 78912\n  policy_reward_max:\n    policy_0: 28.555810872526383\n    policy_1: 29.262369698938862\n  policy_reward_mean:\n    policy_0: 26.66537855291701\n    policy_1: 27.019643828179607\n  policy_reward_min:\n    policy_0: 24.18760285252851\n    policy_1: 25.039384936058234\n  sampler_perf:\n    mean_action_processing_ms: 0.11793645814896017\n    mean_env_wait_ms: 0.2110868681598353\n    mean_inference_ms: 3.017315291921032\n    mean_raw_obs_processing_ms: 0.34655542437123416\n  time_since_restore: 36.51482343673706\n  time_this_iter_s: 1.6169090270996094\n  time_total_s: 36.51482343673706\n  timers:\n    learn_throughput: 1772.001\n    learn_time_ms: 18.059\n    update_time_ms: 5.48\n  timestamp: 1618159423\n  timesteps_since_restore: 0\n  timesteps_total: 29348\n  training_iteration: 29\n  trial_id: f918e_00000\n  \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 14.0/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/12.84 GiB heap, 0.0/4.44 GiB objects<br>Current best trial: f918e_00000 with episode_reward_mean=53.68502238109662 and parameters={'num_workers': 11, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 4, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 32, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'num_framestacks': 'auto', 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1, 'framestack': True}, 'optimizer': {}, 'gamma': 0.95, 'horizon': 100, 'soft_horizon': True, 'no_done_at_end': True, 'env_config': {'mkt_config': {'lower_price': [1.3699999999999999, 1.3699999999999999], 'higher_price': [2.03, 2.03], 'parameteres': {'cost': [1, 1], 'values': [2, 2], 'ext_demand': 0, 'substitution': 0.25}, 'space_type': 'MultiDiscrete', 'gridpoints': 16}}, 'env': 'diffdemand', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.15, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 10000, 'epsilon_schedule': <ray.rllib.utils.schedules.exponential_schedule.ExponentialSchedule object at 0x32f534bb0>}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {'explore': False}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': True, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 1, 'timesteps_per_iteration': 1000, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'policy_0': (<class 'ray.rllib.policy.policy_template.DQNTorchPolicy'>, MultiDiscrete([16 16]), Discrete(16), {}), 'policy_1': (<class 'ray.rllib.policy.policy_template.DQNTorchPolicy'>, MultiDiscrete([16 16]), Discrete(16), {})}, 'policy_mapping_fn': <function <lambda> at 0x32f47dca0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, 'replay_sequence_length': 1, 'num_atoms': 1, 'v_min': -10.0, 'v_max': 10.0, 'noisy': False, 'sigma0': 0.5, 'dueling': True, 'hiddens': [256], 'double_q': True, 'n_step': 1, 'target_network_update_freq': 500, 'buffer_size': 50000, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'final_prioritized_replay_beta': 0.4, 'prioritized_replay_beta_annealing_timesteps': 20000, 'prioritized_replay_eps': 1e-06, 'before_learn_on_batch': None, 'training_intensity': None, 'lr_schedule': None, 'adam_epsilon': 1e-08, 'grad_clip': 40, 'learning_starts': 1000, 'worker_side_prioritization': False}<br>Result logdir: /Users/matiascovarrubias/ray_results/DQN_test_April9<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n<thead>\n<tr><th>Trial name                </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>DQN_diffdemand_f918e_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         36.5148</td><td style=\"text-align: right;\">29348</td><td style=\"text-align: right;\">  53.685</td><td style=\"text-align: right;\">             56.0507</td><td style=\"text-align: right;\">             51.0032</td><td style=\"text-align: right;\">               100</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best checkpont: /Users/matiascovarrubias/ray_results/DQN_test_April9/DQN_diffdemand_f918e_00000_0_2021-04-11_12-42-58/checkpoint_29/checkpoint-29\n"
     ]
    }
   ]
  },
  {
   "source": [
    "## Continuous Space\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'gamma': 0.95, 'lr': 0.15, 'env': 'diffdemand', 'exploration_config': {'type': 'EpsilonGreedy', 'epsilon_schedule': <ray.rllib.utils.schedules.exponential_schedule.ExponentialSchedule object at 0x192b5d7c0>}, 'env_config': {'mkt_config': {'lower_price': [1.3699999999999999, 1.3699999999999999], 'higher_price': [2.03, 2.03], 'parameteres': {'cost': [1, 1], 'values': [2, 2], 'ext_demand': 0, 'substitution': 0.25}, 'space_type': 'Continuous', 'gridpoints': 16}}, 'horizon': 100, 'soft_horizon': True, 'no_done_at_end': True, 'multiagent': {'policies': {'policy_0': (None, Box(1.3699999999999999, 2.03, (2,), float64), Box(1.3699999999999999, 2.03, (1,), float64), {}), 'policy_1': (None, Box(1.3699999999999999, 2.03, (2,), float64), Box(1.3699999999999999, 2.03, (1,), float64), {})}, 'policy_mapping_fn': <function <lambda> at 0x192b3e1f0>}, 'framework': 'torch', 'num_workers': 11, 'num_gpus': 0}\n{'agent_0': Box(1.3699999999999999, 2.03, (1,), float64), 'agent_1': Box(1.3699999999999999, 2.03, (1,), float64)}\n"
     ]
    }
   ],
   "source": [
    "env_config[\"mkt_config\"][\"space_type\"] = \"Continuous\"\n",
    "env=DiffDemand(env_config)\n",
    "training_config[\"env_config\"] = env_config\n",
    "training_config[\"multiagent\"][\"policies\"] =  {\n",
    "            policy_ids[i]: (None, env.observation_space[f\"agent_{i}\"], env.action_space[f\"agent_{i}\"],{},) for i in range(env.n_agents)\n",
    "}\n",
    "#print(env_config)\n",
    "print(training_config)\n",
    "print(env.action_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 14.0/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 12/12 CPUs, 0/0 GPUs, 0.0/12.84 GiB heap, 0.0/4.44 GiB objects<br>Result logdir: /Users/matiascovarrubias/ray_results/DDPG_cont_test_April9<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                 </th><th>status  </th><th>loc  </th></tr>\n</thead>\n<tbody>\n<tr><td>DDPG_diffdemand_13c23_00000</td><td>RUNNING </td><td>     </td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ble before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "\u001b[2m\u001b[36m(pid=78987)\u001b[0m   torch.from_numpy(self.action_space.low).float())\n",
      "\u001b[2m\u001b[36m(pid=78987)\u001b[0m 2021-04-11 12:43:52,760\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78981)\u001b[0m {'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n",
      "\u001b[2m\u001b[36m(pid=78982)\u001b[0m {'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n",
      "\u001b[2m\u001b[36m(pid=78983)\u001b[0m {'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n",
      "\u001b[2m\u001b[36m(pid=78984)\u001b[0m {'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n",
      "\u001b[2m\u001b[36m(pid=78985)\u001b[0m {'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n",
      "\u001b[2m\u001b[36m(pid=78987)\u001b[0m {'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n",
      "\u001b[2m\u001b[36m(pid=78985)\u001b[0m 2021-04-11 12:43:52,852\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78985)\u001b[0m 2021-04-11 12:43:52,863\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78987)\u001b[0m 2021-04-11 12:43:52,861\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78989)\u001b[0m 2021-04-11 12:43:52,857\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78989)\u001b[0m /Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/rllib/agents/ddpg/ddpg_torch_model.py:56: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "\u001b[2m\u001b[36m(pid=78989)\u001b[0m   torch.from_numpy(self.action_space.low).float())\n",
      "\u001b[2m\u001b[36m(pid=78991)\u001b[0m 2021-04-11 12:43:52,835\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78991)\u001b[0m /Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/rllib/agents/ddpg/ddpg_torch_model.py:56: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "\u001b[2m\u001b[36m(pid=78991)\u001b[0m   torch.from_numpy(self.action_space.low).float())\n",
      "\u001b[2m\u001b[36m(pid=78991)\u001b[0m 2021-04-11 12:43:52,851\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78993)\u001b[0m 2021-04-11 12:43:52,853\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78993)\u001b[0m /Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/rllib/agents/ddpg/ddpg_torch_model.py:56: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "\u001b[2m\u001b[36m(pid=78993)\u001b[0m   torch.from_numpy(self.action_space.low).float())\n",
      "\u001b[2m\u001b[36m(pid=78989)\u001b[0m 2021-04-11 12:43:52,870\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78993)\u001b[0m 2021-04-11 12:43:52,867\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78973)\u001b[0m 2021-04-11 12:43:52,876\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78987)\u001b[0m 2021-04-11 12:43:52,873\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78973)\u001b[0m 2021-04-11 12:43:52,887\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78995)\u001b[0m 2021-04-11 12:43:52,907\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78995)\u001b[0m /Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/rllib/agents/ddpg/ddpg_torch_model.py:56: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "\u001b[2m\u001b[36m(pid=78995)\u001b[0m   torch.from_numpy(self.action_space.low).float())\n",
      "\u001b[2m\u001b[36m(pid=78995)\u001b[0m 2021-04-11 12:43:52,917\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78989)\u001b[0m 2021-04-11 12:43:52,952\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78989)\u001b[0m 2021-04-11 12:43:52,960\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78991)\u001b[0m 2021-04-11 12:43:52,947\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78991)\u001b[0m 2021-04-11 12:43:52,957\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78993)\u001b[0m 2021-04-11 12:43:52,964\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78993)\u001b[0m 2021-04-11 12:43:52,970\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78995)\u001b[0m 2021-04-11 12:43:52,988\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78997)\u001b[0m 2021-04-11 12:43:52,944\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78997)\u001b[0m /Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/rllib/agents/ddpg/ddpg_torch_model.py:56: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "\u001b[2m\u001b[36m(pid=78997)\u001b[0m   torch.from_numpy(self.action_space.low).float())\n",
      "\u001b[2m\u001b[36m(pid=78997)\u001b[0m 2021-04-11 12:43:52,955\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78973)\u001b[0m 2021-04-11 12:43:53,044\tWARNING util.py:47 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=78995)\u001b[0m 2021-04-11 12:43:52,997\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78997)\u001b[0m 2021-04-11 12:43:53,023\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78997)\u001b[0m 2021-04-11 12:43:53,031\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=78993)\u001b[0m {'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n",
      "\u001b[2m\u001b[36m(pid=78989)\u001b[0m {'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n",
      "\u001b[2m\u001b[36m(pid=78991)\u001b[0m {'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n",
      "\u001b[2m\u001b[36m(pid=78995)\u001b[0m {'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n",
      "\u001b[2m\u001b[36m(pid=78997)\u001b[0m {'agent_0': array([1.6, 1.6]), 'agent_1': array([1.6, 1.6])} {'agent_0': 0.27249236968976237, 'agent_1': 0.27249236968976237} {'__all__': False} {'agent_0': 1.6, 'agent_1': 1.6}\n",
      "\u001b[2m\u001b[36m(pid=78981)\u001b[0m 2021-04-11 12:43:53,107\tWARNING deprecation.py:33 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\n",
      "2021-04-11 12:43:53,153\tERROR trial_runner.py:616 -- Trial DDPG_diffdemand_13c23_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 586, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 609, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 47, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/worker.py\", line 1456, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::DDPG.train_buffered()\u001b[39m (pid=78973, ip=192.168.1.202)\n",
      "  File \"python/ray/_raylet.pyx\", line 480, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 432, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/tune/trainable.py\", line 167, in train_buffered\n",
      "    result = self.train()\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 526, in train\n",
      "    raise e\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 515, in train\n",
      "    result = Trainable.train(self)\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/tune/trainable.py\", line 226, in train\n",
      "    result = self.step()\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\", line 148, in step\n",
      "    res = next(self.train_exec_impl)\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/util/iter.py\", line 756, in __next__\n",
      "    return next(self.built_iterator)\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
      "    for item in it:\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
      "    for item in it:\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
      "    for item in it:\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/util/iter.py\", line 1075, in build_union\n",
      "    item = next(it)\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/util/iter.py\", line 756, in __next__\n",
      "    return next(self.built_iterator)\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
      "    for item in it:\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/util/iter.py\", line 471, in base_iterator\n",
      "    yield ray.get(futures, timeout=timeout)\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 47, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::RolloutWorker.par_iter_next()\u001b[39m (pid=78987, ip=192.168.1.202)\n",
      "  File \"python/ray/_raylet.pyx\", line 480, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 432, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/util/iter.py\", line 1152, in par_iter_next\n",
      "    return next(self.local_it)\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 327, in gen_rollouts\n",
      "    yield self.sample()\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 662, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 95, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 224, in get_data\n",
      "    item = next(self.rollout_provider)\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 651, in _env_runner\n",
      "    eval_results = _do_policy_eval_w_trajectory_view_api(\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 1341, in _do_policy_eval_w_trajectory_view_api\n",
      "    policy.compute_actions_from_input_dict(\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/rllib/policy/torch_policy.py\", line 207, in compute_actions_from_input_dict\n",
      "    return self._compute_action_helper(input_dict, state_batches,\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/rllib/utils/threading.py\", line 21, in wrapper\n",
      "    return func(self, *a, **k)\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/rllib/policy/torch_policy.py\", line 263, in _compute_action_helper\n",
      "    self.exploration.get_exploration_action(\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/rllib/utils/exploration/epsilon_greedy.py\", line 82, in get_exploration_action\n",
      "    return self._get_torch_exploration_action(action_distribution,\n",
      "  File \"/Users/matiascovarrubias/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/rllib/utils/exploration/epsilon_greedy.py\", line 185, in _get_torch_exploration_action\n",
      "    action = torch.where(\n",
      "RuntimeError: expected scalar type long long but found float\n",
      "Result for DDPG_diffdemand_13c23_00000:\n",
      "  {}\n",
      "  \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 14.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/12.84 GiB heap, 0.0/4.44 GiB objects<br>Result logdir: /Users/matiascovarrubias/ray_results/DDPG_cont_test_April9<br>Number of trials: 1/1 (1 ERROR)<br><table>\n<thead>\n<tr><th>Trial name                 </th><th>status  </th><th>loc  </th></tr>\n</thead>\n<tbody>\n<tr><td>DDPG_diffdemand_13c23_00000</td><td>ERROR   </td><td>     </td></tr>\n</tbody>\n</table><br>Number of errored trials: 1<br><table>\n<thead>\n<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                            </th></tr>\n</thead>\n<tbody>\n<tr><td>DDPG_diffdemand_13c23_00000</td><td style=\"text-align: right;\">           1</td><td>/Users/matiascovarrubias/ray_results/DDPG_cont_test_April9/DDPG_diffdemand_13c23_00000_0_2021-04-11_12-43-43/error.txt</td></tr>\n</tbody>\n</table><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Memory usage on this node: 14.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/12.84 GiB heap, 0.0/4.44 GiB objects<br>Result logdir: /Users/matiascovarrubias/ray_results/DDPG_cont_test_April9<br>Number of trials: 1/1 (1 ERROR)<br><table>\n<thead>\n<tr><th>Trial name                 </th><th>status  </th><th>loc  </th></tr>\n</thead>\n<tbody>\n<tr><td>DDPG_diffdemand_13c23_00000</td><td>ERROR   </td><td>     </td></tr>\n</tbody>\n</table><br>Number of errored trials: 1<br><table>\n<thead>\n<tr><th>Trial name                 </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                            </th></tr>\n</thead>\n<tbody>\n<tr><td>DDPG_diffdemand_13c23_00000</td><td style=\"text-align: right;\">           1</td><td>/Users/matiascovarrubias/ray_results/DDPG_cont_test_April9/DDPG_diffdemand_13c23_00000_0_2021-04-11_12-43-43/error.txt</td></tr>\n</tbody>\n</table><br>"
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [DDPG_diffdemand_13c23_00000])",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8ad879bf13a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexp_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"DDPG_cont_test_April9\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m results = tune.run(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"DDPG\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexp_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/marketsai-reVLCGV_-py3.8/lib/python3.8/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, loggers, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [DDPG_diffdemand_13c23_00000])"
     ]
    }
   ],
   "source": [
    "exp_name = \"DDPG_cont_test_April9\"\n",
    "results = tune.run(\n",
    "    \"DDPG\",\n",
    "    name=exp_name,\n",
    "    config=training_config,\n",
    "    checkpoint_freq=250,\n",
    "    checkpoint_at_end=True,\n",
    "    stop=stop,\n",
    "    metric=\"episode_reward_mean\",\n",
    "    mode=\"max\",\n",
    "    callbacks=[MLflowLoggerCallback(experiment_name=exp_name, save_artifact=True)],\n",
    ")\n",
    "\n",
    "best_checkpoint = results.best_checkpoint\n",
    "print(\"Best checkpont:\", best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}