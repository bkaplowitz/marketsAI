{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python387jvsc74a57bd01c99579f0a861f1ade1e1abc4784a15ca138f424327e789e2dba1116d0806699",
   "display_name": "Python 3.8.7 64-bit ('marketsai-reVLCGV_-py3.8')"
  },
  "metadata": {
   "interpreter": {
    "hash": "1c99579f0a861f1ade1e1abc4784a15ca138f424327e789e2dba1116d0806699"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Playing Differentiated Demand Environemnt"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "from marketsai.markets.diff_demand import DiffDemand\n",
    "\n",
    "#import ray\n",
    "\n",
    "from ray import tune, shutdown, init\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.agents.a3c.a2c import A2CTrainer\n",
    "from ray.rllib.agents.dqn.dqn import DQNTrainer\n",
    "from ray.tune.integration.mlflow import MLflowLoggerCallback\n",
    "from ray.rllib.utils.exploration.epsilon_greedy import EpsilonGreedy\n",
    "from ray.rllib.utils.schedules.exponential_schedule import ExponentialSchedule\n",
    "\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.202',\n",
       " 'raylet_ip_address': '192.168.1.202',\n",
       " 'redis_address': '192.168.1.202:52920',\n",
       " 'object_store_address': '/tmp/ray/session_2021-04-13_12-54-20_758294_69994/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-04-13_12-54-20_758294_69994/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8266',\n",
       " 'session_dir': '/tmp/ray/session_2021-04-13_12-54-20_758294_69994',\n",
       " 'metrics_export_port': 62891,\n",
       " 'node_id': '2d99a85dd404a30f067bd27ae6360421d8a2241d8aca447d86fb270c'}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# STEP 0: Inititialize ray\n",
    "NUM_CPUS = 11\n",
    "shutdown()\n",
    "init(num_cpus=NUM_CPUS, \n",
    "    logging_level=logging.ERROR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: register environment\n",
    "register_env(\"diffdemand\", DiffDemand)\n",
    "env = DiffDemand()\n",
    "policy_ids = [f\"policy_{i}\" for i in range(env.n_agents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fd8d6d42c6e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m env_config = {\n\u001b[1;32m     23\u001b[0m     \"mkt_config\": {\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;34m\"lower_price\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mLOWER_PRICE\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_agents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;34m\"higher_price\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mHIGHER_PRICE\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_agents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \"parameteres\": {\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "# STEP 2: Experiment configuration\n",
    "\n",
    "\n",
    "#Experiment configuration\n",
    "test=True\n",
    "date=\"April13\"\n",
    "if (test==True): \n",
    "    MAX_STEPS = 20 * 1000\n",
    "    exp_label =\"_test_\"+date \n",
    "else: MAX_STEPS = 3000 * 1000\n",
    "\n",
    "verbosity=2\n",
    "stop = {\"episodes_total\": MAX_STEPS//100}\n",
    "\n",
    "#Environment configuration\n",
    "PRICE_BAND_WIDE = 0.1\n",
    "LOWER_PRICE = 1.47 - PRICE_BAND_WIDE\n",
    "HIGHER_PRICE = 1.93 + PRICE_BAND_WIDE\n",
    "DEC_RATE = float(math.e ** (-4 * 10 ** (-6)))\n",
    "DEC_RATE_HIGH = float(math.e ** (-4 * 10 ** (-6) * 4))\n",
    "\n",
    "env_config = {\n",
    "    \"mkt_config\": {\n",
    "    \"lower_price\": [LOWER_PRICE for i in range(env.n_agents)],\n",
    "    \"higher_price\": [HIGHER_PRICE for i in range(env.n_agents)],\n",
    "    \"parameteres\": {\n",
    "                \"cost\": [1 for i in range(env.n_agents)],\n",
    "                \"values\": [2 for i in range(env.n_agents)],\n",
    "                \"ext_demand\": 0,\n",
    "                \"substitution\": 0.25,\n",
    "    },\n",
    "    \"space_type\": \"MultiDiscrete\",\n",
    "    \"gridpoints\": 16,\n",
    "    }\n",
    "}\n",
    "\n",
    "exploration_config = {\"type\": \"EpsilonGreedy\",\n",
    "    \"epsilon_schedule\": ExponentialSchedule(\n",
    "      schedule_timesteps = 1,\n",
    "      framework=\"Torch\",\n",
    "      initial_p=1.0,\n",
    "      decay_rate=DEC_RATE,\n",
    "    ),\n",
    "}\n",
    "\n",
    "training_config = {\n",
    "    \"gamma\": 0.95,\n",
    "    \"lr\": 0.15,\n",
    "    \"env\": \"diffdemand\",\n",
    "    \"exploration_config\": exploration_config,\n",
    "    \"env_config\": env_config,\n",
    "    \"horizon\": 100,\n",
    "    \"soft_horizon\": True,\n",
    "    \"no_done_at_end\": True,\n",
    "    \"multiagent\": {\n",
    "        \"policies\": {\n",
    "            policy_ids[i]: (\n",
    "                None,\n",
    "                env.observation_space[\"agent_{}\".format(i)],\n",
    "                env.action_space[\"agent_{}\".format(i)],\n",
    "                {},\n",
    "            )\n",
    "            for i in range(env.n_agents)\n",
    "        },\n",
    "        \"policy_mapping_fn\": (lambda agent_id: policy_ids[int(agent_id.split(\"_\")[1])]),\n",
    "    },\n",
    "    \"framework\": \"torch\",\n",
    "    \"num_workers\": NUM_CPUS - 1,\n",
    "    \"num_gpus\": 0,\n",
    "    \"timesteps_per_iteration\": 1000,\n",
    "    \"normalize_actions\": False,\n",
    "}\n",
    "\n",
    "\n",
    "#stop = {\"training_iteration\": MAX_STEPS//1000}\n",
    "#stop = {\"info/num_steps_trained\": MAX_STEPS}"
   ]
  },
  {
   "source": [
    "#Step 3: Experiments\n",
    "\n",
    "#DQN Methods: DQN, \n",
    "\n",
    "exp_name = \"DQN_test_April13\"\n",
    "results = tune.run(\n",
    "    \"DQN\",\n",
    "    name=exp_name,\n",
    "    config=training_config,\n",
    "    #checkpoint_freq=250,\n",
    "    checkpoint_at_end=True,\n",
    "    stop=stop,\n",
    "    callbacks=[MLflowLoggerCallback(experiment_name=exp_name, save_artifact=True)],\n",
    "    verbose=verbosity\n",
    ")\n",
    "\n",
    "# exp_name = \"APEXDQN_test_April13\"\n",
    "# results = tune.run(\n",
    "#     \"APEX\",\n",
    "#     name=exp_name,\n",
    "#     config=training_config,\n",
    "#     #checkpoint_freq=250,\n",
    "#     checkpoint_at_end=True,\n",
    "#     stop=stop,\n",
    "#     callbacks=[MLflowLoggerCallback(experiment_name=exp_name, save_artifact=True)],\n",
    "#     verbose=3\n",
    "# )\n",
    "\n",
    "# exp_name = \"R2D2_test_April13\"\n",
    "# results = tune.run(\n",
    "#     \"R2D2\",\n",
    "#     name=exp_name,\n",
    "#     config=training_config,\n",
    "#     #checkpoint_freq=250,\n",
    "#     checkpoint_at_end=True,\n",
    "#     stop=stop,\n",
    "#     callbacks=[MLflowLoggerCallback(experiment_name=exp_name, save_artifact=True)],\n",
    "#     verbose=3\n",
    "# )\n",
    "\n",
    "training_config_RBW=training_config.copy()\n",
    "training_config_RBW[\"n_step\"] = 5\n",
    "training_config_RBW[\"noisy\"] = True\n",
    "training_config_RBW[\"num_atoms\"] = 10\n",
    "training_config_RBW[\"v_min\"] = 0.5\n",
    "training_config_RBW[\"v_min\"] = 2\n",
    "\n",
    "\n",
    "exp_name = \"RAINBOW_test_April13\"\n",
    "results = tune.run(\n",
    "    \"DQN\",\n",
    "    name=exp_name,\n",
    "    config=training_config_RBW,\n",
    "    #checkpoint_freq=250,\n",
    "    checkpoint_at_end=True,\n",
    "    stop=stop,\n",
    "    callbacks=[MLflowLoggerCallback(experiment_name=exp_name, save_artifact=True)],\n",
    "    verbose=verbosity\n",
    ")\n"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Policy Gradient Methods: PG, A2C, A3C, PPO, APPO\n",
    "\n",
    "exp_name = \"PG_test_April13\"\n",
    "results = tune.run(\n",
    "    \"PG\",\n",
    "    name=exp_name,\n",
    "    config=training_config,\n",
    "    #checkpoint_freq=250,\n",
    "    checkpoint_at_end=True,\n",
    "    stop=stop,\n",
    "    callbacks=[MLflowLoggerCallback(experiment_name=exp_name, save_artifact=True)],\n",
    "    verbose=verbosity\n",
    ")\n",
    "\n",
    "# exp_name = \"A2C_test_April12\"\n",
    "# results = tune.run(\n",
    "#     \"A2C\",\n",
    "#     name=exp_name,\n",
    "#     config=training_config,\n",
    "#     #checkpoint_freq=250,\n",
    "#     checkpoint_at_end=True,\n",
    "#     stop=stop,\n",
    "#     callbacks=[MLflowLoggerCallback(experiment_name=exp_name, save_artifact=True)],\n",
    "#     verbose=3\n",
    "# )\n",
    "\n",
    "# exp_name = \"A3C_test_April12\"\n",
    "# results = tune.run(\n",
    "#     \"A3C\",\n",
    "#     name=exp_name,\n",
    "#     config=training_config,\n",
    "#     #checkpoint_freq=250,\n",
    "#     checkpoint_at_end=True,\n",
    "#     stop=stop,\n",
    "#     callbacks=[MLflowLoggerCallback(experiment_name=exp_name, save_artifact=True)],\n",
    "#     verbose=3\n",
    "# )\n",
    "\n",
    "exp_name = \"PPO_test_April13\"\n",
    "results = tune.run(\n",
    "    \"PPO\",\n",
    "    name=exp_name,\n",
    "    config=training_config,\n",
    "    #checkpoint_freq=250,\n",
    "    checkpoint_at_end=True,\n",
    "    stop=stop,\n",
    "    callbacks=[MLflowLoggerCallback(experiment_name=exp_name, save_artifact=True)],\n",
    "    verbose=verbosity\n",
    ")\n",
    "\n",
    "# exp_name = \"APPO_test_April12\"\n",
    "# results = tune.run(\n",
    "#     \"APPO\",\n",
    "#     name=exp_name,\n",
    "#     config=training_config,\n",
    "#     #checkpoint_freq=250,\n",
    "#     checkpoint_at_end=True,\n",
    "#     stop=stop,\n",
    "#     callbacks=[MLflowLoggerCallback(experiment_name=exp_name, save_artifact=True)],\n",
    "#     verbose=3\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#Mixed:  SAC, IMPALA\n",
    "\n",
    "exp_name = \"SAC_test_April13\"\n",
    "results = tune.run(\n",
    "    \"SAC\",\n",
    "    name=exp_name,\n",
    "    config=training_config,\n",
    "    #checkpoint_freq=250,\n",
    "    checkpoint_at_end=True,\n",
    "    stop=stop,\n",
    "    callbacks=[MLflowLoggerCallback(experiment_name=exp_name, save_artifact=True)],\n",
    "    verbose=verbosity\n",
    ")\n",
    "\n",
    "#Has off-policy correction methods\n",
    "exp_name = \"IMPALA_test_April13\"\n",
    "results = tune.run(\n",
    "    \"IMPALA\",\n",
    "    name=exp_name,\n",
    "    config=training_config,\n",
    "    #checkpoint_freq=250,\n",
    "    checkpoint_at_end=True,\n",
    "    stop=stop,\n",
    "    callbacks=[MLflowLoggerCallback(experiment_name=exp_name, save_artifact=True)],\n",
    "    verbose=verbosity\n",
    ")"
   ]
  },
  {
   "source": [
    "## Continuous Space\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#DDGP uses its own exploration config\n",
    "# See exploration config in https://github.com/ray-project/ray/blob/master/rllib/utils/exploration/ornstein_uhlenbeck_noise.pyDDPG \n",
    "exploration_config_cont = {\n",
    "        # DDPG uses OrnsteinUhlenbeck (stateful) noise to be added to NN-output\n",
    "        # actions (after a possible pure random phase of n timesteps).\n",
    "        \"type\": \"OrnsteinUhlenbeckNoise\",\n",
    "        \"final_scale\": 0.02,\n",
    "        \"scale_timesteps\": 100000,\n",
    "    }\n",
    "\n",
    "training_config_cont=training_config.copy()\n",
    "env_config_cont=env_config.copy()\n",
    "training_config_cont[\"exploration_config\"] = exploration_config_cont\n",
    "env_config_cont[\"mkt_config\"][\"space_type\"] = \"Continuous\"\n",
    "\n",
    "env=DiffDemand(env_config_cont)\n",
    "training_config_cont[\"env_config\"] = env_config_cont\n",
    "training_config_cont[\"multiagent\"][\"policies\"] =  {\n",
    "            policy_ids[i]: (None, env.observation_space[f\"agent_{i}\"], env.action_space[f\"agent_{i}\"],{},) for i in range(env.n_agents)\n",
    "}\n",
    "#print(env_config)\n",
    "print(training_config_cont)\n",
    "print(env.action_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "exp_name = \"DDPG_cont_test_April13\"\n",
    "results = tune.run(\n",
    "    \"DDPG\",\n",
    "    name=exp_name,\n",
    "    config=training_config_cont,\n",
    "    #checkpoint_freq=250,\n",
    "    checkpoint_at_end=True,\n",
    "    stop=stop,\n",
    "    callbacks=[MLflowLoggerCallback(experiment_name=exp_name, save_artifact=True)],\n",
    "    verbose=verbosity\n",
    ")\n",
    "\n",
    "exp_name = \"TD3_cont_test_April13\"\n",
    "results = tune.run(\n",
    "    \"TD3\",\n",
    "    name=exp_name,\n",
    "    config=training_config_cont,\n",
    "    #checkpoint_freq=250,\n",
    "    checkpoint_at_end=True,\n",
    "    stop=stop,\n",
    "    callbacks=[MLflowLoggerCallback(experiment_name=exp_name, save_artifact=True)],\n",
    "    verbose=verbosity\n",
    ")\n",
    "\n",
    "exp_name = \"SAC_cont_test_April13\"\n",
    "results = tune.run(\n",
    "    \"SAC\",\n",
    "    name=exp_name,\n",
    "    config=training_config_cont,\n",
    "    #checkpoint_freq=250,\n",
    "    checkpoint_at_end=True,\n",
    "    stop=stop,\n",
    "    callbacks=[MLflowLoggerCallback(experiment_name=exp_name, save_artifact=True)],\n",
    "    verbose=verbosity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}